{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MatiasCovarrubias/jaxecon/blob/main/jaxDEQN_rbc.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmNe6o_4tTEy"
      },
      "source": [
        "# DEQN Solver in Jax: Prelims\n",
        "\n",
        "This notebook trains a neural net to output the optimal policy of a nonlinear Rbc model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ue0dX6Q14A1Q",
        "outputId": "4f6d4918-f222-4e51-c4e6-ae1fe9f3d6c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Feb 21 16:11:52 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   61C    P8              10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n",
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# BACKEND RELATED: the default backend is CPU (change in Edit -> Notebook settings)\n",
        "GPU = True # set True if using GPU (only to see GPU)\n",
        "if GPU:\n",
        "  !nvidia-smi\n",
        "\n",
        "# precision\n",
        "from jax import numpy as jnp, lax, random, config\n",
        "double_precision = True\n",
        "if double_precision:\n",
        "  config.update(\"jax_enable_x64\", True)\n",
        "  precision = jnp.float64\n",
        "else:\n",
        "  precision = jnp.float32\n",
        "\n",
        "# Imports\n",
        "import matplotlib.pyplot as plt, jax, flax, optax, os, json\n",
        "import flax.linen as nn\n",
        "from flax.training.train_state import TrainState  # Useful dataclass to keep train state\n",
        "from flax.training import checkpoints\n",
        "from flax.core import freeze, unfreeze\n",
        "import optax\n",
        "from time import time\n",
        "from typing import Sequence\n",
        "config.update(\"jax_debug_nans\", True)\n",
        "\n",
        "# Mount Google Drive to store results (a pop up will appear, follow instructions)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rIQLSPJLvaPE"
      },
      "source": [
        "# Create Neural Net Policy\n",
        "\n",
        "First, we use Flax to create the Neural Net, Notice that we activate the last layer using Softplus to guarantee that we get possitive outputs.\n",
        "\n",
        "See https://flax.readthedocs.io/en/latest/getting_started.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NVGY1ZCnvtXh"
      },
      "outputs": [],
      "source": [
        "class NeuralNet(nn.Module):\n",
        "  features: Sequence[int]\n",
        "  param_dtype = precision\n",
        "\n",
        "  @nn.compact\n",
        "  def __call__(self, x):\n",
        "    for feat in self.features[:-1]:\n",
        "      x = nn.relu(nn.Dense(feat, param_dtype=precision)(x))\n",
        "    x = nn.softplus(nn.Dense(self.features[-1], param_dtype=precision)(x))\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7LXEca1NwAiC"
      },
      "source": [
        "# Create Economic Model\n",
        "\n",
        "We will represent our model as clas with four main methods (or functions): initial_obs to get first observation; step to advance a period, expectation to get the expectation term given a state, policy, and shock; and a loss funciton that gets as the loss given a state, policy and expectation term."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Model():\n",
        "  \"\"\"A JAX implementation of an RBC model.\"\"\"\n",
        "\n",
        "  def __init__(self):\n",
        "    # set parameters\n",
        "    self.beta = jnp.array(0.96, dtype=precision)\n",
        "    self.alpha = jnp.array(0.3, dtype=precision)\n",
        "    self.delta = jnp.array(0.1, dtype=precision)\n",
        "    self.rho = jnp.array(0.9, dtype=precision)\n",
        "    self.shock_sd = jnp.array(0.02, dtype=precision)\n",
        "\n",
        "\n",
        "    # set steady state and standard deviations for normalization\n",
        "    self.k_ss = jnp.log((self.alpha/(1/self.beta-1+self.delta))**(1/(1-self.alpha)))\n",
        "    self.a_ss = jnp.array(0, dtype=precision)\n",
        "    self.obs_ss = jnp.array([self.k_ss, 0], dtype=precision)\n",
        "    self.obs_sd = jnp.array([1, 1], dtype=precision)  # use 1 if you don't have an estimate\n",
        "    self.policy_ss = self.k_ss\n",
        "\n",
        "    # number of policies\n",
        "    self.n_actions = 1\n",
        "\n",
        "  def initial_obs(self, rng):\n",
        "    \"\"\" Get initial obs given first shock \"\"\"\n",
        "    rng_k, rng_a = random.split(rng,2)\n",
        "    K = random.uniform(\n",
        "            rng_k, minval=0.9 * jnp.exp(self.k_ss), maxval=1.1 * jnp.exp(self.k_ss), dtype=precision\n",
        "        )  # get uniform draw around the steady state\n",
        "    A = random.uniform(\n",
        "            rng_a, minval=0.9 * jnp.exp(self.a_ss), maxval=1.1 * jnp.exp(self.a_ss), dtype=precision\n",
        "        )  # get uniform draw around the steady state\n",
        "\n",
        "    obs_init_notnorm = jnp.array([jnp.log(K), jnp.log(A)], dtype=precision)\n",
        "    obs_init = (obs_init_notnorm-self.obs_ss)/self.obs_sd # normalize\n",
        "    return obs_init\n",
        "\n",
        "  def step(self, obs, policy, shock):\n",
        "    \"\"\" A period step of the model, given current obs, the shock and policy \"\"\"\n",
        "\n",
        "    obs_notnorm = obs*self.obs_sd + self.obs_ss # denormalize\n",
        "    K = jnp.exp(obs_notnorm[0])                 # Kt in levels\n",
        "    a = obs_notnorm[1]                    # a_{t}\n",
        "    a_tplus1 = self.rho * a + self.shock_sd*shock[0]   # recover a_{t+1}\n",
        "    policy_notnorm = policy*jnp.exp(self.policy_ss)             # multiply by stst pols in level\n",
        "    # K_tplus1 = (1-self.delta)*K + policy_notnorm[0]             #get K_{t+1}\n",
        "    K_tplus1 = policy_notnorm[0]             #get K_{t+1}\n",
        "    obs_next_notnorm = jnp.array([jnp.log(K_tplus1),a_tplus1])  #concatenate observation\n",
        "    obs_next = (obs_next_notnorm-self.obs_ss)/self.obs_sd        # normalize\n",
        "\n",
        "    return obs_next\n",
        "\n",
        "\n",
        "  def expect_realization(self, obs_next, policy_next):\n",
        "    \"\"\" A realization (given a shock) of the expectation terms in system of equation \"\"\"\n",
        "\n",
        "    policy_notnorm = policy_next*jnp.exp(self.policy_ss) # multiply by stst pols in levels\n",
        "    K_tplus1 = policy_notnorm[0]                                # define investment\n",
        "\n",
        "    # Process observation\n",
        "    obs_notnorm = obs_next*self.obs_sd + self.obs_ss     # denormalize obs\n",
        "    K = jnp.exp(obs_notnorm[0])                          # K_{t+1} in levels\n",
        "    a = obs_notnorm[1]                             # a_{t}\n",
        "    I = K_tplus1 - (1-self.delta)*K\n",
        "    # Rest of variables\n",
        "    A = jnp.exp(a)\n",
        "    Y = A * K**self.alpha\n",
        "    C = Y-I\n",
        "\n",
        "    # Calculate the FOC for Pk\n",
        "    expect_realization = (1/C) * (1+ A * self.alpha * K**(self.alpha-1)-self.delta)\n",
        "\n",
        "    return expect_realization\n",
        "\n",
        "  def loss(self, obs, expect, policy):\n",
        "    \"\"\" Calculate loss associated with observing obs, having policy_params, and expectation exp \"\"\"\n",
        "\n",
        "    policy_notnorm = policy*jnp.exp(self.policy_ss)\n",
        "    K_tplus1 = policy_notnorm[0]\n",
        "\n",
        "    # Process observation\n",
        "    obs_notnorm = obs*self.obs_sd + self.obs_ss        # denormalize\n",
        "    K = jnp.exp(obs_notnorm[0])                        # put in levels\n",
        "    a = obs_notnorm[1]\n",
        "\n",
        "    # Rest of variables\n",
        "    I = K_tplus1-(1-self.delta)*K\n",
        "    A = jnp.exp(a)\n",
        "    Y = A * K**self.alpha\n",
        "    C = Y-I\n",
        "\n",
        "    # Calculate the FOC for Pk\n",
        "    FOC_loss = (1/C)/(self.beta*expect) - 1\n",
        "    mean_loss = jnp.mean(jnp.array([FOC_loss**2])) # here there is just one, but more gemore generally.\n",
        "    mean_accuracy = jnp.mean(jnp.array([1-jnp.abs(FOC_loss)]))\n",
        "    min_accuracy = jnp.min(jnp.array([1-jnp.abs(FOC_loss)]))\n",
        "    return mean_loss, mean_accuracy, min_accuracy\n",
        "\n",
        "  def sample_shock(self, rng, n_draws=1):\n",
        "    \"\"\" sample one realization of the shock.\n",
        "    Uncomment second line for continuous shocks instead of grid \"\"\"\n",
        "    # return random.choice(rng, jnp.array([-1.2816,-0.6745,0,0.6745, 1.2816]))\n",
        "    return random.normal(rng, shape=(n_draws,), dtype=precision)\n",
        "\n",
        "  def mc_shocks(self, rng=random.PRNGKey(0), mc_draws=8):\n",
        "    \"\"\" sample omc_draws realizations of the shock (for monte-carlo)\n",
        "    Uncomment second line for continuous shocks instead of grid \"\"\"\n",
        "    # return  jnp.array([-1.2816,-0.6745,0,0.6745, 1.2816])\n",
        "    return random.normal(rng, shape=(mc_draws,1), dtype = precision)\n",
        "\n",
        "  def ir_shocks(self):\n",
        "    \"\"\" (Optional) Define a set of shocks sequences that are of interest\"\"\"\n",
        "    # ir_shock_1 = jnp.array([-1]+[0 for i in range(40)])\n",
        "    # ir_shock_2 = jnp.array([1]+[0 for i in range(40)])\n",
        "    ir_shock_1 = jnp.zeros(shape=(40,1), dtype = precision).at[0,:].set(-1)\n",
        "    ir_shock_2 = jnp.zeros(shape=(40,1), dtype = precision).at[0,:].set(1)\n",
        "\n",
        "    return jnp.array([ir_shock_1, ir_shock_2])\n",
        "\n",
        "  def get_econ_stats(self, obs, policy):\n",
        "\n",
        "    policy_notnorm = policy*jnp.exp(self.policy_ss)\n",
        "    I = policy_notnorm[0]\n",
        "\n",
        "    # Process observation\n",
        "    obs_notnorm = obs*self.obs_sd + self.obs_ss        # denormalize\n",
        "    K = jnp.exp(obs_notnorm[0])                        # put in levels\n",
        "    a = obs_notnorm[1]\n",
        "\n",
        "    # Rest of variables\n",
        "    A = jnp.exp(a)\n",
        "    Y = A * K**self.alpha\n",
        "    C = Y-I\n",
        "\n",
        "    return jnp.array([K,I,Y,C])"
      ],
      "metadata": {
        "id": "9ueaQPW4GbcR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test the environment\n",
        "We are going to make sure that the functions in our model are correct"
      ],
      "metadata": {
        "id": "Fz-RH8Wt23Rz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "env = Model()\n",
        "rng_test = random.PRNGKey(2)\n",
        "\n",
        "# test steady state policies with random params\n",
        "obs_ss = jnp.zeros_like(env.obs_ss, dtype=precision)\n",
        "nn_test = NeuralNet([2,2] + [env.n_actions])\n",
        "nn_policy_test = nn_test.apply\n",
        "params_test = nn_test.init(rng_test, obs_ss) # we initialize random params\n",
        "policy_ss = nn_policy_test(params_test,obs_ss)\n",
        "\n",
        "# intialize env\n",
        "obs_init = env.initial_obs(rng_test)\n",
        "\n",
        "# apply a step\n",
        "policy_firststep = nn_policy_test(params_test,obs_init)\n",
        "shock_firststep = env.sample_shock(rng_test)\n",
        "next_obs_firststep = env.step(obs_init, policy_firststep, shock_firststep)\n",
        "\n",
        "# calculate loss in first step.\n",
        "\n",
        "#First, we calculate expectations\n",
        "mc_shocks = env.mc_shocks(rng_test)\n",
        "mc_nextobs = jax.vmap(env.step, in_axes = (None,None,0))(obs_init, policy_firststep, mc_shocks) # next obs given policy and for each shock in mc_shocks\n",
        "\n",
        "mc_nextpols = nn_policy_test(params_test, mc_nextobs)\n",
        "expect_firststep = jnp.mean(jax.vmap(env.expect_realization)(mc_nextobs, mc_nextpols))\n",
        "\n",
        "# Second, we calculate loss given expectations and policy\n",
        "mean_loss, mean_accuracy, min_accuracy = env.loss(obs_init, expect_firststep, policy_firststep)\n",
        "print(\"test first step: \\n\",\n",
        "      \", Mean_loss:\", mean_loss,\n",
        "      \", Mean_accuracy:\", mean_accuracy,\n",
        "      \", Min_accuracy:\", min_accuracy)\n",
        "\n",
        "# calculate loss with policy = 1\n",
        "policy_ones = jnp.ones_like(policy_firststep)\n",
        "mc_nextobs = jax.vmap(env.step, in_axes = (None,None,0))(obs_ss, policy_ones, jnp.zeros_like(mc_shocks)) # next obs given policy and for each shock in mc_shocks\n",
        "print(\"next obs for montecarlo with policies =1 (should be an array with multiple obs =0)\", mc_nextobs)\n",
        "\n",
        "mc_nextpols = jnp.ones_like(mc_nextpols)\n",
        "expect = jnp.mean(jax.vmap(env.expect_realization)(mc_nextobs, mc_nextpols))\n",
        "print(\"expectation\", expect)\n",
        "\n",
        "mean_loss, mean_accuracy, min_accuracy = env.loss(obs_ss, expect, policy_ones)\n",
        "print(\"test that StSt. policies give 0 loss in StSt. obs: \\n\",\n",
        "      \", Mean_loss:\", mean_loss,\n",
        "      \", Mean_accuracy:\", mean_accuracy,\n",
        "      \", Min_accuracy:\", min_accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-g60VDRJ-Zx_",
        "outputId": "ff4b4831-f127-42e0-9502-c35a486df634"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test first step: \n",
            " , Mean_loss: 0.08757804310517178 , Mean_accuracy: 0.7040641233220079 , Min_accuracy: 0.7040641233220079\n",
            "next obs for montecarlo with policies =1 (should be an array with multiple obs =0) [[0. 0.]\n",
            " [0. 0.]\n",
            " [0. 0.]\n",
            " [0. 0.]\n",
            " [0. 0.]\n",
            " [0. 0.]\n",
            " [0. 0.]\n",
            " [0. 0.]]\n",
            "expectation 0.958123199223544\n",
            "test that StSt. policies give 0 loss in StSt. obs: \n",
            " , Mean_loss: 0.0 , Mean_accuracy: 1.0 , Min_accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Simulation function"
      ],
      "metadata": {
        "id": "Xf6Ond64MCsp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_episode_simul_fn(env, config):\n",
        "\n",
        "  def sample_epis_obs(train_state, epis_rng):\n",
        "    \"sample obs of an episode\"\n",
        "    init_obs = env.initial_obs(epis_rng)\n",
        "    period_rngs = random.split(epis_rng, config[\"periods_per_epis\"])\n",
        "    def period_step(env_obs, period_rng):\n",
        "      policy = train_state.apply_fn(train_state.params, env_obs)                 # calculate policy\n",
        "      period_shock = config[\"simul_vol_scale\"]*env.sample_shock(period_rng)         # Sample next obs\n",
        "      obs_next = env.step(env_obs, policy, period_shock)  # apply period steps.\n",
        "      return obs_next, obs_next # we pass it two times because of the syntax of the lax.scan loop\n",
        "    _, epis_obs = lax.scan(period_step, init_obs, jnp.stack(period_rngs)) # we get the obs_batch\n",
        "    # init_obs = init_obs.reshape(1,init_obs.shape[0])\n",
        "    # epis_obs =jnp.concatenate([init_obs,epis_obs])\n",
        "    return epis_obs\n",
        "\n",
        "  return sample_epis_obs"
      ],
      "metadata": {
        "id": "1K6CZbSNMIWy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test simulation function"
      ],
      "metadata": {
        "id": "cygQcsHYIiDN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#CREATE ENV,  TRAIN_STATE AND RNG\n",
        "env_test = Model()\n",
        "nn_test = NeuralNet([2,2] + [env_test.n_actions])\n",
        "rng_test = random.PRNGKey(1)\n",
        "\n",
        "# CREATE CONFIG\n",
        "config_test = {\n",
        "    \"periods_per_epis\": 4,      # periods per episode\n",
        "    \"simul_vol_scale\": 1,        # scale of volatility while simul\n",
        "}\n",
        "\n",
        "# GET FUNCTIONS\n",
        "episode_simul_fn = create_episode_simul_fn(env_test, config_test)\n",
        "train_state_test = TrainState.create(apply_fn=nn_test.apply, params=nn_test.init(rng_test, env_test.initial_obs(rng_test)), tx=optax.adam(0.05))\n",
        "epis_rng, loss_rng = random.split(rng_test, 2)\n",
        "epis_obs = episode_simul_fn(train_state_test, epis_rng)\n",
        "print(epis_obs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BwozvI7BImR3",
        "outputId": "97c72f57-868c-4634-c997-6843207f8584"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-0.3655886   0.03784751]\n",
            " [-0.33945239  0.02578569]\n",
            " [-0.34034204  0.00378591]\n",
            " [-0.33782834 -0.0035688 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Loss function"
      ],
      "metadata": {
        "id": "e6qLf-4qM4GN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_batch_loss_fn(env, config):\n",
        "\n",
        "  def batch_loss_fn(params, train_state, batch_obs, loss_rng):\n",
        "    \"\"\"Loss function of a batch of obs.\"\"\"\n",
        "    period_mc_rngs = random.split(loss_rng, batch_obs.shape[0])\n",
        "    batch_policies = train_state.apply_fn(params, batch_obs) # get the policies for the entire obs batch.\n",
        "\n",
        "    def period_loss(obs, policy, period_mc_rng):\n",
        "      \"\"\"Loss function for an individual period.\"\"\"\n",
        "      mc_shocks = env.mc_shocks(period_mc_rng, config[\"mc_draws\"])\n",
        "      mc_nextobs = jax.vmap(env.step, in_axes = (None,None,0))(obs, policy, mc_shocks)\n",
        "      mc_nextpols = train_state.apply_fn(params, mc_nextobs)\n",
        "      expect = jnp.mean(jax.vmap(env.expect_realization)(mc_nextobs, mc_nextpols))\n",
        "      mean_loss, mean_accuracy, min_accuracy = env.loss(obs, expect, policy) # calculate loss\n",
        "      return mean_loss, mean_accuracy, min_accuracy\n",
        "\n",
        "    # parallelize callculation of period_loss for the entire batch\n",
        "    mean_losses, mean_accuracies, min_accuracies = jax.vmap(period_loss)(batch_obs, batch_policies, jnp.stack(period_mc_rngs))\n",
        "    mean_loss = jnp.mean(mean_losses)                   # average accross periods\n",
        "    mean_accuracy = jnp.mean(mean_accuracies)           # average accross periods\n",
        "    min_accuracy = jnp.min(min_accuracies)              # min accross periods and across eqs within period\n",
        "    metrics = jnp.array([mean_loss, mean_accuracy, min_accuracy]) # pass as auxiliary info\n",
        "    # metrics = jnp.array([mean_losses, mean_accuracies, min_accuracies]) # pass as auxiliary info\n",
        "    return mean_loss, metrics\n",
        "\n",
        "  return batch_loss_fn"
      ],
      "metadata": {
        "id": "TcoKxR5xM8CL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test loss fn\n",
        "\n",
        "We calculate the loss and metrics of a single epsiode. To do so, we set batch_size equal to periods_per_epis"
      ],
      "metadata": {
        "id": "1pceB-eSEbcG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#CREATE ENV,  TRAIN_STATE AND RNG\n",
        "env_test = Model()\n",
        "nn_test = NeuralNet([2,2] + [env_test.n_actions])\n",
        "rng_test = random.PRNGKey(1)\n",
        "\n",
        "# CREATE CONFIG\n",
        "config_test = {\n",
        "    \"periods_per_epis\": 8,      # periods per episode\n",
        "    \"simul_vol_scale\": 1,        # scale of volatility while simul\n",
        "    \"mc_draws\": 32,             # only applies if shock is continuous\n",
        "}\n",
        "config_test[\"batch_size\"] = config_test[\"periods_per_epis\"]\n",
        "\n",
        "# GET FUNCTIONS\n",
        "episode_simul_fn = create_episode_simul_fn(env_test, config_test)\n",
        "episode_loss_fn = create_batch_loss_fn(env_test, config_test)\n",
        "\n",
        "train_state_test = TrainState.create(apply_fn=nn_test.apply, params=nn_test.init(rng_test, env_test.initial_obs(rng_test)), tx=optax.adam(0.05))\n",
        "epis_rng, loss_rng = random.split(rng_test, 2)\n",
        "epis_obs = episode_simul_fn(train_state_test, epis_rng)\n",
        "\n",
        "loss, epis_metrics = episode_loss_fn(train_state_test.params, train_state_test, epis_obs, loss_rng)\n",
        "print(\"loss:\", loss)\n",
        "print(\"epis_metrics:\", epis_metrics)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_MLBUEcHEgdY",
        "outputId": "56c9c039-569d-49c7-8722-90510b067f99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss: 0.0011850035778332838\n",
            "epis_metrics: [0.001185   0.96803212 0.94555273]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Epoch Training function\n",
        "\n"
      ],
      "metadata": {
        "id": "mjl96ePdNvjb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_epoch_train_fn(env, config):\n",
        "  episode_simul_fn = create_episode_simul_fn(env, config)\n",
        "  episode_loss_fn = create_batch_loss_fn(env, config)\n",
        "\n",
        "  def batch_train_fn(train_state, batch_obs, loss_rng):\n",
        "    grad_fn = jax.value_and_grad(episode_loss_fn, has_aux=True)\n",
        "    (_, epis_metrics), grads = grad_fn(train_state.params, train_state, batch_obs, loss_rng)\n",
        "    grads = jax.lax.pmean(grads, axis_name=\"batch\")\n",
        "    train_state = train_state.apply_gradients(grads=grads)\n",
        "    return train_state, epis_metrics\n",
        "\n",
        "  def step_train_fn(train_state, step_rng):\n",
        "    epis_rng = random.split(step_rng, config[\"epis_per_step\"])\n",
        "    loss_rng = random.split(step_rng, config[\"n_batches\"])\n",
        "    step_obs = jax.vmap(episode_simul_fn, in_axes=(None,0))(train_state, jnp.stack(epis_rng))\n",
        "    step_obs = step_obs.reshape(config[\"periods_per_step\"], env.obs_ss.shape[0]) # combine all periods in one axis\n",
        "    step_obs = random.permutation(step_rng, step_obs, axis=0)                   # reshuffle obs at random\n",
        "    step_obs = step_obs.reshape(config[\"n_batches\"], config[\"batch_size\"] ,env.obs_ss.shape[0]) # reshape to into batches\n",
        "    train_state, batch_metrics = jax.vmap(batch_train_fn, in_axes=(None,0,0), out_axes=(None,0), axis_name=\"batch\")(train_state, step_obs, jnp.stack(loss_rng))\n",
        "    batch_metrics = jnp.mean(batch_metrics,axis=0)\n",
        "    return train_state, batch_metrics\n",
        "\n",
        "  def epoch_train_fn(train_state, epoch_rng):\n",
        "    \"\"\"Vectorise and repeat the update to complete an epoch, made aout of steps_per_epoch episodes.\"\"\"\n",
        "    epoch_rng, *step_rngs = random.split(epoch_rng, config[\"steps_per_epoch\"] + 1)\n",
        "    train_state, epoch_metrics = lax.scan(step_train_fn, train_state, jnp.stack(step_rngs))\n",
        "    return train_state, epoch_rng, epoch_metrics\n",
        "\n",
        "  return epoch_train_fn"
      ],
      "metadata": {
        "id": "Lacb6dyKN7hi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test the training function\n",
        "\n",
        "We can run one epoch and see the results. Play with the parameters of the epoch to evaluate how good is the starting point. You can also add prints inside the update function to check internal values. An important check is to print the grads inside the epis_update_fn and make sure they are not zero for an entire layer. This is especially relevant when using pre-trained models."
      ],
      "metadata": {
        "id": "JYEia3OD-Lij"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config_test = {\n",
        "    \"periods_per_epis\": 16,      # periods per episode\n",
        "    \"epis_per_step\": 8,         # epoch per steps\n",
        "    \"steps_per_epoch\": 100,       # steps per epoch\n",
        "    \"batch_size\": 4,\n",
        "    \"n_epochs\": 1,              # number of epochs\n",
        "    \"mc_draws\": 32,             # only applies if shock is continuous\n",
        "    \"simul_vol_scale\": 1,        # scale of volatility while simul\n",
        "}\n",
        "\n",
        "config_test[\"periods_per_step\"] =config_test[\"periods_per_epis\"]*config_test[\"epis_per_step\"]\n",
        "config_test[\"n_batches\"] = config_test[\"periods_per_step\"]//config_test[\"batch_size\"]\n",
        "env_test = Model()\n",
        "epoch_update_test = get_epoch_train_fn(env_test, config_test)\n",
        "\n",
        "#CREATE TRAIN_STATE AND RNG\n",
        "nn_test = NeuralNet([2,2] + [env_test.n_actions])\n",
        "rng_test_init = random.PRNGKey(1)\n",
        "train_state_test = TrainState.create(apply_fn=nn_test.apply, params=nn_test.init(rng_test, env_test.initial_obs(rng_test)), tx=optax.adam(0.05))\n",
        "\n",
        "# RUN UPDATE FUNCTION\n",
        "new_train_state, new_rng_test, metrics_test = epoch_update_test(train_state_test, rng_test_init)\n",
        "print(len(metrics_test))\n",
        "print(len(metrics_test[0]))\n",
        "\n",
        "print(\"test epoch: \\n\",\n",
        "      \"Mean_loss:\", metrics_test[-1][0], \"\\n\",\n",
        "      \"Mean_accuracy:\", metrics_test[-1][1], \"\\n\",\n",
        "      \"Min_accuracy:\", metrics_test[-1][2],)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hicUBLteIjCP",
        "outputId": "ba790989-6090-4d45-d1c4-78ddd14f07da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100\n",
            "3\n",
            "test epoch: \n",
            " Mean_loss: 6.320878721404735e-05 \n",
            " Mean_accuracy: 0.9943174139625349 \n",
            " Min_accuracy: 0.9880704039107062\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Evaluation function"
      ],
      "metadata": {
        "id": "fJ5nxqwWwPTU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_eval_fn(env, config):\n",
        "  config = config[\"config_eval\"]\n",
        "  episode_simul_fn = create_episode_simul_fn(env, config)\n",
        "  batch_loss_fn = create_batch_loss_fn(env, config)\n",
        "\n",
        "  def episode_eval_fn(train_state, epis_rng):\n",
        "    epis_rng, loss_rng = random.split(epis_rng, 2)\n",
        "    epis_obs = episode_simul_fn(train_state, epis_rng)\n",
        "    _, epis_metrics = batch_loss_fn(train_state.params, train_state, epis_obs, loss_rng)\n",
        "    return epis_metrics\n",
        "\n",
        "  def eval_fn(train_state, step_rng):\n",
        "    epis_rng = random.split(step_rng, config[\"eval_n_epis\"])\n",
        "    eval_metrics = jax.vmap(episode_eval_fn, in_axes=(None,0))(train_state, jnp.stack(epis_rng))\n",
        "    eval_metrics = jnp.mean(eval_metrics,axis=0)\n",
        "    return eval_metrics\n",
        "\n",
        "  return eval_fn"
      ],
      "metadata": {
        "id": "Tt-0bBX9wUIe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Evaluation function\n",
        "\n"
      ],
      "metadata": {
        "id": "wEG-xLNZQJLY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config_test = {\n",
        "    \"periods_per_epis\": 16,      # periods per episode\n",
        "    \"epis_per_step\": 8,         # epoch per steps\n",
        "    \"steps_per_epoch\": 10,       # steps per epoch\n",
        "    \"batch_size\": 4,\n",
        "    \"n_epochs\": 1,              # number of epochs\n",
        "    \"mc_draws\": 32,             # only applies if shock is continuous\n",
        "    \"simul_vol_scale\": 1,        # scale of volatility while simul\n",
        "    \"config_eval\": {\n",
        "      \"periods_per_epis\": 16,      # periods per episode\n",
        "      \"mc_draws\": 128,         # number of mc draws\n",
        "      \"simul_vol_scale\": 1,        # scale of volatility while simul\n",
        "      \"eval_n_epis\": 128,           # episodes to sample for eval\n",
        "    }\n",
        "}\n",
        "\n",
        "config_test[\"periods_per_step\"] =config_test[\"periods_per_epis\"]*config_test[\"epis_per_step\"]\n",
        "config_test[\"n_batches\"] = config_test[\"periods_per_step\"]//config_test[\"batch_size\"]\n",
        "env_test = Model()\n",
        "epoch_train_fn_test = get_epoque_train_fn(env_test, config_test)\n",
        "eval_fn_test = get_eval_fn(env_test, config_test)\n",
        "\n",
        "#CREATE TRAIN_STATE AND RNG\n",
        "nn_test = NeuralNet([2,2] + [env_test.n_actions])\n",
        "rng_test_init = random.PRNGKey(1)\n",
        "train_state_test = TrainState.create(apply_fn=nn_test.apply, params=nn_test.init(rng_test, env_test.initial_obs(rng_test)), tx=optax.adam(0.05))\n",
        "\n",
        "# RUN UPDATE FUNCTION\n",
        "new_train_state, new_rng_test, train_metrics_test = epoch_train_fn_test(train_state_test, rng_test_init)\n",
        "print(\"Training Metrics:\", train_metrics_test)\n",
        "eval_metrics_test = eval_fn_test(new_train_state, rng_test)\n",
        "print(\"Evaluation Metrics:\", eval_metrics_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IGKZvG6AQTnA",
        "outputId": "9ae78197-b97c-4e2e-d6d2-8a33c62da16c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Metrics: [[1.38475564e-03 9.66976272e-01 9.48431888e-01]\n",
            " [1.19806105e-03 9.71585892e-01 9.51370903e-01]\n",
            " [1.04816352e-03 9.79465775e-01 9.57080891e-01]\n",
            " [7.50678550e-04 9.81448469e-01 9.61906280e-01]\n",
            " [6.61230761e-04 9.83211500e-01 9.65042923e-01]\n",
            " [2.47831286e-03 9.72843243e-01 9.39768301e-01]\n",
            " [2.68937543e-03 9.75473590e-01 9.40545072e-01]\n",
            " [1.47142798e-03 9.80667488e-01 9.58113524e-01]\n",
            " [2.03047028e-03 9.77668665e-01 9.39700270e-01]\n",
            " [2.06233660e-03 9.75692128e-01 9.39352488e-01]]\n",
            "Evaluation Metrics: [0.00119602 0.98035572 0.89911972]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PlXarixBjTC2"
      },
      "source": [
        "# Configure experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3zWgbr0HjQua",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbe40148-7a14-4a53-a1ee-185447496e1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of parameters:\n",
            "\n",
            "\u001b[3m                               NeuralNet Summary                                \u001b[0m\n",
            "┏━━━━━━━━━┳━━━━━━━━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
            "┃\u001b[1m \u001b[0m\u001b[1mpath   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mmodule   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1minputs      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1moutputs     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mparams                  \u001b[0m\u001b[1m \u001b[0m┃\n",
            "┡━━━━━━━━━╇━━━━━━━━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
            "│         │ NeuralNet │ \u001b[2mfloat64\u001b[0m[2]   │ \u001b[2mfloat64\u001b[0m[1]   │                          │\n",
            "├─────────┼───────────┼──────────────┼──────────────┼──────────────────────────┤\n",
            "│ Dense_0 │ Dense     │ \u001b[2mfloat64\u001b[0m[2]   │ \u001b[2mfloat64\u001b[0m[128] │ bias: \u001b[2mfloat64\u001b[0m[128]       │\n",
            "│         │           │              │              │ kernel: \u001b[2mfloat64\u001b[0m[2,128]   │\n",
            "│         │           │              │              │                          │\n",
            "│         │           │              │              │ \u001b[1m384 \u001b[0m\u001b[1;2m(3.1 KB)\u001b[0m             │\n",
            "├─────────┼───────────┼──────────────┼──────────────┼──────────────────────────┤\n",
            "│ Dense_1 │ Dense     │ \u001b[2mfloat64\u001b[0m[128] │ \u001b[2mfloat64\u001b[0m[128] │ bias: \u001b[2mfloat64\u001b[0m[128]       │\n",
            "│         │           │              │              │ kernel: \u001b[2mfloat64\u001b[0m[128,128] │\n",
            "│         │           │              │              │                          │\n",
            "│         │           │              │              │ \u001b[1m16,512 \u001b[0m\u001b[1;2m(132.1 KB)\u001b[0m        │\n",
            "├─────────┼───────────┼──────────────┼──────────────┼──────────────────────────┤\n",
            "│ Dense_2 │ Dense     │ \u001b[2mfloat64\u001b[0m[128] │ \u001b[2mfloat64\u001b[0m[128] │ bias: \u001b[2mfloat64\u001b[0m[128]       │\n",
            "│         │           │              │              │ kernel: \u001b[2mfloat64\u001b[0m[128,128] │\n",
            "│         │           │              │              │                          │\n",
            "│         │           │              │              │ \u001b[1m16,512 \u001b[0m\u001b[1;2m(132.1 KB)\u001b[0m        │\n",
            "├─────────┼───────────┼──────────────┼──────────────┼──────────────────────────┤\n",
            "│ Dense_3 │ Dense     │ \u001b[2mfloat64\u001b[0m[128] │ \u001b[2mfloat64\u001b[0m[1]   │ bias: \u001b[2mfloat64\u001b[0m[1]         │\n",
            "│         │           │              │              │ kernel: \u001b[2mfloat64\u001b[0m[128,1]   │\n",
            "│         │           │              │              │                          │\n",
            "│         │           │              │              │ \u001b[1m129 \u001b[0m\u001b[1;2m(1.0 KB)\u001b[0m             │\n",
            "├─────────┼───────────┼──────────────┼──────────────┼──────────────────────────┤\n",
            "│\u001b[1m \u001b[0m\u001b[1m       \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m         \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m            \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m       Total\u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m33,537 \u001b[0m\u001b[1;2m(268.3 KB)\u001b[0m\u001b[1m       \u001b[0m\u001b[1m \u001b[0m│\n",
            "└─────────┴───────────┴──────────────┴──────────────┴──────────────────────────┘\n",
            "\u001b[1m                                                                                \u001b[0m\n",
            "\u001b[1m                      Total Parameters: 33,537 \u001b[0m\u001b[1;2m(268.3 KB)\u001b[0m\u001b[1m                       \u001b[0m\n",
            "\n",
            "\n",
            "TOTAL Number of steps (NN updates): 10000 episodes \n",
            "\n"
          ]
        }
      ],
      "source": [
        "'''Config dictionary'''\n",
        "\n",
        "# CREATE CONFIG DICT\n",
        "config = {\n",
        "    # general\n",
        "    \"seed\": 48,\n",
        "    \"run_name\": \"rbc_xlargeNNv2\",\n",
        "    \"date\": \"Feb20_24\",\n",
        "    \"working_dir\": \"/content/drive/MyDrive/Jaxecon/Rbc/Training/\",\n",
        "    \"restore\": False,                                                            # True if start from restored checkpoint\n",
        "    \"restore_run_name\": None,\n",
        "\n",
        "    # neural net\n",
        "    \"layers\": [128,128,128],              # layers of the NN\n",
        "\n",
        "    # learning rate schedule\n",
        "    \"lr_sch_values\": [0.001,0.001],                                        # values (from the last, we do cosine decay to 0)\n",
        "    \"lr_sch_transitions\": [5000],\n",
        "\n",
        "    # simulation\n",
        "    \"periods_per_epis\": 32,\n",
        "    \"simul_vol_scale\": 1,        # scale of volatility while simul\n",
        "\n",
        "    # loss calculation\n",
        "    \"mc_draws\": 64,               # monte-carlo draws\n",
        "\n",
        "    # training\n",
        "    \"epis_per_step\": 8,         # epoch per steps\n",
        "    \"steps_per_epoch\": 500,       # steps per epoch\n",
        "    \"n_epochs\": 20,               # number of epochs\n",
        "    \"batch_size\": 16,             # size of batch of obs to calculate grads\n",
        "\n",
        "    \"config_eval\": {\n",
        "      \"periods_per_epis\": 64,      # periods per episode\n",
        "      \"mc_draws\": 128,         # number of mc draws\n",
        "      \"simul_vol_scale\": 1,        # scale of volatility while simul\n",
        "      \"eval_n_epis\": 128,           # episodes to sample for eval\n",
        "    }\n",
        "}\n",
        "\n",
        "#create auxiliary config variables for readability\n",
        "config[\"periods_per_step\"] =config[\"periods_per_epis\"]*config[\"epis_per_step\"]\n",
        "config[\"n_batches\"] = config[\"periods_per_step\"]//config[\"batch_size\"]\n",
        "\n",
        "# PRINT AND PLOT KEY CONFIGS\n",
        "print(\"Number of parameters:\")\n",
        "print(NeuralNet(config[\"layers\"] + [Model().n_actions]).tabulate(\n",
        "    random.PRNGKey(0),\n",
        "    Model().initial_obs(random.PRNGKey(0))\n",
        "    ))\n",
        "\n",
        "print(\"TOTAL Number of steps (NN updates):\", config[\"steps_per_epoch\"]*config[\"n_epochs\"], \"episodes \\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CEAiCNRxC1AJ"
      },
      "source": [
        "# Create experiment\n",
        "Now we the entire experiment workflow as a function to call later."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def run_experiment(env, config):\n",
        "  \"\"\"Runs experiment.\"\"\"\n",
        "\n",
        "  n_cores = len(jax.devices())\n",
        "\n",
        "  # CREATE NN, RNGS, TRAIN_STATE AND EPOQUE UPDATE\n",
        "  nn = NeuralNet(config[\"layers\"] + [env.n_actions])\n",
        "  rng, rng_pol, rng_env, rng_epoch, rng_eval = random.split(random.PRNGKey(config[\"seed\"]), num=5)  # random number generator\n",
        "\n",
        "  # CREATE LR SCHEDULE\n",
        "  lr_schedule = optax.join_schedules(\n",
        "    schedules= [optax.constant_schedule(i) for i in config[\"lr_sch_values\"][:-1]]\n",
        "                  + [optax.warmup_cosine_decay_schedule(\n",
        "                    init_value=config[\"lr_sch_values\"][-1],\n",
        "                    peak_value=config[\"lr_sch_values\"][-1],\n",
        "                    warmup_steps=0,\n",
        "                    decay_steps=config[\"n_epochs\"]*config[\"steps_per_epoch\"]-config[\"lr_sch_transitions\"][-1],\n",
        "                    end_value=0.0000001,)],\n",
        "      boundaries=config[\"lr_sch_transitions\"] # the number of episodes at which to switch\n",
        "      )\n",
        "\n",
        "  # INITIALIZE OR RESTORE FULL NN TRAIN STATE\n",
        "  if not config[\"restore\"]:\n",
        "    params=nn.init(rng_pol, jnp.zeros_like(env.initial_obs(rng_env)))\n",
        "    train_state = TrainState.create(apply_fn=nn.apply, params=params, tx=optax.adam(lr_schedule))\n",
        "  else:\n",
        "    train_state_restored = checkpoints.restore_checkpoint(ckpt_dir=config[\"working_dir\"]+config[\"restore_run_name\"], target = None)\n",
        "    params = train_state_restored[\"params\"]\n",
        "    opt_state = train_state_restored[\"opt_state\"]\n",
        "    train_state = TrainState.create(apply_fn=nn.apply, params=params, tx=optax.adam(lr_schedule))\n",
        "    train_state.replace(opt_state=opt_state)\n",
        "\n",
        "  # GET TRAIN AND EVAL FUNCTIONS\n",
        "  train_epoch_fn  = jax.jit(get_epoch_train_fn(env, config))\n",
        "  eval_fn  = jax.jit(get_eval_fn(env, config))\n",
        "\n",
        "  # COMPILE CODE\n",
        "  time_start = time()\n",
        "  train_epoch_fn(train_state, rng_epoch)  # compiles\n",
        "  eval_fn(train_state, rng_epoch) # compiles\n",
        "  time_compilation = time() - time_start\n",
        "  print(\"Time Elapsed for Compilation:\", time_compilation, \"seconds\")\n",
        "\n",
        "  # RUN AN EPOCH TO GET TIME STATS\n",
        "  time_start = time()\n",
        "  train_epoch_fn(train_state, rng_epoch) # run one epoque\n",
        "  time_epoch = time() - time_start\n",
        "  print(\"Time Elapsed for epoch:\", time_epoch, \"seconds\")\n",
        "\n",
        "  time_start = time()\n",
        "  eval_fn(train_state, rng_epoch) # run one epoque\n",
        "  time_eval = time() - time_start\n",
        "  print(\"Time Elapsed for eval:\", time_eval, \"seconds\")\n",
        "\n",
        "  time_experiment = (time_epoch + time_eval)*config[\"n_epochs\"]/60\n",
        "  print(\"Estimated time for full experiment\", time_experiment, \"minutes\")\n",
        "\n",
        "  steps_per_second = config[\"steps_per_epoch\"]*config[\"periods_per_step\"]/time_epoch\n",
        "  print(\"Steps per second:\", steps_per_second, \"st/s\")\n",
        "\n",
        "  # CREATE LISTS TO STORE METRICS\n",
        "  mean_losses, mean_accuracy, min_accuracy = [], [], []\n",
        "\n",
        "  # RUN ALL THE EPOCHS\n",
        "  time_start = time()\n",
        "  for i in range(1,config[\"n_epochs\"]+1):\n",
        "\n",
        "    # run epoch\n",
        "    train_state, rng_epoch, epoch_metrics = train_epoch_fn(train_state, rng_epoch)\n",
        "    print('TRAINING:\\n',\n",
        "          'Iteration:', train_state.step,\n",
        "          \", Mean_loss:\", jnp.mean(epoch_metrics[:,0]),\n",
        "          \", Mean_accuracy:\", jnp.mean(epoch_metrics[:,1]),\n",
        "          \", Min_accuracy:\", jnp.min(epoch_metrics[:,2]),\n",
        "          \", Learning rate:\", lr_schedule(train_state.step),\n",
        "          \"\\n\"\n",
        "          )\n",
        "\n",
        "    # eval\n",
        "    eval_metrics = eval_fn(train_state, rng_eval)\n",
        "    print('EVALUATION:\\n',\n",
        "      'Iteration:', train_state.step,\n",
        "      \"Mean_loss:\", eval_metrics[0],\n",
        "      \", Mean Acc:\", eval_metrics[1],\n",
        "      \", Min Acc:\", eval_metrics[2],\n",
        "      \"\\n\")\n",
        "\n",
        "    # checkpoint\n",
        "    if train_state.step>1000 and float(eval_metrics[0])<min(mean_losses):\n",
        "      checkpoints.save_checkpoint(ckpt_dir=config['working_dir']+config['run_name'], target=train_state, step=train_state.step)\n",
        "\n",
        "    # store results\n",
        "    mean_losses.append(float(eval_metrics[0]))\n",
        "    mean_accuracy.append(float(eval_metrics[1]))\n",
        "    min_accuracy.append(float(eval_metrics[2]))\n",
        "\n",
        "    #end of inner loop\n",
        "\n",
        "\n",
        "  # PRINT RESULTS\n",
        "  print(\"Minimum loss attained in evaluation:\", min(mean_losses))\n",
        "  print(\"Maximum mean accuracy attained in evaluation:\", max(mean_accuracy))\n",
        "  print(\"Maximum min accuracy attained in evaluation:\", max(min_accuracy))\n",
        "  time_fullexp = (time() - time_start)/60\n",
        "  print(\"Time Elapsed for Full Experiment:\", time_fullexp, \"minutes\")\n",
        "\n",
        "  # STORE RESULTS\n",
        "  results = {\n",
        "    \"min_loss\":  min(mean_losses),\n",
        "    \"max_mean_acc\": max(mean_accuracy),\n",
        "    \"max_min_acc\": max(min_accuracy),\n",
        "    \"Time for Full Experiment (m)\": time_fullexp,\n",
        "    \"Time for epoch (s)\": time_epoch,\n",
        "    \"Time for Compilation (s)\": time_compilation,\n",
        "    \"Steps per second\": steps_per_second,\n",
        "    \"Losses_list\": mean_losses,\n",
        "    \"mean_accuracy_list\": mean_accuracy,\n",
        "    \"min_accuracy_list\": min_accuracy,\n",
        "    \"config\": config,\n",
        "  }\n",
        "\n",
        "  if not os.path.exists(config['working_dir']+config['run_name']):\n",
        "    os.mkdir(config['working_dir']+config['run_name'])\n",
        "  with open(config['working_dir']+config['run_name']+\"/results.json\", \"w\") as write_file:\n",
        "    json.dump(results, write_file)\n",
        "\n",
        "  # PLOT LEARNING\n",
        "\n",
        "  # Mean Losses\n",
        "  plt.plot([(i)*config[\"steps_per_epoch\"] for i in range(len(mean_losses))], mean_losses)\n",
        "  plt.xlabel('Steps (NN updates)')\n",
        "  plt.ylabel('Mean Losses')\n",
        "  plt.savefig(config['working_dir']+config['run_name']+'/mean_losses.jpg')\n",
        "  plt.close()\n",
        "\n",
        "  # Mean Accuracy\n",
        "  plt.plot([(i)*config[\"steps_per_epoch\"] for i in range(len(mean_accuracy))], mean_accuracy)\n",
        "  plt.xlabel('Steps (NN updates)')\n",
        "  plt.ylabel('Mean Accuracy (%)')\n",
        "  plt.savefig(config['working_dir']+config['run_name']+'/mean_accuracy.jpg')\n",
        "  plt.close()\n",
        "\n",
        "  # Min Accuracy\n",
        "  plt.plot([(i)*config[\"steps_per_epoch\"] for i in range(len(min_accuracy))], min_accuracy)\n",
        "  plt.xlabel('Steps (NN updates)')\n",
        "  plt.ylabel('Minimum Accuracy (%)')\n",
        "  plt.savefig(config['working_dir']+config['run_name']+'/min_accuracy.jpg')\n",
        "  plt.close()\n",
        "\n",
        "  # Learning rate schedule\n",
        "  plt.plot([i*config[\"steps_per_epoch\"] for i in range(len(mean_losses))], [lr_schedule(i*config[\"steps_per_epoch\"]) for i in range(len(mean_losses))])\n",
        "  plt.xlabel('Steps (NN updates)')\n",
        "  plt.ylabel('Learning Rate')\n",
        "  plt.savefig(config['working_dir']+config['run_name']+'/learning_rate.jpg')\n",
        "  plt.close()\n",
        "\n",
        "  return train_state"
      ],
      "metadata": {
        "id": "tw69_Ic-dcVr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run experiment\n",
        "*Finally*, we run the experiment abd get the trained parameter plus useful info."
      ],
      "metadata": {
        "id": "WdkzmdmHk_Il"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "awmY1xXgDOcU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74d6eaf8-d9b8-4b0c-b05b-2916557bbe81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time Elapsed for Compilation: 15.465006113052368 seconds\n",
            "Time Elapsed for epoch: 10.172770500183105 seconds\n",
            "Time Elapsed for eval: 0.34877800941467285 seconds\n",
            "Estimated time for full experiment 3.5071828365325928 minutes\n",
            "Steps per second: 12582.60962416247 st/s\n",
            "TRAINING:\n",
            " Iteration: 500 , Mean_loss: 0.00040228542213468436 , Mean_accuracy: 0.9938218751429517 , Min_accuracy: 0.6816197821813761 , Learning rate: 0.001 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 500 Mean_loss: 1.6218765270332445e-06 , Mean Acc: 0.999112837322851 , Min Acc: 0.9965883830197872 \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 1000 , Mean_loss: 1.5166081845247973e-06 , Mean_accuracy: 0.9990452089098902 , Min_accuracy: 0.9934833490317083 , Learning rate: 0.001 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 1000 Mean_loss: 1.0555975230374851e-06 , Mean Acc: 0.9992772661936953 , Min Acc: 0.9973315214974074 \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 1500 , Mean_loss: 1.265739740047699e-06 , Mean_accuracy: 0.9991184916118898 , Min_accuracy: 0.9956525469637831 , Learning rate: 0.001 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 1500 Mean_loss: 9.308622704565366e-07 , Mean Acc: 0.9993006788385077 , Min Acc: 0.9974891351215793 \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 2000 , Mean_loss: 1.3028202313858502e-06 , Mean_accuracy: 0.999103101502362 , Min_accuracy: 0.9954713664446367 , Learning rate: 0.001 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 2000 Mean_loss: 7.819046135910572e-07 , Mean Acc: 0.9993390327161995 , Min Acc: 0.9976394410554005 \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 2500 , Mean_loss: 1.159011970101636e-06 , Mean_accuracy: 0.9991505677686453 , Min_accuracy: 0.9955041602940476 , Learning rate: 0.001 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 2500 Mean_loss: 7.483978699303902e-07 , Mean Acc: 0.9993271054499484 , Min Acc: 0.9976593267738777 \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 3000 , Mean_loss: 1.3618400792530196e-06 , Mean_accuracy: 0.9990823865122344 , Min_accuracy: 0.9954242690866094 , Learning rate: 0.001 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 3000 Mean_loss: 1.03664100604396e-06 , Mean Acc: 0.9991773692738594 , Min Acc: 0.9975347620422663 \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 3500 , Mean_loss: 1.3169331644377111e-06 , Mean_accuracy: 0.9990927083125785 , Min_accuracy: 0.9963252076186364 , Learning rate: 0.001 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 3500 Mean_loss: 7.78963427165683e-07 , Mean Acc: 0.9993115356566268 , Min Acc: 0.9976652726946467 \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 4000 , Mean_loss: 1.440673270580852e-06 , Mean_accuracy: 0.9990510003623554 , Min_accuracy: 0.9957658692860084 , Learning rate: 0.001 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 4000 Mean_loss: 7.572092474197786e-07 , Mean Acc: 0.9993094182126867 , Min Acc: 0.9976783178396271 \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 4500 , Mean_loss: 1.5501541558113718e-06 , Mean_accuracy: 0.9990259588915791 , Min_accuracy: 0.9945617820319852 , Learning rate: 0.001 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 4500 Mean_loss: 6.059051906113383e-07 , Mean Acc: 0.9993921449616485 , Min Acc: 0.9978720988266909 \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 5000 , Mean_loss: 1.4972765266192662e-06 , Mean_accuracy: 0.9990345141587343 , Min_accuracy: 0.994343908102855 , Learning rate: 0.001 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 5000 Mean_loss: 4.886270182910521e-06 , Mean Acc: 0.9981709313491891 , Min Acc: 0.9952388925580795 \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 5500 , Mean_loss: 2.655155495351457e-06 , Mean_accuracy: 0.998771397033501 , Min_accuracy: 0.9911394715879223 , Learning rate: 0.0009755307053217621 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 5500 Mean_loss: 5.874984232780596e-07 , Mean Acc: 0.9993932068775495 , Min Acc: 0.9979672884110741 \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 6000 , Mean_loss: 1.963914633583976e-06 , Mean_accuracy: 0.9989274832961038 , Min_accuracy: 0.9935443061002637 , Learning rate: 0.000904518046337755 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 6000 Mean_loss: 7.026340557762194e-07 , Mean Acc: 0.9993304875919873 , Min Acc: 0.9978505354785198 \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 6500 , Mean_loss: 1.4790170494215146e-06 , Mean_accuracy: 0.9990453946350644 , Min_accuracy: 0.9946064788646819 , Learning rate: 0.000793913236883622 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 6500 Mean_loss: 1.093347174522143e-06 , Mean Acc: 0.9991563273884093 , Min Acc: 0.9973996725257043 \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 7000 , Mean_loss: 1.4764091271380697e-06 , Mean_accuracy: 0.9990479839115372 , Min_accuracy: 0.99502613051897 , Learning rate: 0.000654543046337755 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 7000 Mean_loss: 5.324042165906541e-07 , Mean Acc: 0.9994242198072067 , Min Acc: 0.99805705052434 \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 7500 , Mean_loss: 1.1087097774213359e-06 , Mean_accuracy: 0.9991625117532483 , Min_accuracy: 0.9965764190617401 , Learning rate: 0.00050005 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 7500 Mean_loss: 5.457065781769006e-07 , Mean Acc: 0.9994159307655768 , Min Acc: 0.9980350417542634 \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 8000 , Mean_loss: 1.119936544916549e-06 , Mean_accuracy: 0.9991591217440293 , Min_accuracy: 0.9961467139245069 , Learning rate: 0.00034555695366224516 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 8000 Mean_loss: 6.600898380544331e-07 , Mean Acc: 0.9993583991741705 , Min Acc: 0.9979285735854783 \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 8500 , Mean_loss: 9.90549636920039e-07 , Mean_accuracy: 0.9992065221173312 , Min_accuracy: 0.9974002088803403 , Learning rate: 0.0002061867631163781 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 8500 Mean_loss: 5.275839826797949e-07 , Mean Acc: 0.9994246279796054 , Min Acc: 0.9980748597008717 \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 9000 , Mean_loss: 9.450162574133321e-07 , Mean_accuracy: 0.9992250975197546 , Min_accuracy: 0.9970114289889666 , Learning rate: 9.558195366224507e-05 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 9000 Mean_loss: 5.132566330631634e-07 , Mean Acc: 0.9994306091454718 , Min Acc: 0.9981250172194258 \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 9500 , Mean_loss: 9.150196065344468e-07 , Mean_accuracy: 0.9992378108998724 , Min_accuracy: 0.9975016217494942 , Learning rate: 2.4569294678237992e-05 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 9500 Mean_loss: 4.820503217262202e-07 , Mean Acc: 0.9994496934181533 , Min Acc: 0.998180354039943 \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 10000 , Mean_loss: 9.051964037273122e-07 , Mean_accuracy: 0.9992407680996036 , Min_accuracy: 0.9957338597308342 , Learning rate: 1e-07 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 10000 Mean_loss: 4.688631412955199e-07 , Mean Acc: 0.9994574035151457 , Min Acc: 0.9981930051979163 \n",
            "\n",
            "Minimum loss attained in evaluation: 4.688631412955199e-07\n",
            "Maximum mean accuracy attained in evaluation: 0.9994574035151457\n",
            "Maximum min accuracy attained in evaluation: 0.9981930051979163\n",
            "Time Elapsed for Full Experiment: 3.5465205828348796 minutes\n"
          ]
        }
      ],
      "source": [
        "final_train_state = run_experiment(Model(), config)\n",
        "\n",
        "# DISCONNECT SESSION (uncomment next 2 lines if you do large run)\n",
        "# from google.colab import runtime\n",
        "# runtime.unassign()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Simulate with results"
      ],
      "metadata": {
        "id": "uCl6x_gesykv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CONFIG SIMUL FUNCTION\n",
        "config_simul = {\n",
        "    \"periods_per_epis\": 10000,      # periods\n",
        "    \"simul_vol_scale\": 1,\n",
        "\n",
        "    \"mc_draws\": 256,               # only applies if shock is continuous\n",
        "}\n",
        "\n",
        "# CREATE SIMUL FUNCTION\n",
        "def get_simul_fn(env, config):\n",
        "  episode_simul_fn = create_episode_simul_fn(env, config)\n",
        "  episode_loss_fn = create_episode_loss_fn(env, config)\n",
        "\n",
        "  def simul_fn(train_state, simul_rng):\n",
        "    \"\"\"Get obs for simul and then calculate loss function\"\"\"\n",
        "    simul_obs = episode_simul_fn(train_state, simul_rng)\n",
        "    loss, simul_metrics = episode_loss_fn(train_state.params, train_state, simul_obs, simul_rng)\n",
        "    return simul_obs, simul_metrics\n",
        "\n",
        "  return simul_fn\n",
        "\n",
        "# RUN SIMUL\n",
        "rng_simul = random.PRNGKey(1)\n",
        "env_simul = Model()\n",
        "simul_fn = jax.jit(get_simul_fn(env_simul, config_simul))\n",
        "simul_obs, simul_metrics = simul_fn(final_train_state, rng_simul)\n",
        "print(simul_metrics)\n",
        "# # GET STATISTICS\n",
        "obs_quantiles = jnp.quantile(simul_obs, jnp.array([0.1,0.25,0.5,0.75,0.9]), axis=0)\n",
        "acc_quantiles = jnp.quantile(simul_metrics[1], jnp.array([0.1,0.25,0.4, 0.75,0.9]))\n",
        "print('Observations Quantiles (10%,25%,50%,75%,90%)', obs_quantiles)\n",
        "print('Minimum Accuracy', jnp.min(simul_metrics[1]))\n",
        "print('Accuracies Quantiles (10%,25%,50%,75%,90%)', acc_quantiles)\n",
        "\n",
        "# HISTOGRAM OF ACCURACIES\n",
        "counts, bins = jnp.histogram(simul_metrics[1])\n",
        "freqs = counts/config_simul[\"periods_per_epis\"]\n",
        "fig = plt.figure()\n",
        "ax = fig.add_axes([0,0,1,1])\n",
        "ax.hist(bins[:-1], bins, weights=freqs)\n",
        "plt.xlabel('Accuracy')\n",
        "plt.ylabel('Frequency')\n",
        "# plt.show\n",
        "fig.savefig(config['working_dir']+config['run_name']+'/acurracy_hists.jpg', bbox_inches=\"tight\", pad_inches=1)\n"
      ],
      "metadata": {
        "id": "zdt21KpZs8B7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 786
        },
        "outputId": "9f278f23-b4cc-4826-f7a6-0606085ceb59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[3.30633661e-09 1.13429177e-06 1.17986610e-07 ... 8.93429474e-09\n",
            "  5.95990699e-08 1.37959386e-06]\n",
            " [9.99942499e-01 9.98934969e-01 9.99656508e-01 ... 9.99905479e-01\n",
            "  9.99755871e-01 9.98825439e-01]\n",
            " [9.99942499e-01 9.98934969e-01 9.99656508e-01 ... 9.99905479e-01\n",
            "  9.99755871e-01 9.98825439e-01]]\n",
            "Observations Quantiles (10%,25%,50%,75%,90%) [[-0.08291141 -0.05778573]\n",
            " [-0.04264142 -0.02934612]\n",
            " [ 0.00818631  0.00198456]\n",
            " [ 0.04973345  0.03295673]\n",
            " [ 0.08652259  0.06168493]]\n",
            "Minimum Accuracy 0.98872558000645\n",
            "Accuracies Quantiles (10%,25%,50%,75%,90%) [0.99847131 0.99901628 0.99929079 0.99972735 0.99989329]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate Accuracy of MC Estimation"
      ],
      "metadata": {
        "id": "aJDp4kuLHqyO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate montecarlo estimation of expectation\n",
        "env = Model()\n",
        "rng_mc = random.PRNGKey(0)\n",
        "params_test = final_train_state.params # Choose parameteres to test\n",
        "nn_policy_test = final_train_state.apply_fn\n",
        "\n",
        "def get_expectation_fn(nn_policy, params, env):\n",
        "  def expectation(n_draws, rng,  obs):\n",
        "    policy = nn_policy(params, obs)\n",
        "    mc_obs = env.mc_shocks(rng, mc_draws=n_draws)\n",
        "    mc_nextobs = jax.vmap(env.step, in_axes=(None, None,0))(obs, policy, mc_obs)\n",
        "    mc_nextpols = nn_policy(params,jnp.stack(mc_nextobs))\n",
        "    exp = jnp.mean(jax.vmap(env.expect_realization)(mc_nextobs, mc_nextpols))\n",
        "    return exp\n",
        "  return expectation\n",
        "\n",
        "rng_mc, *mc_rngs = jax.random.split(rng_mc, 100 + 1)\n",
        "\n",
        "# obs_list = list(obs_quantiles)\n",
        "obs_list = [env.initial_obs(rng_mc)]\n",
        "n_draws_list = [1,4,16,64,256]\n",
        "# n_draws_list = [500, 1000]\n",
        "rng_list =list(mc_rngs)\n",
        "\n",
        "mc_explist = {n_draws_list[i]: [] for i in range(len(n_draws_list))}\n",
        "mc_error = {f\"error_{n_draws_list[i]}_draws\": [] for i in range(len(n_draws_list))}\n",
        "for i in range(len(n_draws_list)):\n",
        "  for j in range(len(rng_list)):\n",
        "    for k in range(len(obs_list)):\n",
        "      # exp_jitted = jax.jit(get_expectation_fn(nn_forward, params, env)).lower(n_draws_list[i], rng_list[j], obs_list[k]).compile\n",
        "      mc_explist[n_draws_list[i]].append(get_expectation_fn(nn_policy_test, params_test, env)(n_draws_list[i], rng_list[j],  obs_list[k]))\n",
        "      # mc_eval[(i,j,k)] = exp_jitted(n_draws_list[i], rng_list[j],  obs_list[k])\n",
        "  mc_error[f\"error_{n_draws_list[i]}_draws\"] = jnp.std(jnp.array(mc_explist[n_draws_list[i]]))\n",
        "print(mc_error)\n",
        "\n",
        "error_list = [float(mc_error[f\"error_{n_draws_list[i]}_draws\"]) for i in range(len(n_draws_list))]\n",
        "print(error_list)\n",
        "n_drawsstr_list = [str(n_draws_list[i]) for i in range(len(n_draws_list))]\n",
        "fig = plt.figure()\n",
        "ax = fig.add_axes([0,0,1,1])\n",
        "ax.bar(n_drawsstr_list, error_list)\n",
        "plt.xlabel('Number of Montecarlo draws')\n",
        "plt.ylabel('Standard Deviation of expectations')\n",
        "# plt.show\n",
        "fig.savefig(config['working_dir']+config['run_name']+'/mc_eval.jpg', bbox_inches=\"tight\", pad_inches=1)\n"
      ],
      "metadata": {
        "id": "dq6XyondH93j",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        },
        "outputId": "6a20d39d-1c78-4f15-99d0-8ffecbcba4cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'error_1_draws': Array(0.00704697, dtype=float64), 'error_4_draws': Array(0.00326178, dtype=float64), 'error_16_draws': Array(0.00147381, dtype=float64), 'error_64_draws': Array(0.00092192, dtype=float64), 'error_256_draws': Array(0.00041204, dtype=float64)}\n",
            "[0.007046967244546932, 0.0032617806807877393, 0.0014738100183919987, 0.0009219225304782928, 0.0004120413640682382]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Impulse Responses"
      ],
      "metadata": {
        "id": "ZmnpWXEr-1sT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Impulse responses of dynare policy vs learned policy\n",
        "env = Model()\n",
        "\n",
        "ir_shocks = env.ir_shocks()\n",
        "print(\"shape of ir shocks:\", ir_shocks.shape)\n",
        "\n",
        "def ir(env, train_state, shocks):\n",
        "  def step(obs, shock):\n",
        "    policy = train_state.apply_fn(train_state.params, obs)\n",
        "    next_obs = env.step(obs, policy, shock)\n",
        "    obs_pol_pair = (obs,policy)\n",
        "    return next_obs, obs_pol_pair\n",
        "  obs_init = jnp.zeros_like(env.obs_ss)\n",
        "  final_obs, obs_pol_pairs = lax.scan(step, obs_init, shocks)\n",
        "  return final_obs, obs_pol_pairs\n",
        "\n",
        "ir_final_obs, ir_obs_pol_pairs = jax.vmap(ir, in_axes = (None,None,0))(env, final_train_state, ir_shocks)\n",
        "ir_obs, ir_policy = ir_obs_pol_pairs\n",
        "\n",
        "# PLOT\n",
        "ir_index = 0 # choose the IR exercise\n",
        "obs_index = 0 # choose the obs to plot\n",
        "obs_label = f\"Observation {obs_index}\" # create label\n",
        "policy_index = 0 # choose the policy to plot\n",
        "policy_label = f\"Policy {policy_index}\" # create label\n",
        "# plot obs\n",
        "plt.plot(list(range(40)), ir_obs[ir_index,:,obs_index], label =\"observation\")\n",
        "plt.savefig(config['working_dir']+config['run_name']+'/IRobs.jpg')\n",
        "plt.xlabel(\"Period\")\n",
        "plt.ylabel(obs_label)\n",
        "plt.show()\n",
        "#plot policy\n",
        "plt.plot(list(range(40)), ir_policy[0,:,policy_index], label =\"policy\")\n",
        "plt.savefig(config['working_dir']+config['run_name']+'/IRpolicy.jpg')\n",
        "plt.xlabel(\"Period\")\n",
        "plt.ylabel(policy_label)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "mmBJ9LxS-54A",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 902
        },
        "outputId": "63d96346-17a3-44e8-f33b-ecc65bbd6188"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape of ir shocks: (2, 40, 1)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test Results\n",
        "\n",
        "We will first test that the environment works as its supposed to. First, we check if the error in the steady state is 0 under the loglinear policy. for that, we will firsr create a function that calculates the loss in the steady state"
      ],
      "metadata": {
        "id": "v0Vb1mt4G-Id"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test 1: steady state"
      ],
      "metadata": {
        "id": "hIKEQKv2HtXS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test policies in steady state\n",
        "env = Model()\n",
        "params_test = final_train_state.params # Choose parameteres to test\n",
        "nn_policy_test = final_train_state.apply_fn\n",
        "rng_test = random.PRNGKey(1)\n",
        "\n",
        "# test steady state policies\n",
        "obs_init = env.initial_obs(rng_test)\n",
        "obs_ss = jnp.zeros_like(obs_init, dtype=jnp.float32)\n",
        "policy_ss = nn_policy_test(params_test, obs_ss) # nn_policy is the nn policy that comes from the training experiment\n",
        "print(\"Pretrain Policy in ss (should be ~ 1):\", policy_ss)\n",
        "\n",
        "# check that steady state policies takes a zero step\n",
        "shock_ss = jnp.array([0])\n",
        "obs_next_ss = env.step(obs_ss, policy_ss, shock_ss)\n",
        "print(\"Nex obs after ss policies (should be ~ 0):\", obs_next_ss)\n",
        "# print(\"Neural Net Gives 0 step in StSt?\",jnp.allclose(obs_next_ss, obs_ss, rtol=1e-02))\n",
        "print(\"Difference between next obs after applying nn_policy and stst\", obs_next_ss-obs_ss)\n",
        "\n",
        "# calculate expectation in StSt\n",
        "start = time()\n",
        "exp_ss = env.expect_realization(obs_ss, policy_ss)\n",
        "print(\"Expectation in SS:\", exp_ss)\n",
        "finish = time()\n",
        "print(f\"executing an expectation realization took {(finish-start)*1000} miliseconds\")\n",
        "\n",
        "# calculate loss in STST\n",
        "start = time()\n",
        "mean_loss, mean_accuracy, min_accuracy = env.loss(obs_ss,exp_ss, policy_ss)\n",
        "print(\"Mean Loss in SS:\", mean_loss, \"Mean accuracy in SS:\", mean_accuracy, \"Min. accuracy in SS:\", min_accuracy)\n",
        "finish = time()\n",
        "print(f\"executing the loss function {(finish-start)*1000} miliseconds\")\n"
      ],
      "metadata": {
        "id": "tMDHWyamqM8g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59496ecb-9d14-4392-e1d2-3b362750eb18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pretrain Policy in ss (should be ~ 1): [0.9985242]\n",
            "Nex obs after ss policies (should be ~ 0): [-4.4345856e-05  0.0000000e+00]\n",
            "Difference between next obs after applying nn_policy and stst [-4.4345856e-05  0.0000000e+00]\n",
            "Expectation in SS: 0.56312555\n",
            "executing an expectation realization took 41.3203239440918 miliseconds\n",
            "Mean Loss in SS: 1.4210855e-14 Mean accuracy in SS: 0.9999999 Min. accuracy in SS: 0.9999999\n",
            "executing the loss function 9.791135787963867 miliseconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test 2: step and loss function\n",
        "\n",
        "Now we test that the step function and loss function works correctly."
      ],
      "metadata": {
        "id": "duUIS9EaCIZo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "env = Model()\n",
        "rng_test = random.PRNGKey(0)\n",
        "params_test = final_train_state.params # Choose parameteres to test\n",
        "nn_policy_test = final_train_state.apply_fn\n",
        "# test envreset\n",
        "obs_init = env.initial_obs(rng_test)\n",
        "print(\"shape of initial obs:\", obs_init.shape)\n",
        "\n",
        "# test step\n",
        "shock = env.sample_shock(rng_test)\n",
        "policy = nn_policy_test(params_test, obs_init)\n",
        "obs_next = env.step(obs_init,policy,shock)\n",
        "print(\"shape of next obs\", obs_next.shape)\n",
        "\n",
        "# test expectation\n",
        "mc_shocks = env.mc_shocks(rng_test, config[\"mc_draws\"])\n",
        "mc_nextobs = jax.vmap(env.step, in_axes=(None, None,0))(obs_init, policy, mc_shocks)\n",
        "mc_nextpols = nn_policy_test(params_test,jnp.stack(mc_nextobs))\n",
        "exp = jnp.mean(jax.vmap(env.expect_realization)(mc_nextobs, mc_nextpols))\n",
        "print(\"shape of exp\", exp.shape)\n",
        "print(\"exp\", exp)\n",
        "\n",
        "#test loss\n",
        "mean_loss, mean_accuracy, min_accuracy  = env.loss(obs_init, exp, policy)\n",
        "print(\"Mean Loss in init obs:\", mean_loss, \"Mean accuracy in init obs:\", mean_accuracy, \"Min. accuracy in init obs:\", min_accuracy)\n",
        "\n"
      ],
      "metadata": {
        "id": "IRycSm2iCKKp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ed55136-e141-4684-d64d-3cb1be2422fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape of initial obs: (2,)\n",
            "shape of next obs (2,)\n",
            "shape of exp ()\n",
            "exp 0.53553444\n",
            "Mean Loss in init obs: 1.0706799e-08 Mean accuracy in init obs: 0.9998965 Min. accuracy in init obs: 0.9998965\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test 3: Simulating the environment (only states and policy, no loss)"
      ],
      "metadata": {
        "id": "3x-jPOefIMfa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Simulate env\n",
        "env = Model()\n",
        "params_test = final_train_state.params # Choose parameteres to test\n",
        "nn_policy_test = final_train_state.apply_fn\n",
        "rng_test = random.PRNGKey(1)\n",
        "obs_init = env.initial_obs(rng_test)\n",
        "\n",
        "def period_step_fn(obs, shock, nn_params):\n",
        "  policy = nn_policy_test(nn_params, obs)\n",
        "  obs_next = env.step(obs, policy, jnp.array([shock]))  # apply period steps for each row shock in shocks.\n",
        "  return obs_next, (obs_next, policy)\n",
        "\n",
        "n_periods = 1000000\n",
        "shocks = env.sample_shock(rng_test, n_draws=n_periods)\n",
        "period_step = jax.tree_util.Partial(period_step_fn, nn_params = params_test)\n",
        "start = time()\n",
        "obs_final, obs_policy_pair = lax.scan(period_step,obs_init,shocks)\n",
        "finish = time()\n",
        "print(f\"Simulating {n_periods} with only state evolution given policy took {(finish-start)} seconds\")\n",
        "\n",
        "obs, policy = obs_policy_pair\n",
        "print('mean for each state (should be ~ 0)')\n",
        "print(jnp.mean(obs,axis=0))\n",
        "print('std for each state (if normalized, should be ~ 1)')\n",
        "print(jnp.std(obs, axis=0))\n",
        "print('average policy', jnp.mean(policy,axis=0))"
      ],
      "metadata": {
        "id": "pPZz_th8ITA0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "142f0b04-14fa-4a0e-a044-3b29626da39b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Simulating 1000000 with only state evolution given policy took 0.28539276123046875 seconds\n",
            "mean for each state (should be ~ 0)\n",
            "[1.8740162e-04 8.0411519e-05]\n",
            "std for each state (if normalized, should be ~ 1)\n",
            "[0.03095767 0.02291827]\n",
            "average policy [1.0006654]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Analysis"
      ],
      "metadata": {
        "id": "WNY20VuEIGep"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now perform three analysis. First, we analyse business cycle frequencies and amplifications."
      ],
      "metadata": {
        "id": "X5eMjoQjINtM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Calculate fourier transform \"\"\"\n",
        "\n",
        "# simulate 100000 periods\n",
        "rng_test = random.PRNGKey(0)\n",
        "env = Model()\n",
        "n_periods = 1000000\n",
        "state_init = jnp.array(jnp.log(jax.random.uniform(rng_test,(2*env.n_sectors,),minval=0.9,maxval=1.1)))\n",
        "shocks = jax.random.multivariate_normal(rng_test, jnp.zeros((env.n_sectors,)), env.Sigma_A, shape=(n_periods,))\n",
        "_, state_policy_pairs = lax.scan(env.step,state_init,shocks)\n",
        "states, _ = state_policy_pairs\n",
        "print(states.shape) #check that last dimension is the time dimension\n",
        "fourier = jax.scipy.fft.dct(states)\n",
        "del states\n",
        "del shocks\n"
      ],
      "metadata": {
        "id": "rVIE1CZfIXOi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 548
        },
        "outputId": "b6b4cff7-3f6b-4cdf-de6b-c2a215a0e702"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnfilteredStackTrace\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-604d68dcc43d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mshocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultivariate_normal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrng_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_sectors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSigma_A\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_periods\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_policy_pairs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstate_init\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate_policy_pairs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/traceback_util.py\u001b[0m in \u001b[0;36mreraise_with_filtered_traceback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/lax/control_flow/loops.py\u001b[0m in \u001b[0;36mscan\u001b[0;34m(f, init, xs, length, reverse, unroll)\u001b[0m\n\u001b[1;32m    258\u001b[0m   \u001b[0;31m# necessary, a second time with modified init values.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m   \u001b[0minit_flat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcarry_avals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcarry_avals_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_tree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mrest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_create_jaxpr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m   \u001b[0mnew_init_flat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchanged\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_promote_weak_typed_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_flat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcarry_avals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcarry_avals_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/lax/control_flow/loops.py\u001b[0m in \u001b[0;36m_create_jaxpr\u001b[0;34m(init)\u001b[0m\n\u001b[1;32m    245\u001b[0m     jaxpr, consts, out_tree = _initial_style_jaxpr(\n\u001b[0;32m--> 246\u001b[0;31m         f, in_tree, (*carry_avals, *x_avals), \"scan\")\n\u001b[0m\u001b[1;32m    247\u001b[0m     \u001b[0mout_tree_children\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout_tree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/lax/control_flow/common.py\u001b[0m in \u001b[0;36m_initial_style_jaxpr\u001b[0;34m(fun, in_tree, in_avals, primitive_name)\u001b[0m\n\u001b[1;32m     60\u001b[0m   jaxpr, consts, out_tree = _initial_style_open_jaxpr(\n\u001b[0;32m---> 61\u001b[0;31m       fun, in_tree, in_avals, primitive_name)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0mclosed_jaxpr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mClosedJaxpr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_constvars_jaxpr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjaxpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/lax/control_flow/common.py\u001b[0m in \u001b[0;36m_initial_style_open_jaxpr\u001b[0;34m(fun, in_tree, in_avals, primitive_name)\u001b[0m\n\u001b[1;32m     53\u001b[0m   \u001b[0mdebug\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_tree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprimitive_name\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\"<unknown>\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m   \u001b[0mjaxpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_to_jaxpr_dynamic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_avals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mjaxpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/profiler.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mTraceAnnotation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mdecorator_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/interpreters/partial_eval.py\u001b[0m in \u001b[0;36mtrace_to_jaxpr_dynamic\u001b[0;34m(fun, in_avals, debug_info, keep_inputs)\u001b[0m\n\u001b[1;32m   1981\u001b[0m     jaxpr, out_avals, consts = trace_to_subjaxpr_dynamic(\n\u001b[0;32m-> 1982\u001b[0;31m       fun, main, in_avals, keep_inputs=keep_inputs, debug_info=debug_info)\n\u001b[0m\u001b[1;32m   1983\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/interpreters/partial_eval.py\u001b[0m in \u001b[0;36mtrace_to_subjaxpr_dynamic\u001b[0;34m(fun, main, in_avals, keep_inputs, debug_info)\u001b[0m\n\u001b[1;32m   1997\u001b[0m     \u001b[0min_tracers_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_tracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_inputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mkeep\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1998\u001b[0;31m     \u001b[0mans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0min_tracers_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1999\u001b[0m     \u001b[0mout_tracers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_raise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/linear_util.py\u001b[0m in \u001b[0;36mcall_wrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m       \u001b[0mans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnfilteredStackTrace\u001b[0m: TypeError: step() missing 1 required positional argument: 'shock'\n\nThe stack trace below excludes JAX-internal frames.\nThe preceding is the original exception that occurred, unmodified.\n\n--------------------",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-604d68dcc43d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mstate_init\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrng_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_sectors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mminval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmaxval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mshocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultivariate_normal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrng_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_sectors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSigma_A\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_periods\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_policy_pairs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstate_init\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate_policy_pairs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#check that last dimension is the time dimension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: step() missing 1 required positional argument: 'shock'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Obsolete"
      ],
      "metadata": {
        "id": "AxcdZawR-2L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# def loss(self, rng, state, policy_params):\n",
        "\n",
        "  #   # process state\n",
        "  #   state = state*self.states_sd\n",
        "  #   K = jnp.exp(state[:self.n_sectors]+self.states_ss[:self.n_sectors])\n",
        "  #   a = state[self.n_sectors:]+self.states_ss[self.n_sectors:]\n",
        "\n",
        "  #   # calculate the policy variables\n",
        "  #   policy = self.policy_fn(policy_params,state)\n",
        "  #   I = policy[:self.n_sectors]\n",
        "  #   Q = policy[self.n_sectors:2*self.n_sectors]\n",
        "  #   P = policy[2*self.n_sectors:3*self.n_sectors]\n",
        "  #   L = policy[3*self.n_sectors:]\n",
        "\n",
        "  #   #Rest of variables\n",
        "  #   A = jnp.exp(a)\n",
        "  #   Lagg = jnp.sum(L)  # Aggregate labor\n",
        "  #   Pagg = jnp.dot(jnp.transpose(self.xi),P**(1-self.sigma_c))**(1/(1-self.sigma_c)) # Agg price\n",
        "  #   Cagg = 1/Pagg  # Agg consumption\n",
        "  #   C = self.xi * (P/Pagg)**(-self.sigma_c) * Cagg  # Sectoral Consumption\n",
        "  #   Pm = (jnp.dot(jnp.transpose(self.Gamma_M),P**(1-self.sigma_m)))**(1/(1-self.sigma_m)) #  Interm. Price Index\n",
        "  #   M = self.mu * (Pm/P)**(-self.sigma_q) * Q  # Sectoral Intermediates\n",
        "  #   Mout = P**(-self.sigma_m) * jnp.dot(self.Gamma_M,Pm**(self.sigma_m)*M) # interm sold by sector\n",
        "  #   Pk = (jnp.dot(jnp.transpose(self.Gamma_I),P**(1-self.sigma_I)))**(1/(1-self.sigma_I)) #  Capital Price Index\n",
        "  #   Iout = P**(-self.sigma_I) * jnp.dot(self.Gamma_I,Pk**(self.sigma_I)*I) # New Capital sold by sector\n",
        "  #   Y = (A * (\n",
        "  #       self.alpha**(1/self.sigma_y)*K**((self.sigma_y-1)/self.sigma_y) +\n",
        "  #       (1-self.alpha)**(1/self.sigma_y)*L**((self.sigma_y-1)/self.sigma_y)\n",
        "  #       )**(self.sigma_y/(self.sigma_y-1)))\n",
        "\n",
        "  #   # Now we calculate the expectation term through montecarlo. We know K_next\n",
        "  #   K_next = (1-self.delta)*K + I  # get next K\n",
        "\n",
        "  #   # First, we get what is inside expectations for the realization of one shock\n",
        "  #   def exp_realization(shock):\n",
        "  #     # get next state\n",
        "  #     a_next = self.rho*a + shock\n",
        "  #     state_next = jnp.concatenate([jnp.log(K_next),a_next])-self.states_ss\n",
        "\n",
        "  #     #calculate policies\n",
        "  #     policy_next = self.policy_fn(policy_params,state_next)\n",
        "  #     I_next = policy_next[:self.n_sectors]\n",
        "  #     Q_next = policy_next[self.n_sectors:2*self.n_sectors]\n",
        "  #     P_next = policy_next[2*self.n_sectors:3*self.n_sectors]\n",
        "  #     L_next = policy_next[3*self.n_sectors:]\n",
        "\n",
        "  #     # Solve for the rest of the endogenous variables\n",
        "  #     A_next = jnp.exp(a_next)\n",
        "  #     Lagg = jnp.sum(L)\n",
        "  #     Pk_next = (jnp.dot(jnp.transpose(self.Gamma_I),P_next**(1-self.sigma_I)))**(1/(1-self.sigma_I))\n",
        "  #     Y_next = (A_next * (\n",
        "  #       self.alpha**(1/self.sigma_y)*K_next**((self.sigma_y-1)/self.sigma_y) +\n",
        "  #       (1-self.alpha)**(1/self.sigma_y)*L_next**((self.sigma_y-1)/self.sigma_y)\n",
        "  #       )**(self.sigma_y/(self.sigma_y-1)))\n",
        "\n",
        "  #     # Solve for the expectation term\n",
        "  #     exp_realization = (P_next*A_next**((self.sigma_y-1)/self.sigma_y) *\n",
        "  #       ((1-self.mu)*Q_next/Y_next)**(1/self.sigma_q) *\n",
        "  #       (self.alpha*Y_next/K_next)**(1/self.sigma_y) +\n",
        "  #       (1-self.delta)*Pk_next)\n",
        "  #     return exp_realization\n",
        "\n",
        "  #   # Now we calculate the expectation through montecarlo\n",
        "  #   def monte_carlo_exp(rng, mc_draws):\n",
        "  #     shocks = jax.random.multivariate_normal(rng, jnp.zeros((self.n_sectors,)), self.Sigma_A, shape=(mc_draws,))\n",
        "  #     exp = jnp.mean(jax.vmap(exp_realization)(shocks),axis=0)\n",
        "  #     return exp\n",
        "  #   # exp = monte_carlo_exp(rng, self.mc_draws)\n",
        "  #   # rng, *mc_rngs  = random.split(rng,self.n_mcs+1)\n",
        "  #   exp = monte_carlo_exp(rng,self.mc_draws)\n",
        "\n",
        "  #   # Calculate model implied Q\n",
        "  #   Qmod = ((\n",
        "  #       (1-self.mu)**(1/self.sigma_q)*Y**((self.sigma_q-1)/self.sigma_q) +\n",
        "  #       (self.mu)**(1/self.sigma_q)*M**((self.sigma_q-1)/self.sigma_q)\n",
        "  #       )**(self.sigma_q/(self.sigma_q-1)))\n",
        "\n",
        "  #   # Calculate right hand side of error eq for L\n",
        "  #   Lmod = (P*A**((self.sigma_y-1)/self.sigma_y) *\n",
        "  #     ((1-self.mu)*Q/Y)**(1/self.sigma_q) *\n",
        "  #     ((1-self.alpha)*Y/L)**(1/self.sigma_y))\n",
        "\n",
        "  #   Q_loss = Q / Qmod - 1\n",
        "  #   Pk_loss = Pk/(self.beta*exp) - 1\n",
        "  #   Market_loss = Q / (C+Mout+Iout) - 1\n",
        "  #   L_loss = Lagg**(1/self.eps_l)/Lmod - 1\n",
        "  #   loss = (jnp.sum(jnp.array([jnp.square(Q_loss),jnp.square(Pk_loss),jnp.square(Market_loss), jnp.square(L_loss)])))/self.n_actions\n",
        "\n",
        "  #   return lax.stop_gradient(loss)\n",
        "\n",
        "  # def expectation(self, rng, state, K_next, policy_params):\n",
        "  #   K = jnp.exp(state[:self.n_sectors]+self.states_ss[:self.n_sectors])\n",
        "  #   a = state[self.n_sectors:]\n",
        "\n",
        "  #   def exp_realization(shock):\n",
        "  #     # get next state\n",
        "  #     a_next = self.rho*a + shock\n",
        "  #     state_next = jnp.concatenate([jnp.log(K_next),a_next])-self.states_ss\n",
        "\n",
        "  #     #calculate policies\n",
        "  #     policy_next = self.policy_fn(policy_params,state_next)\n",
        "  #     I_next = policy_next[:self.n_sectors]\n",
        "  #     Q_next = policy_next[self.n_sectors:2*self.n_sectors]\n",
        "  #     P_next = policy_next[2*self.n_sectors:3*self.n_sectors]\n",
        "  #     L_next = policy_next[3*self.n_sectors:]\n",
        "\n",
        "  #     # Solve for the rest of the endogenous variables\n",
        "  #     A_next = jnp.exp(a_next)\n",
        "  #     Lagg = jnp.sum(L)\n",
        "  #     Pk_next = (jnp.dot(jnp.transpose(self.Gamma_I),P_next**(1-self.sigma_I)))**(1/(1-self.sigma_I))\n",
        "  #     Y_next = (A_next * (\n",
        "  #       self.alpha**(1/self.sigma_y)*K_next**((self.sigma_y-1)/self.sigma_y) +\n",
        "  #       (1-self.alpha)**(1/self.sigma_y)*L_next**((self.sigma_y-1)/self.sigma_y)\n",
        "  #       )**(self.sigma_y/(self.sigma_y-1)))\n",
        "\n",
        "  #     # Solve for the expectation term\n",
        "  #     exp_realization = (P_next*A_next**((self.sigma_y-1)/self.sigma_y) *\n",
        "  #       ((1-self.mu)*Q_next/Y_next)**(1/self.sigma_q) *\n",
        "  #       (self.alpha*Y_next/K_next)**(1/self.sigma_y) +\n",
        "  #       (1-self.delta)*Pk_next)\n",
        "  #     return exp_realization\n",
        "\n",
        "  #   shocks = jax.random.multivariate_normal(rng, jnp.zeros((self.n_sectors,)), self.Sigma_A, shape=(self.mc_draws,))\n",
        "  #   exp = jnp.mean(jax.vmap(exp_realization)(shocks), axis=0)\n",
        "  #   return exp"
      ],
      "metadata": {
        "id": "lXkrrPTm-4UR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Environment\n",
        "# class ProdNetRbc_SS():\n",
        "#   \"\"\"A JAX implementation of an RBC model with Production Networks.\"\"\"\n",
        "\n",
        "#   def __init__(self, params = params, states_ss=states_ss, policies_ss=policies_ss, states_sd = states_sd, policy_layers=[1024,1024]):\n",
        "\n",
        "#     self.alpha = params[\"alpha\"]\n",
        "#     self.beta = params[\"beta\"]\n",
        "#     self.delta = params[\"delta\"]\n",
        "#     self.rho = params[\"rho\"]\n",
        "#     self.eps_l = params[\"eps_l\"]\n",
        "#     self.sigma_c = params[\"sigma_c\"]\n",
        "#     self.sigma_m = params[\"sigma_m\"]\n",
        "#     self.sigma_q = params[\"sigma_q\"]\n",
        "#     self.sigma_y = params[\"sigma_y\"]\n",
        "#     self.sigma_I = params[\"sigma_I\"]\n",
        "#     self.xi = jnp.array(params[\"xi\"])\n",
        "#     self.mu = jnp.array(params[\"mu\"])\n",
        "#     self.Gamma_M = jnp.array(params[\"Gamma_M\"])\n",
        "#     self.Gamma_I = jnp.array(params[\"Gamma_I\"])\n",
        "#     self.n_sectors = params[\"n_sectors\"]\n",
        "#     self.states_ss = jnp.concatenate([states_ss,jnp.zeros(shape=(self.n_sectors,))])\n",
        "#     self.policies_ss = jnp.array(policies_ss)\n",
        "#     self.n_actions = 4*self.n_sectors\n",
        "#     self.states_sd = states_sd\n",
        "#   def initial_state(self):\n",
        "#     state_init = jnp.zeros(shape=(2*self.n_sectors,))\n",
        "#     return lax.stop_gradient(state_init)\n",
        "\n",
        "#   def step(self, state):\n",
        "#     state = state*self.states_sd\n",
        "#     K = jnp.exp(state[:self.n_sectors]+self.states_ss[:self.n_sectors])\n",
        "#     a = state[self.n_sectors:]\n",
        "#     policy = jnp.exp(self.policies_ss)\n",
        "#     K_next = (1-self.delta)*K + policy[:self.n_sectors]\n",
        "#     a_next = self.rho*a\n",
        "#     state_next = (jnp.concatenate([jnp.log(K_next),a_next])-self.states_ss)/self.states_sd\n",
        "#     # return lax.stop_gradient(state_next), lax.stop_gradient(state_next)\n",
        "#     return lax.stop_gradient(state_next)\n",
        "\n",
        "\n",
        "#   def loss(self, state):\n",
        "#     state = state*self.states_sd\n",
        "#     # process state\n",
        "#     K = jnp.exp(state[:self.n_sectors]+self.states_ss[:self.n_sectors])\n",
        "\n",
        "#     # calculate the policy variables\n",
        "#     policy = jnp.exp(self.policies_ss)\n",
        "#     I = policy[:self.n_sectors]\n",
        "#     Q = policy[self.n_sectors:2*self.n_sectors]\n",
        "#     P = policy[2*self.n_sectors:3*self.n_sectors]\n",
        "#     L = policy[3*self.n_sectors:]\n",
        "\n",
        "#     #Rest of variables\n",
        "#     Lagg = jnp.sum(L)  # Aggregate labor\n",
        "#     Pagg = jnp.dot(jnp.transpose(self.xi),P**(1-self.sigma_c))**(1/(1-self.sigma_c)) # Agg price\n",
        "#     Cagg = 1/Pagg  # Agg consumption\n",
        "#     C = self.xi * (P/Pagg)**(-self.sigma_c) * Cagg  # Sectoral Consumption\n",
        "#     Pm = (jnp.dot(jnp.transpose(self.Gamma_M),P**(1-self.sigma_m)))**(1/(1-self.sigma_m)) #  Interm. Price Index\n",
        "#     M = self.mu * (Pm/P)**(-self.sigma_q) * Q  # Sectoral Intermediates\n",
        "#     Mout = P**(-self.sigma_m) * jnp.dot(self.Gamma_M,Pm**(self.sigma_m)*M) # interm sold by sector\n",
        "#     Pk = (jnp.dot(jnp.transpose(self.Gamma_I),P**(1-self.sigma_I)))**(1/(1-self.sigma_I)) #  Capital Price Index\n",
        "#     Iout = P**(-self.sigma_I) * jnp.dot(self.Gamma_I,Pk**(self.sigma_I)*I) # New Capital sold by sector\n",
        "#     Y = (\n",
        "#         (\n",
        "#         self.alpha**(1/self.sigma_y)*K**((self.sigma_y-1)/self.sigma_y) +\n",
        "#         (1-self.alpha)**(1/self.sigma_y)*L**((self.sigma_y-1)/self.sigma_y)\n",
        "#         )**(self.sigma_y/(self.sigma_y-1)))\n",
        "\n",
        "#     print(Y)\n",
        "#     # Now we calculate the expectation term through montecarlo. We know K_next\n",
        "#     K_next = (1-self.delta)*K + I  # get next K\n",
        "#     exp = (\n",
        "#         P *\n",
        "#         ((1-self.mu)*Q/Y)**(1/self.sigma_q) *\n",
        "#         (self.alpha*Y/K_next)**(1/self.sigma_y) +\n",
        "#         (1-self.delta)*Pk\n",
        "#         )\n",
        "#     # Now we get what is inside expectations for each realization of the shock\n",
        "#     # def exp_realization():\n",
        "#     #   # a_next = self.rho*a\n",
        "#     #   # state_next = jnp.concatenate([jnp.log(K_next),a_next])-self.states_ss\n",
        "\n",
        "#     #   #calculate policies\n",
        "#     #   # policy_next = policy\n",
        "#     #   # I_next = policy_next[:self.n_sectors]\n",
        "#     #   # Q_next = policy_next[self.n_sectors:2*self.n_sectors]\n",
        "#     #   # P_next = policy_next[2*self.n_sectors:3*self.n_sectors]\n",
        "#     #   # L_next = policy_next[3*self.n_sectors:]\n",
        "\n",
        "#     #   # Solve for the rest of the endogenous variables\n",
        "#     #   # A_next = jnp.exp(a_next)\n",
        "#     #   # Lagg = jnp.sum(L)\n",
        "#     #   # Pk_next = (jnp.dot(jnp.transpose(Gamma_I),P_next**(1-self.sigma_I)))**(1/(1-self.sigma_I))\n",
        "#     #   # Y_next = (A_next * (\n",
        "#     #   #   self.alpha**(1/self.sigma_y)*K_next**((self.sigma_y-1)/self.sigma_y) +\n",
        "#     #   #   (1-self.alpha)**(1/self.sigma_y)*L_next**((self.sigma_y-1)/self.sigma_y)\n",
        "#     #   #   )**(self.sigma_y/(self.sigma_y-1)))\n",
        "\n",
        "#     #   # Solve for the expectation term\n",
        "#     #   # exp_realization = (P_next*A_next**((self.sigma_y-1)/self.sigma_y) *\n",
        "#     #   #   ((1-self.mu)*Q_next/Y_next)**(1/self.sigma_q) *\n",
        "#     #   #   (self.alpha*Y_next/K_next)**(1/self.sigma_y) +\n",
        "#     #   #   (1-self.delta)*Pk_next)\n",
        "#     #   exp_realization = (P*A**((self.sigma_y-1)/self.sigma_y) *\n",
        "#     #     ((1-self.mu)*Q/Y)**(1/self.sigma_q) *\n",
        "#     #     (self.alpha*Y/K_next)**(1/self.sigma_y) +\n",
        "#     #     (1-self.delta)*Pk)\n",
        "#     #   return exp_realization\n",
        "\n",
        "#     # Now we calculate the expectation\n",
        "\n",
        "#     # Calculate model implied Q\n",
        "#     Qmod = ((\n",
        "#         (1-self.mu)**(1/self.sigma_q)*Y**((self.sigma_q-1)/self.sigma_q) +\n",
        "#         (self.mu)**(1/self.sigma_q)*M**((self.sigma_q-1)/self.sigma_q)\n",
        "#         )**(self.sigma_q/(self.sigma_q-1)))\n",
        "\n",
        "#     # Calculate right hand side of error eq for L\n",
        "#     Lmod = (P *\n",
        "#       ((1-self.mu)*Q/Y)**(1/self.sigma_q) *\n",
        "#       ((1-self.alpha)*Y/L)**(1/self.sigma_y))\n",
        "\n",
        "#     Q_loss = Q / Qmod - 1\n",
        "#     Pk_loss = Pk/(self.beta*exp) - 1\n",
        "#     Market_loss = Q / (C+Mout+Iout) - 1\n",
        "#     L_loss = Lagg**(1/self.eps_l)/Lmod - 1\n",
        "#     loss = (jnp.sum(jnp.array([jnp.square(Q_loss),jnp.square(Pk_loss),jnp.square(Market_loss), jnp.square(L_loss)])))/self.n_actions\n",
        "\n",
        "#     return lax.stop_gradient(loss)"
      ],
      "metadata": {
        "id": "jrdME6CMJ0kp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_experiment(env, config):\n",
        "  \"\"\"Runs experiment.\"\"\"\n",
        "  cores_count = len(jax.devices())  # get available TPU cores.\n",
        "  nn_policy = NeuralNet(config[\"layers\"] + [env.n_actions])\n",
        "  optim = optax.adam(config[\"learning_rate\"])  # define optimiser.\n",
        "\n",
        "  rng, rng_e = random.split(random.PRNGKey(config[\"seed\"]), 2)  # prng keys.\n",
        "  dummy_obs = env.initial_obs(rng_e)  # dummy for net init.\n",
        "  params = params # initialise params.\n",
        "  nn_forward = nn_policy.apply\n",
        "  mean_loss = jnp.array([0.0]) # initialize loss\n",
        "  # mean_abs_loss = jnp.array([0.0]) # initialize loss\n",
        "  opt_state = optim.init(params)  # initialise optimiser stats.\n",
        "  learn = jax.jit(get_epoch_learner_fn(env, nn_forward, optim.update, config[\"batch_size\"], config[\"epoch_iters\"]))\n",
        "  # learn = jax.pmap(learn, axis_name='i')  # replicate over multiple cores.\n",
        "\n",
        "  #  broadcast = lambda x: jnp.broadcast_to(x, (cores_count, config[\"n_batches\"]) + x.shape)\n",
        "  # params = jax.tree_map(broadcast, params)  # broadcast to cores and batch.\n",
        "  # opt_state = jax.tree_map(broadcast, opt_state)  # broadcast to cores and batch\n",
        "  # mean_loss = jax.tree_map(broadcast, mean_loss)\n",
        "  # mean_abs_loss = jax.tree_map(broadcast, mean_abs_loss)\n",
        "\n",
        "  # rng, *env_rngs = jax.random.split(rng, cores_count * config[\"n_batches\"]+ 1)\n",
        "  # env_obs = jax.vmap(env.initial_obs)(jnp.stack(env_rngs))  # init envs.\n",
        "  # rng, *step_rngs = jax.random.split(rng, cores_count * config[\"n_batches\"] + 1)\n",
        "  # rng, *eval_rngs = jax.random.split(rng, cores_count * config[\"n_batches\"] + 1)\n",
        "  rng, env_rngs = jax.random.split(rng, cores_count * config[\"n_batches\"]+ 1)\n",
        "  env_obs = env.initial_obs(env_rngs)  # init envs.\n",
        "  rng, step_rngs = jax.random.split(rng, cores_count * config[\"n_batches\"] + 1)\n",
        "  rng, eval_rngs = jax.random.split(rng, cores_count * config[\"n_batches\"] + 1)\n",
        "\n",
        "  # reshape = lambda x: x.reshape((cores_count, config[\"n_batches\"]) + x.shape[1:])\n",
        "  # step_rngs = reshape(jnp.stack(step_rngs))  # add dimension to pmap over.\n",
        "  # eval_rngs = reshape(jnp.stack(eval_rngs))  # add dimension to pmap over.\n",
        "  # env_obs = reshape(env_obs)  # add dimension to pmap over.\n",
        "\n",
        "  mean_losses = []\n",
        "  mean_accuracy = []\n",
        "  num_steps = cores_count * config[\"epoch_iters\"] * config[\"batch_size\"] * config[\"n_batches\"]\n",
        "\n",
        "  with TimeIt(tag='COMPILATION'):\n",
        "    learn(params, opt_state, step_rngs, env_obs, mean_loss)  # compiles\n",
        "\n",
        "  #First run, we calculate periods per second\n",
        "  with TimeIt(tag='EXECUTION', steps=num_steps):\n",
        "    params, opt_state, step_rngs, env_obs, mean_loss = learn(\n",
        "        params, opt_state, step_rngs, env_obs, mean_loss)\n",
        "\n",
        "  #Rest of the runs\n",
        "  for i in range(2,config[\"n_epochs\"]+1):\n",
        "    rng, step_rngs = jax.random.split(rng, cores_count * config[\"n_batches\"] + 1)\n",
        "    # step_rngs = reshape(jnp.stack(step_rngs))\n",
        "    params, opt_state, step_rngs, env_obs, mean_loss = learn(\n",
        "        params, opt_state, step_rngs, env_obs, mean_loss)\n",
        "\n",
        "    mean_losses.append(jnp.mean(mean_loss))\n",
        "    # mean_accuracy.append((1- jnp.mean(mean_abs_loss))*100)\n",
        "\n",
        "    print('Iteration:', i*config[\"epoch_iters\"],\n",
        "          \", Mean_loss:\", jnp.mean(mean_loss),\n",
        "          \", Learning rate:\", config[\"learning_rate\"](i*config[\"epoch_iters\"]),\n",
        "          # \", Mean accuracy (%):\", (1- jnp.mean(mean_abs_loss))*100\n",
        "          )\n",
        "\n",
        "    if i%config[\"reset_env_nepochs\"]==0:\n",
        "      env_obs = jnp.zeros_like(env_obs)\n",
        "      print(\"ENV RESET\")\n",
        "\n",
        "  # Print best result\n",
        "  # print(\"Maximum accuracy attained in training:\", max(mean_accuracy))\n",
        "\n",
        "  #Checkpoint\n",
        "  checkpoints.save_checkpoint(ckpt_dir=config['working_dir']+config['run_name'], target=params, step=config[\"n_epochs\"]*config[\"epoch_iters\"])\n",
        "\n",
        "  # Plots\n",
        "  plt.plot([i for i in range(len(mean_losses[100:]))], mean_losses[100:])\n",
        "  plt.xlabel('Steps')\n",
        "  plt.ylabel('Mean Losses')\n",
        "  plt.savefig(config['working_dir']+config['run_name']+'/mean_losses.jpg')\n",
        "  plt.close()\n",
        "\n",
        "\n",
        "  return params, optim, nn_policy, mean_losses, mean_accuracy"
      ],
      "metadata": {
        "id": "gOC1kNvM92Bk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_epoch_learner_fn(\n",
        "    env, nn_forward, opt_update, batch_size, epoch_iters):\n",
        "  \"\"\"It runs and epoch with learing. This is what the compiler reads and parallelize (the minimal unit of computation).\"\"\"\n",
        "\n",
        "  def period_loss_fn(nn_params, loss_rng, env_obs):\n",
        "\n",
        "    # get rngs\n",
        "    loss_rng, mc_rng = random.split(loss_rng,2)\n",
        "\n",
        "    # Step the environemnt\n",
        "    period_shock = jax.random.multivariate_normal(loss_rng, jnp.zeros((env.n_sectors,)), env.Sigma_A/100)\n",
        "    policy = nn_forward(nn_params, env_obs)\n",
        "    obs_final = env.step(env_obs, policy, period_shock)  # apply period steps for each row shock in shocks.\n",
        "\n",
        "    # calculate exp\n",
        "    mc_shocks = jax.random.multivariate_normal(mc_rng, jnp.zeros((env.n_sectors,)), env.Sigma_A, shape=(200000,))\n",
        "    mc_nextobs = jax.vmap(env.step, in_axes=(None, None, 0))(env_obs, policy, mc_shocks)\n",
        "    del mc_shocks\n",
        "    mc_nextpols = nn_forward(nn_params,jnp.stack(mc_nextobs))\n",
        "    exp = jnp.mean(jax.vmap(env.exp_realization)(mc_nextobs, mc_nextpols))\n",
        "\n",
        "    loss = env.loss(env_obs, exp, policy)\n",
        "\n",
        "    return loss, (obs_final, jnp.array([loss]))\n",
        "\n",
        "  def update_fn(nn_params, opt_state, rng, env_obs, mean_loss):\n",
        "    \"\"\"Compute a gradient update from a single trajectory.\"\"\"\n",
        "    rng, loss_rng = random.split(rng,2)\n",
        "    grads, aux_info  = jax.grad(  # compute gradient on a single trajectory.\n",
        "        period_loss_fn, has_aux=True)(nn_params, loss_rng, env_obs)\n",
        "    new_env_obs, mean_loss = aux_info\n",
        "    # grads = lax.pmean(grads, axis_name='j')  # reduce mean (average grads) across cores.\n",
        "    # grads = lax.pmean(grads, axis_name='i')  # reduce mean (average grads) across batch.\n",
        "    updates, new_opt_state = opt_update(grads, opt_state)  # transform grads.\n",
        "    new_params = optax.apply_updates(nn_params, updates)  # update parameters.\n",
        "    return new_params, new_opt_state, rng, new_env_obs, mean_loss\n",
        "\n",
        "  # def learner_fn(params, opt_state, rngs, env_obs, mean_loss):\n",
        "  #   \"\"\"Vectorise and repeat the update.\"\"\"\n",
        "  #   batched_update_fn = jax.vmap(update_fn, axis_name='j')  # vectorize across batch.\n",
        "  #   def iterate_fn(_, val):  # repeat many times to avoid going back to Python.\n",
        "  #     params, opt_state, rngs, env_obs, mean_loss = val\n",
        "  #     return batched_update_fn(params, opt_state, rngs, env_obs, mean_loss)\n",
        "  #   return lax.fori_loop(0, epoch_iters, iterate_fn, (\n",
        "  #       params, opt_state, rngs, env_obs, mean_loss))\n",
        "\n",
        "  return update_fn"
      ],
      "metadata": {
        "id": "E5O7oVye_I7v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_epoch_update_fn(env, config):\n",
        "  \"\"\"It runs and epoch with learning. This is what the compiler reads and parallelize.\"\"\"\n",
        "\n",
        "  def sample_epis_obs(train_state, epis_rng):\n",
        "    \"sample obs of an episode\"\n",
        "    env_obs = env.initial_obs(epis_rng)\n",
        "    epis_rng, *period_rngs = random.split(epis_rng, config[\"periods_per_epis\"]+1)\n",
        "    def period_step(env_obs, period_rng):\n",
        "      policy = train_state.apply_fn(train_state.params, env_obs)                 # calculate policy\n",
        "      period_shock = env.sample_shock(period_rng)         # Sample next obs\n",
        "      obs_next = env.step(env_obs, policy, period_shock)  # apply period steps.\n",
        "      return obs_next, obs_next # we pass it two times because of the syntax of the lax.scan loop\n",
        "    _, epis_obs = lax.scan(period_step, env_obs, jnp.stack(period_rngs)) # we get the obs_batch\n",
        "    return epis_obs\n",
        "\n",
        "  def epis_loss_fn(params, nn_policy, epis_rng, obs_batch):\n",
        "    \"\"\"Loss function of an episode, which has periods_per_epis time periods.\"\"\"\n",
        "    epis_rng, *period_mc_rngs = random.split(epis_rng, config[\"periods_per_epis\"]+1)\n",
        "    policies_batch = nn_policy(params, obs_batch) # get the policies for the entire obs batch.\n",
        "\n",
        "    def period_loss(obs, policy, period_mc_rng):\n",
        "      \"\"\"Loss function for an individual period.\"\"\"\n",
        "      mc_shocks = env.mc_shocks(period_mc_rng, config[\"mc_draws\"])\n",
        "      mc_nextobs = jax.vmap(env.step, in_axes = (None,None,0))(obs, policy, mc_shocks)\n",
        "      mc_nextpols = nn_policy(params, mc_nextobs)\n",
        "      expect = jnp.mean(jax.vmap(env.expect_realization)(mc_nextobs, mc_nextpols))\n",
        "      mean_loss, mean_accuracy, min_accuracy = env.loss(obs, expect, policy) # calculate loss\n",
        "      return mean_loss, mean_accuracy, min_accuracy\n",
        "\n",
        "    # parallelize callculation of period_loss for the entire batch\n",
        "    mean_losses, mean_accuracies, min_accuracies = jax.vmap(period_loss)(obs_batch, policies_batch, jnp.stack(period_mc_rngs))\n",
        "    mean_loss = jnp.mean(mean_losses)                   # average accross periods\n",
        "    mean_accuracy = jnp.mean(mean_accuracies)           # average accross periods\n",
        "    min_accuracy = jnp.min(min_accuracies)              # min accross periods and across eqs within period\n",
        "    metrics = jnp.array([mean_loss, mean_accuracy, min_accuracy]) # pass as auxiliary info\n",
        "    return mean_loss, metrics\n",
        "\n",
        "  def epis_update_fn(train_state, epis_rng):\n",
        "    \"\"\"Compute a gradient update from a single episode.\"\"\"\n",
        "    epis_obs = sample_epis_obs(train_state, epis_rng)\n",
        "    grads, epis_metrics  = jax.grad(  # compute gradient on a single trajectory.\n",
        "        epis_loss_fn, has_aux=True)(train_state.params, train_state.apply_fn, epis_rng, epis_obs)\n",
        "    train_state = train_state.apply_gradients(grads=grads)\n",
        "    return train_state, epis_metrics\n",
        "\n",
        "  # def batch_update_fn(train_state, batch_rng):\n",
        "  #   \"\"\"Compute a gradient update from a single episode.\"\"\"\n",
        "  #   batch_rng, *epis_rng = random.split(batch_rng, config[\"epis_per_step\"]+1)\n",
        "  #   batch_obs = jax.vmap(sample_epis_obs, in_axes = (None,0))(train_state, jnp.stack(epis_rng))\n",
        "  #   grads, epis_metrics  = jax.grad(  # compute gradient on a single trajectory.\n",
        "  #       epis_loss_fn, has_aux=True)(train_state.params, train_state.apply_fn, epis_rng, batch_obs)\n",
        "  #   train_state = train_state.apply_gradients(grads=grads)\n",
        "  #   return train_state, epis_metrics\n",
        "\n",
        "  def epoch_update_fn(train_state, epoch_rng):\n",
        "    \"\"\"Vectorise and repeat the update to complete an epoch, made aout of steps_per_epoch episodes.\"\"\"\n",
        "    epoch_rng, *epis_rngs = random.split(epoch_rng, config[\"steps_per_epoch\"]+1)\n",
        "    train_state, epoch_metrics = lax.scan(epis_update_fn, train_state, jnp.stack(epis_rngs))\n",
        "    return train_state, epoch_rng, epoch_metrics\n",
        "\n",
        "  return epoch_update_fn"
      ],
      "metadata": {
        "id": "2qH550PbOd3K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-FGm6vTqXqzz"
      },
      "source": [
        "Create Training function\n",
        "No we define a function specifying an entire epoch of learning. This is the minimal unti lfo computation that we wil compile and pass to all the devices (devices are sunchronized to average gradients)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_epoch_update_fn(env, config):\n",
        "  \"\"\"It runs and epoch with learning. This is what the compiler reads and parallelize.\"\"\"\n",
        "\n",
        "  def sample_epis_obs(train_state, epis_rng):\n",
        "    \"sample obs of an episode\"\n",
        "    env_obs = env.initial_obs(epis_rng)\n",
        "    epis_rng, *period_rngs = random.split(epis_rng, config[\"periods_per_epis\"]+1)\n",
        "    def period_step(env_obs, period_rng):\n",
        "      policy = train_state.apply_fn(train_state.params, env_obs)                 # calculate policy\n",
        "      period_shock = config[\"simul_vol_scale\"]*env.sample_shock(period_rng)         # Sample next obs\n",
        "      obs_next = env.step(env_obs, policy, period_shock)  # apply period steps.\n",
        "      return obs_next, obs_next # we pass it two times because of the syntax of the lax.scan loop\n",
        "    _, epis_obs = lax.scan(period_step, env_obs, jnp.stack(period_rngs)) # we get the obs_batch\n",
        "    return epis_obs\n",
        "\n",
        "  def epis_loss_fn(params, nn_policy, epis_rng, obs_batch):\n",
        "    \"\"\"Loss function of an episode, which has periods_per_epis time periods.\"\"\"\n",
        "    epis_rng, *period_mc_rngs = random.split(epis_rng, config[\"periods_per_epis\"]+1)\n",
        "    policies_batch = nn_policy(params, obs_batch) # get the policies for the entire obs batch.\n",
        "\n",
        "    def period_loss(obs, policy, period_mc_rng):\n",
        "      \"\"\"Loss function for an individual period.\"\"\"\n",
        "      mc_shocks = env.mc_shocks(period_mc_rng, config[\"mc_draws\"])\n",
        "      mc_nextobs = jax.vmap(env.step, in_axes = (None,None,0))(obs, policy, mc_shocks)\n",
        "      mc_nextpols = nn_policy(params, mc_nextobs)\n",
        "      expect = jnp.mean(jax.vmap(env.expect_realization)(mc_nextobs, mc_nextpols))\n",
        "      mean_loss, mean_accuracy, min_accuracy = env.loss(obs, expect, policy) # calculate loss\n",
        "      return mean_loss, mean_accuracy, min_accuracy\n",
        "\n",
        "    # parallelize callculation of period_loss for the entire batch\n",
        "    mean_losses, mean_accuracies, min_accuracies = jax.vmap(period_loss)(obs_batch, policies_batch, jnp.stack(period_mc_rngs))\n",
        "    mean_loss = jnp.mean(mean_losses)                   # average accross periods\n",
        "    mean_accuracy = jnp.mean(mean_accuracies)           # average accross periods\n",
        "    min_accuracy = jnp.min(min_accuracies)              # min accross periods and across eqs within period\n",
        "    metrics = jnp.array([mean_loss, mean_accuracy, min_accuracy]) # pass as auxiliary info\n",
        "    return mean_loss, metrics\n",
        "\n",
        "  def step_loss_fn(params, nn_policy, epis_rng, step_obs):\n",
        "    mean_losses, step_metrics = jax.vmap(epis_loss_fn,in_axes = (None,None,0,0))(\n",
        "        params, nn_policy, jnp.stack(epis_rng), step_obs)\n",
        "    mean_loss = jnp.mean(mean_losses)\n",
        "    step_metrics = jnp.mean(step_metrics,axis=0)\n",
        "    return mean_loss, step_metrics\n",
        "\n",
        "  def step_update_fn(train_state, step_rng):\n",
        "    \"\"\"Compute a gradient update from a single episode.\"\"\"\n",
        "    step_rng, *epis_rng = random.split(step_rng, config[\"epis_per_step\"]+1)\n",
        "    step_obs = jax.vmap(sample_epis_obs, in_axes = (None,0))(train_state, jnp.stack(epis_rng))\n",
        "    grads, step_metrics  = jax.grad(step_loss_fn, has_aux=True)(\n",
        "        train_state.params, train_state.apply_fn, epis_rng, step_obs)\n",
        "    train_state = train_state.apply_gradients(grads=grads)\n",
        "    return train_state, step_metrics\n",
        "\n",
        "  def epoch_update_fn(train_state, epoch_rng):\n",
        "    \"\"\"Vectorise and repeat the update to complete an epoch, made aout of steps_per_epoch episodes.\"\"\"\n",
        "    epoch_rng, *step_rngs = random.split(epoch_rng, config[\"steps_per_epoch\"]+1)\n",
        "    train_state, epoch_metrics = lax.scan(step_update_fn, train_state, jnp.stack(step_rngs))\n",
        "    return train_state, epoch_rng, epoch_metrics\n",
        "\n",
        "  return epoch_update_fn"
      ],
      "metadata": {
        "id": "D4dBSMYfc327"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Fz-RH8Wt23Rz",
        "cygQcsHYIiDN",
        "1pceB-eSEbcG",
        "JYEia3OD-Lij",
        "wEG-xLNZQJLY",
        "hIKEQKv2HtXS",
        "duUIS9EaCIZo",
        "AxcdZawR-2L0"
      ],
      "toc_visible": true,
      "gpuClass": "premium",
      "gpuType": "T4",
      "mount_file_id": "1QW4LOfJ21C_dgXh3C3UXHawi1YgzYTjE",
      "authorship_tag": "ABX9TyNVOai1xAMfDe2dAgo9kSsb",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}