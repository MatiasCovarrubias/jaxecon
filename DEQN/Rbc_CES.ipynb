{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MatiasCovarrubias/jaxecon/blob/main/Rbc_CES.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmNe6o_4tTEy"
      },
      "source": [
        "# DEQN Solver in Jax: Prelims\n",
        "\n",
        "This notebook trains a neural net to output the optimal policy of a nonlinear Rbc model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ue0dX6Q14A1Q",
        "outputId": "981d443d-f643-45ac-e639-bdefc36276c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Apr 29 16:21:39 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   46C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n",
            "Cloning into 'jaxecon'...\n",
            "remote: Enumerating objects: 267, done.\u001b[K\n",
            "remote: Counting objects: 100% (5/5), done.\u001b[K\n",
            "remote: Compressing objects: 100% (5/5), done.\u001b[K\n",
            "remote: Total 267 (delta 0), reused 1 (delta 0), pack-reused 262\u001b[K\n",
            "Receiving objects: 100% (267/267), 234.16 KiB | 2.86 MiB/s, done.\n",
            "Resolving deltas: 100% (162/162), done.\n",
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# BACKEND RELATED: the default backend is CPU (change in Edit -> Notebook settings)\n",
        "GPU = True # set True if using GPU (only to see GPU)\n",
        "if GPU:\n",
        "  !nvidia-smi\n",
        "\n",
        "# precision\n",
        "from jax import numpy as jnp, lax, random, config\n",
        "double_precision = False\n",
        "if double_precision:\n",
        "  config.update(\"jax_enable_x64\", True)\n",
        "  precision = jnp.float64\n",
        "else:\n",
        "  precision = jnp.float32\n",
        "\n",
        "# Imports\n",
        "import matplotlib.pyplot as plt, flax.linen as nn, pandas as pd, jax, flax, optax, os, json\n",
        "from flax.training.train_state import TrainState  # Useful dataclass to keep train state\n",
        "from flax.training import checkpoints\n",
        "from jax.scipy.optimize import minimize\n",
        "from time import time\n",
        "from typing import Sequence\n",
        "config.update(\"jax_debug_nans\", True)\n",
        "\n",
        "! git clone https://github.com/MatiasCovarrubias/jaxecon\n",
        "import sys\n",
        "sys.path.insert(0,'/content/jaxecon')\n",
        "from DEQN.neural_nets.neural_nets import NeuralNet\n",
        "from DEQN.econ_models.rbc_ces import RbcCES_SteadyState, RbcCES\n",
        "from DEQN.algorithm.simulation import create_episode_simul_fn\n",
        "from DEQN.algorithm.loss import create_batch_loss_fn\n",
        "from DEQN.algorithm.epoch_train import create_epoch_train_fn\n",
        "from DEQN.algorithm.eval import create_eval_fn\n",
        "\n",
        "# Mount Google Drive to store results (a pop up will appear, follow instructions)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "working_dir = \"/content/drive/MyDrive/Jaxecon/RbcCES/Experiments/\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Econ model\n"
      ],
      "metadata": {
        "id": "uxCik716xRk1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set parameters\n",
        "\n",
        "beta=0.96\n",
        "alpha=0.4\n",
        "delta=0.07\n",
        "sigma_y=0.8\n",
        "eps_c=2\n",
        "eps_l=0.5\n",
        "rho=0.8\n",
        "phi=2\n",
        "shock_sd = 0.012\n",
        "\n",
        "# Find steady state and theta\n",
        "econ_model_ss = RbcCES_SteadyState(beta=beta, alpha=alpha, delta=delta, sigma_y=sigma_y, eps_c=eps_c, eps_l=eps_l)\n",
        "\n",
        "# initial_policy = jnp.array([1.4680072, 0.83242315,1.5301504, 0.07650742, 1, 1, 1.5444971, 2.434384])\n",
        "initial_policy = jnp.array([1.4185408, 0.43414843, 3.9100795, 0.27370563, 0.99999994, 0.9999998, 1.692247, 15.344204])\n",
        "\n",
        "@jax.jit\n",
        "def optimize_policy(initial_policy):\n",
        "    result = minimize(jax.jit(econ_model_ss.loss), initial_policy, method='BFGS')\n",
        "    return result.success, result.x, result.fun\n",
        "\n",
        "success, optimal_policy, optimal_loss = optimize_policy(initial_policy)\n",
        "print(\"success\", success)\n",
        "print(\"steady state\", optimal_policy)\n",
        "print(\"loss\", optimal_loss)\n",
        "\n",
        "policies_ss = jnp.log(optimal_policy[:7])\n",
        "print(\"policies_ss\", policies_ss)\n",
        "theta = optimal_policy[-1]\n",
        "print(\"theta\", theta)\n",
        "# create econ_model\n",
        "econ_model = RbcCES(policies_ss=policies_ss, theta=theta, beta=beta, alpha=alpha, delta=delta, sigma_y=sigma_y, eps_c=eps_c, eps_l=eps_l, rho=rho, phi=phi, shock_sd=shock_sd)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wgnaEMZhxNkX",
        "outputId": "55d2ee78-61f8-4906-9781-938f59c180b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "success True\n",
            "steady state [ 1.4185408   0.43414843  3.9100795   0.27370563  0.99999994  0.9999998\n",
            "  1.692247   15.344204  ]\n",
            "loss 2.7489122e-13\n",
            "policies_ss [ 3.4962878e-01 -8.3436882e-01  1.3635577e+00 -1.2957021e+00\n",
            " -5.9604645e-08 -1.7881395e-07  5.2605724e-01]\n",
            "theta 15.344204\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PlXarixBjTC2"
      },
      "source": [
        "# Configure experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3zWgbr0HjQua",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59b05c2c-18ea-4a29-8c2d-3395e23b8900"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of parameters:\n",
            "\n",
            "\u001b[3m                             NeuralNet Summary                              \u001b[0m\n",
            "┏━━━━━━━━━┳━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
            "┃\u001b[1m \u001b[0m\u001b[1mpath   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mmodule   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1minputs     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1moutputs    \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mparams                \u001b[0m\u001b[1m \u001b[0m┃\n",
            "┡━━━━━━━━━╇━━━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
            "│         │ NeuralNet │ \u001b[2mfloat32\u001b[0m[2]  │ \u001b[2mfloat32\u001b[0m[7]  │                        │\n",
            "├─────────┼───────────┼─────────────┼─────────────┼────────────────────────┤\n",
            "│ Dense_0 │ Dense     │ \u001b[2mfloat32\u001b[0m[2]  │ \u001b[2mfloat32\u001b[0m[16] │ bias: \u001b[2mfloat32\u001b[0m[16]      │\n",
            "│         │           │             │             │ kernel: \u001b[2mfloat32\u001b[0m[2,16]  │\n",
            "│         │           │             │             │                        │\n",
            "│         │           │             │             │ \u001b[1m48 \u001b[0m\u001b[1;2m(192 B)\u001b[0m             │\n",
            "├─────────┼───────────┼─────────────┼─────────────┼────────────────────────┤\n",
            "│ Dense_1 │ Dense     │ \u001b[2mfloat32\u001b[0m[16] │ \u001b[2mfloat32\u001b[0m[16] │ bias: \u001b[2mfloat32\u001b[0m[16]      │\n",
            "│         │           │             │             │ kernel: \u001b[2mfloat32\u001b[0m[16,16] │\n",
            "│         │           │             │             │                        │\n",
            "│         │           │             │             │ \u001b[1m272 \u001b[0m\u001b[1;2m(1.1 KB)\u001b[0m           │\n",
            "├─────────┼───────────┼─────────────┼─────────────┼────────────────────────┤\n",
            "│ Dense_2 │ Dense     │ \u001b[2mfloat32\u001b[0m[16] │ \u001b[2mfloat32\u001b[0m[7]  │ bias: \u001b[2mfloat32\u001b[0m[7]       │\n",
            "│         │           │             │             │ kernel: \u001b[2mfloat32\u001b[0m[16,7]  │\n",
            "│         │           │             │             │                        │\n",
            "│         │           │             │             │ \u001b[1m119 \u001b[0m\u001b[1;2m(476 B)\u001b[0m            │\n",
            "├─────────┼───────────┼─────────────┼─────────────┼────────────────────────┤\n",
            "│\u001b[1m \u001b[0m\u001b[1m       \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m         \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m           \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m      Total\u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m439 \u001b[0m\u001b[1;2m(1.8 KB)\u001b[0m\u001b[1m          \u001b[0m\u001b[1m \u001b[0m│\n",
            "└─────────┴───────────┴─────────────┴─────────────┴────────────────────────┘\n",
            "\u001b[1m                                                                            \u001b[0m\n",
            "\u001b[1m                       Total Parameters: 439 \u001b[0m\u001b[1;2m(1.8 KB)\u001b[0m\u001b[1m                       \u001b[0m\n",
            "\n",
            "\n",
            "TOTAL Number of steps (NN updates): 10000 episodes \n",
            "\n"
          ]
        }
      ],
      "source": [
        "'''Config dictionary'''\n",
        "\n",
        "# CREATE CONFIG DICT\n",
        "config = {\n",
        "    # general\n",
        "    \"seed\": 48,\n",
        "    \"exper_name\": \"Apr29_sigy08epsc2_test2\",\n",
        "    \"save_dir\": working_dir,\n",
        "    \"restore\": False,                                                            # True if start from restored checkpoint\n",
        "    \"restore_exper_name\": \"\",\n",
        "    \"seed\": 5,\n",
        "\n",
        "    # neural net\n",
        "    \"layers\": [16,16],              # layers of the NN\n",
        "\n",
        "    # learning rate schedule\n",
        "    \"lr_sch_values\": [0.001,0.001],                                        # values (from the last, we do cosine decay to 0)\n",
        "    \"lr_sch_transitions\": [2000],\n",
        "    \"lr_end_value\": 1e-7,\n",
        "\n",
        "    # simulation\n",
        "    \"periods_per_epis\": 32,\n",
        "    \"simul_vol_scale\": 1.5,        # scale of volatility while simul\n",
        "    \"init_range\": 10,\n",
        "\n",
        "    # loss calculation\n",
        "    \"mc_draws\": 16,               # monte-carlo draws\n",
        "\n",
        "    # training\n",
        "    \"epis_per_step\": 512,         # epoch per steps\n",
        "    \"steps_per_epoch\": 100,       # steps per epoch\n",
        "    \"n_epochs\": 100,               # number of epochs\n",
        "    \"batch_size\": 16,             # size of batch of obs to calculate grads\n",
        "    \"init_range\": 0,\n",
        "    \"checkpoint_frequency\": 1000,\n",
        "\n",
        "    \"config_eval\": {\n",
        "      \"periods_per_epis\": 64,      # periods per episode\n",
        "      \"mc_draws\": 128,         # number of mc draws\n",
        "      \"simul_vol_scale\": 1,        # scale of volatility while simul\n",
        "      \"eval_n_epis\": 128,           # episodes to sample for eval\n",
        "      \"init_range\": 0\n",
        "    }\n",
        "}\n",
        "\n",
        "#create auxiliary config variables for readability\n",
        "config[\"periods_per_step\"] =config[\"periods_per_epis\"]*config[\"epis_per_step\"]\n",
        "config[\"n_batches\"] = config[\"periods_per_step\"]//config[\"batch_size\"]\n",
        "\n",
        "# PRINT AND PLOT KEY CONFIGS\n",
        "print(\"Number of parameters:\")\n",
        "print(NeuralNet(config[\"layers\"] + [RbcCES().n_actions], precision).tabulate(\n",
        "    random.PRNGKey(0),\n",
        "    RbcCES(precision=precision).initial_obs(random.PRNGKey(0))\n",
        "    ))\n",
        "\n",
        "print(\"TOTAL Number of steps (NN updates):\", config[\"steps_per_epoch\"]*config[\"n_epochs\"], \"episodes \\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CEAiCNRxC1AJ"
      },
      "source": [
        "# Create experiment\n",
        "Now we create code for the entire experiment as a function to call later."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def run_experiment(econ_model, config):\n",
        "  \"\"\"Runs experiment.\"\"\"\n",
        "\n",
        "\n",
        "  # CREATE NN, RNGS, TRAIN_STATE AND EPOQUE UPDATE\n",
        "  nn = NeuralNet(features = config[\"layers\"] + [econ_model.n_actions], precision = precision)\n",
        "  rng, rng_pol, rng_econ_model, rng_epoch, rng_eval = random.split(random.PRNGKey(config[\"seed\"]), num=5)  # random number generator\n",
        "\n",
        "  # CREATE LR SCHEDULE\n",
        "  lr_schedule = optax.join_schedules(\n",
        "    schedules= [optax.constant_schedule(i) for i in config[\"lr_sch_values\"][:-1]]\n",
        "                  + [optax.warmup_cosine_decay_schedule(\n",
        "                    init_value=config[\"lr_sch_values\"][-1],\n",
        "                    peak_value=config[\"lr_sch_values\"][-1],\n",
        "                    warmup_steps=0,\n",
        "                    decay_steps=config[\"n_epochs\"]*config[\"steps_per_epoch\"]-config[\"lr_sch_transitions\"][-1],\n",
        "                    end_value=config[\"lr_end_value\"],)],\n",
        "      boundaries=config[\"lr_sch_transitions\"] # the number of episodes at which to switch\n",
        "      )\n",
        "\n",
        "  # INITIALIZE OR RESTORE FULL NN TRAIN STATE\n",
        "  if not config[\"restore\"]:\n",
        "    params=nn.init(rng_pol, jnp.zeros_like(econ_model.initial_obs(rng_econ_model)))\n",
        "    train_state = TrainState.create(apply_fn=nn.apply, params=params, tx=optax.adam(lr_schedule))\n",
        "  else:\n",
        "    train_state_restored = checkpoints.restore_checkpoint(ckpt_dir=config[\"working_dir\"]+config[\"restore_run_name\"], target = None)\n",
        "    params = train_state_restored[\"params\"]\n",
        "    opt_state = train_state_restored[\"opt_state\"]\n",
        "    train_state = TrainState.create(apply_fn=nn.apply, params=params, tx=optax.adam(lr_schedule))\n",
        "    train_state.replace(opt_state=opt_state)\n",
        "\n",
        "  # GET TRAIN AND EVAL FUNCTIONS\n",
        "  simul_fn = jax.jit(create_episode_simul_fn(econ_model,config))\n",
        "  loss_fn = jax.jit(create_batch_loss_fn(econ_model,config))\n",
        "  train_epoch_fn  = jax.jit(create_epoch_train_fn(econ_model, config, simul_fn, loss_fn))\n",
        "  eval_fn  = jax.jit(create_eval_fn(config, simul_fn, loss_fn))\n",
        "\n",
        "  # COMPILE CODE\n",
        "  time_start = time()\n",
        "  train_epoch_fn(train_state, rng_epoch)  # compiles\n",
        "  eval_fn(train_state, rng_epoch) # compiles\n",
        "  time_compilation = time() - time_start\n",
        "  print(\"Time Elapsed for Compilation:\", time_compilation, \"seconds\")\n",
        "\n",
        "  # RUN AN EPOCH TO GET TIME STATS\n",
        "  time_start = time()\n",
        "  train_epoch_fn(train_state, rng_epoch) # run one epoque\n",
        "  time_epoch = time() - time_start\n",
        "  print(\"Time Elapsed for epoch:\", time_epoch, \"seconds\")\n",
        "\n",
        "  time_start = time()\n",
        "  eval_fn(train_state, rng_epoch) # run one epoque\n",
        "  time_eval = time() - time_start\n",
        "  print(\"Time Elapsed for eval:\", time_eval, \"seconds\")\n",
        "\n",
        "  time_experiment = (time_epoch + time_eval)*config[\"n_epochs\"]/60\n",
        "  print(\"Estimated time for full experiment\", time_experiment, \"minutes\")\n",
        "\n",
        "  steps_per_second = config[\"steps_per_epoch\"]*config[\"periods_per_step\"]/time_epoch\n",
        "  print(\"Steps per second:\", steps_per_second, \"st/s\")\n",
        "\n",
        "  # CREATE LISTS TO STORE METRICS\n",
        "  mean_losses, max_losses, mean_accuracy, min_accuracy = [], [], [], []\n",
        "\n",
        "  # RUN ALL THE EPOCHS\n",
        "  time_start = time()\n",
        "  for i in range(1,config[\"n_epochs\"]+1):\n",
        "\n",
        "    # eval\n",
        "    eval_metrics = eval_fn(train_state, rng_eval)\n",
        "    print('EVALUATION:\\n',\n",
        "      'Iteration:', train_state.step,\n",
        "      \"Mean Loss:\", eval_metrics[0],\n",
        "      \", Max Loss:\", eval_metrics[1],\n",
        "      \", Mean Acc:\", eval_metrics[2],\n",
        "      \", Min Acc:\", eval_metrics[3], \"\\n\"\n",
        "      \", Mean Accs Foc\", eval_metrics[4], \"\\n\"\n",
        "      \", Min Accs Foc:\", eval_metrics[5],\n",
        "      \"\\n\")\n",
        "\n",
        "    # run epoch\n",
        "    train_state, rng_epoch, epoch_metrics = train_epoch_fn(train_state, rng_epoch)\n",
        "    print('TRAINING:\\n',\n",
        "          'Iteration:', train_state.step,\n",
        "          \", Mean Loss:\", jnp.mean(epoch_metrics[0]),\n",
        "          \", Max Loss:\", jnp.mean(epoch_metrics[1]),\n",
        "          \", Mean Acc:\", jnp.mean(epoch_metrics[2]),\n",
        "          \", Min Acc:\", jnp.min(epoch_metrics[3]),\n",
        "          \", Learning rate:\", lr_schedule(train_state.step),\n",
        "          \"\\n\"\n",
        "          )\n",
        "\n",
        "    # checkpoint\n",
        "    if train_state.step>=config[\"checkpoint_frequency\"] and train_state.step%config[\"checkpoint_frequency\"]==0:\n",
        "      checkpoints.save_checkpoint(ckpt_dir=config['save_dir']+config['exper_name'], target=train_state, step=train_state.step)\n",
        "\n",
        "      # store results\n",
        "      mean_losses.append(float(eval_metrics[0]))\n",
        "      max_losses.append(float(eval_metrics[1]))\n",
        "      mean_accuracy.append(float(eval_metrics[2]))\n",
        "      min_accuracy.append(float(eval_metrics[3]))\n",
        "\n",
        "    #end of inner loop\n",
        "\n",
        "  # PRINT RESULTS\n",
        "  print(\"Minimum mean loss attained in evaluation:\", min(mean_losses))\n",
        "  print(\"Minimum max loss attained in evaluation:\", min(max_losses))\n",
        "  print(\"Maximum mean accuracy attained in evaluation:\", max(mean_accuracy))\n",
        "  print(\"Maximum min accuracy attained in evaluation:\", max(min_accuracy))\n",
        "  time_fullexp = (time() - time_start)/60\n",
        "  print(\"Time Elapsed for Full Experiment:\", time_fullexp, \"minutes\")\n",
        "\n",
        "  # STORE RESULTS\n",
        "  results = {\n",
        "    \"exper_name\": config[\"exper_name\"],\n",
        "    \"min_mean_loss\":  min(mean_losses),\n",
        "    \"min_max_loss\": max(max_losses),\n",
        "    \"max_mean_acc\": max(mean_accuracy),\n",
        "    \"max_min_acc\": max(min_accuracy),\n",
        "    \"time_full_exp_minutes\": time_fullexp,\n",
        "    \"time_epoque_seconds\": time_epoch,\n",
        "    \"time_compilation_seconds\": time_compilation,\n",
        "    \"steps_per_second\": steps_per_second,\n",
        "    \"config\": config,\n",
        "    \"mean_losses_list\": mean_losses,\n",
        "    \"max_losses_list\": max_losses,\n",
        "    \"mean_acc_list\": mean_accuracy,\n",
        "    \"min_acc_list\": min_accuracy,\n",
        "  }\n",
        "\n",
        "  # store to json\n",
        "  if not os.path.exists(config['save_dir']+config['exper_name']):\n",
        "    os.mkdir(config['save_dir']+config['exper_name'])\n",
        "  with open(config['save_dir']+config['exper_name']+\"/results.json\", \"w\") as write_file:\n",
        "    json.dump(results, write_file)\n",
        "\n",
        "  # PLOT LEARNING\n",
        "\n",
        "  # Mean Losses\n",
        "  plt.plot([(i+1)*config[\"checkpoint_frequency\"] for i in range(len(mean_losses))], mean_losses)\n",
        "  plt.xlabel('Steps (NN updates)')\n",
        "  plt.ylabel('Mean Losses')\n",
        "  plt.savefig(config['save_dir']+config['exper_name']+'/mean_losses.jpg')\n",
        "  plt.close()\n",
        "\n",
        "  plt.plot([(i+1)*config[\"checkpoint_frequency\"] for i in range(len(max_losses))], max_losses)\n",
        "  plt.xlabel('Steps (NN updates)')\n",
        "  plt.ylabel('Max Losses')\n",
        "  plt.savefig(config['save_dir']+config['exper_name']+'/max_losses.jpg')\n",
        "  plt.close()\n",
        "\n",
        "  # Mean Accuracy\n",
        "  plt.plot([(i+1)*config[\"checkpoint_frequency\"] for i in range(len(mean_accuracy))], mean_accuracy)\n",
        "  plt.xlabel('Steps (NN updates)')\n",
        "  plt.ylabel('Mean Accuracy (%)')\n",
        "  plt.savefig(config['save_dir']+config['exper_name']+'/mean_accuracy.jpg')\n",
        "  plt.close()\n",
        "\n",
        "  # Min Accuracy\n",
        "  plt.plot([(i+1)*config[\"checkpoint_frequency\"] for i in range(len(min_accuracy))], min_accuracy)\n",
        "  plt.xlabel('Steps (NN updates)')\n",
        "  plt.ylabel('Minimum Accuracy (%)')\n",
        "  plt.savefig(config['save_dir']+config['exper_name']+'/min_accuracy.jpg')\n",
        "  plt.close()\n",
        "\n",
        "  # Learning rate schedule\n",
        "  plt.plot([(i+1)*config[\"checkpoint_frequency\"] for i in range(len(mean_losses))], [lr_schedule((i+1)*config[\"checkpoint_frequency\"]) for i in range(len(mean_losses))])\n",
        "  plt.xlabel('Steps (NN updates)')\n",
        "  plt.ylabel('Learning Rate')\n",
        "  plt.savefig(config['save_dir']+config['exper_name']+'/learning_rate.jpg')\n",
        "  plt.close()\n",
        "\n",
        "  return train_state"
      ],
      "metadata": {
        "id": "tw69_Ic-dcVr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run experiment\n",
        "*Finally*, we run the experiment abd get the trained parameter plus useful info."
      ],
      "metadata": {
        "id": "WdkzmdmHk_Il"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "awmY1xXgDOcU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2117008-0e2f-4c18-b956-12fe8dff388c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time Elapsed for Compilation: 7.196796178817749 seconds\n",
            "Time Elapsed for epoch: 0.43602943420410156 seconds\n",
            "Time Elapsed for eval: 0.004654645919799805 seconds\n",
            "Estimated time for full experiment 0.734473466873169 minutes\n",
            "Steps per second: 3757544.494652348 st/s\n",
            "EVALUATION:\n",
            " Iteration: 0 Mean Loss: 0.06026687 , Max Loss: 0.30910265 , Mean Acc: 0.8561336 , Min Acc: 0.44403 \n",
            ", Mean Accs Foc [0.6703282  0.44684172 0.9988658  0.98591715 0.9219183  0.99184406\n",
            " 0.97721964] \n",
            ", Min Accs Foc: [0.6637243  0.44403    0.9957547  0.9788212  0.9150042  0.98178875\n",
            " 0.90426517] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 100 , Mean Loss: 0.018283157 , Max Loss: 0.08410748 , Mean Acc: 0.9092288 , Min Acc: 0.44392508 , Learning rate: 0.001 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 100 Mean Loss: 0.0019157501 , Max Loss: 0.022412835 , Mean Acc: 0.9616962 , Min Acc: 0.85029083 \n",
            ", Mean Accs Foc [0.9307724  0.9763952  0.95801115 0.9513951  0.9565556  0.9855508\n",
            " 0.9731928 ] \n",
            ", Min Accs Foc: [0.85029083 0.9494076  0.9401856  0.90553766 0.9524159  0.97093016\n",
            " 0.91694146] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 200 , Mean Loss: 0.0006371048 , Max Loss: 0.0042265384 , Mean Acc: 0.98022383 , Min Acc: 0.82682437 , Learning rate: 0.001 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 200 Mean Loss: 0.0003441497 , Max Loss: 0.0049940734 , Mean Acc: 0.9863398 , Min Acc: 0.92933124 \n",
            ", Mean Accs Foc [0.991156   0.9966868  0.9640679  0.99497175 0.99546427 0.97990835\n",
            " 0.98212314] \n",
            ", Min Accs Foc: [0.9434265  0.98394614 0.9594061  0.9579115  0.9839519  0.9677695\n",
            " 0.92933124] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 300 , Mean Loss: 0.00031956178 , Max Loss: 0.0024578255 , Mean Acc: 0.9869821 , Min Acc: 0.88240045 , Learning rate: 0.001 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 300 Mean Loss: 0.00029955117 , Max Loss: 0.006022186 , Mean Acc: 0.9874022 , Min Acc: 0.92239726 \n",
            ", Mean Accs Foc [0.99525744 0.99576074 0.96774495 0.9972054  0.9932389  0.98204815\n",
            " 0.9805597 ] \n",
            ", Min Accs Foc: [0.9578863  0.98939157 0.964025   0.9640293  0.97241545 0.97247803\n",
            " 0.92239726] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 400 , Mean Loss: 0.00027478018 , Max Loss: 0.0024433979 , Mean Acc: 0.987948 , Min Acc: 0.8813494 , Learning rate: 0.001 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 400 Mean Loss: 0.00025399233 , Max Loss: 0.005422251 , Mean Acc: 0.98842084 , Min Acc: 0.92636406 \n",
            ", Mean Accs Foc [0.9962492  0.99648476 0.97116995 0.9969582  0.99295986 0.9840106\n",
            " 0.9811137 ] \n",
            ", Min Accs Foc: [0.96553177 0.98449886 0.96841323 0.968649   0.9720341  0.9631009\n",
            " 0.92636406] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 500 , Mean Loss: 0.00023136628 , Max Loss: 0.0023635768 , Mean Acc: 0.98892784 , Min Acc: 0.89322865 , Learning rate: 0.001 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 500 Mean Loss: 0.00021379441 , Max Loss: 0.004908247 , Mean Acc: 0.98932934 , Min Acc: 0.9299411 \n",
            ", Mean Accs Foc [0.99544454 0.99565506 0.9753219  0.99692523 0.9935758  0.98640007\n",
            " 0.9819826 ] \n",
            ", Min Accs Foc: [0.9673047 0.9774085 0.9723769 0.9738989 0.9740794 0.9454216 0.9299411] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 600 , Mean Loss: 0.00019602686 , Max Loss: 0.0024946332 , Mean Acc: 0.9898546 , Min Acc: 0.884458 , Learning rate: 0.001 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 600 Mean Loss: 0.00018247342 , Max Loss: 0.004592725 , Mean Acc: 0.99017584 , Min Acc: 0.93223035 \n",
            ", Mean Accs Foc [0.9950713  0.9952931  0.97877836 0.9965987  0.9939047  0.9890039\n",
            " 0.98258066] \n",
            ", Min Accs Foc: [0.9613389  0.97478795 0.974859   0.97341    0.9750658  0.94020486\n",
            " 0.93223035] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 700 , Mean Loss: 0.00016392775 , Max Loss: 0.0022833832 , Mean Acc: 0.99071366 , Min Acc: 0.8992619 , Learning rate: 0.001 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 700 Mean Loss: 0.00014898248 , Max Loss: 0.0044928147 , Mean Acc: 0.99111974 , Min Acc: 0.93297154 \n",
            ", Mean Accs Foc [0.9946748  0.99499524 0.98269403 0.99710625 0.9944024  0.9908478\n",
            " 0.98311734] \n",
            ", Min Accs Foc: [0.96237123 0.975919   0.97822857 0.98387814 0.9759184  0.94342566\n",
            " 0.93297154] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 800 , Mean Loss: 0.00012856099 , Max Loss: 0.001996519 , Mean Acc: 0.991762 , Min Acc: 0.89797115 , Learning rate: 0.001 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 800 Mean Loss: 0.00010998073 , Max Loss: 0.0041857595 , Mean Acc: 0.9923374 , Min Acc: 0.93530256 \n",
            ", Mean Accs Foc [0.99395454 0.99517405 0.9876268  0.9973692  0.9945091  0.99296093\n",
            " 0.98476696] \n",
            ", Min Accs Foc: [0.9649322  0.98433566 0.9807759  0.9876667  0.97705996 0.9520484\n",
            " 0.93530256] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 900 , Mean Loss: 8.579608e-05 , Max Loss: 0.0014098511 , Mean Acc: 0.99319744 , Min Acc: 0.9088233 , Learning rate: 0.001 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 900 Mean Loss: 6.350853e-05 , Max Loss: 0.0020372132 , Mean Acc: 0.99389184 , Min Acc: 0.9548645 \n",
            ", Mean Accs Foc [0.9938538  0.9954706  0.9933318  0.9968173  0.9954311  0.99275506\n",
            " 0.9895828 ] \n",
            ", Min Accs Foc: [0.9734368  0.9795605  0.98380905 0.98619723 0.9788985  0.9660858\n",
            " 0.9548645 ] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 1000 , Mean Loss: 4.353612e-05 , Max Loss: 0.00059863337 , Mean Acc: 0.99506885 , Min Acc: 0.9289414 , Learning rate: 0.001 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 1000 Mean Loss: 3.7856676e-05 , Max Loss: 0.00140898 , Mean Acc: 0.99559873 , Min Acc: 0.9624636 \n",
            ", Mean Accs Foc [0.99758923 0.9980664  0.9898364  0.997001   0.99778336 0.9915614\n",
            " 0.9973531 ] \n",
            ", Min Accs Foc: [0.98736894 0.98451996 0.9851969  0.984548   0.98570997 0.9624636\n",
            " 0.9840411 ] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 1100 , Mean Loss: 5.723369e-05 , Max Loss: 0.0008419285 , Mean Acc: 0.9948034 , Min Acc: 0.9131849 , Learning rate: 0.001 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 1100 Mean Loss: 5.324823e-05 , Max Loss: 0.0015453213 , Mean Acc: 0.9945109 , Min Acc: 0.9606894 \n",
            ", Mean Accs Foc [0.9980126  0.99721646 0.9920838  0.99569917 0.994777   0.9914024\n",
            " 0.9923848 ] \n",
            ", Min Accs Foc: [0.9832014  0.98326623 0.9810164  0.9743723  0.9715586  0.9606894\n",
            " 0.9703834 ] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 1200 , Mean Loss: 4.5547993e-05 , Max Loss: 0.0004298655 , Mean Acc: 0.9948709 , Min Acc: 0.9304943 , Learning rate: 0.001 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 1200 Mean Loss: 2.5066136e-05 , Max Loss: 0.0009778817 , Mean Acc: 0.9962973 , Min Acc: 0.9687289 \n",
            ", Mean Accs Foc [0.99747175 0.9976405  0.9933958  0.9972637  0.9962791  0.9973386\n",
            " 0.99469125] \n",
            ", Min Accs Foc: [0.9736488  0.9783169  0.97674406 0.9792036  0.9764768  0.9780571\n",
            " 0.9687289 ] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 1300 , Mean Loss: 1.9218201e-05 , Max Loss: 0.00022305093 , Mean Acc: 0.9968093 , Min Acc: 0.9420115 , Learning rate: 0.001 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 1300 Mean Loss: 1.5073168e-05 , Max Loss: 0.00051133917 , Mean Acc: 0.9972131 , Min Acc: 0.9773872 \n",
            ", Mean Accs Foc [0.99771136 0.99832284 0.99472135 0.9975624  0.99760205 0.99822974\n",
            " 0.99634194] \n",
            ", Min Accs Foc: [0.97795284 0.98866165 0.98050004 0.9840317  0.9788356  0.9808897\n",
            " 0.9773872 ] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 1400 , Mean Loss: 1.4057077e-05 , Max Loss: 0.00017282752 , Mean Acc: 0.9973412 , Min Acc: 0.94577634 , Learning rate: 0.001 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 1400 Mean Loss: 1.2867142e-05 , Max Loss: 0.0005477808 , Mean Acc: 0.99749684 , Min Acc: 0.9765953 \n",
            ", Mean Accs Foc [0.99775314 0.9986832  0.9950973  0.9977486  0.9979418  0.99842733\n",
            " 0.9968263 ] \n",
            ", Min Accs Foc: [0.98189723 0.98818254 0.98078    0.9874344  0.9809191  0.9826462\n",
            " 0.9765953 ] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 1500 , Mean Loss: 1.2248568e-05 , Max Loss: 0.00016177945 , Mean Acc: 0.99757063 , Min Acc: 0.9598761 , Learning rate: 0.001 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 1500 Mean Loss: 1.1868622e-05 , Max Loss: 0.00051766104 , Mean Acc: 0.99765366 , Min Acc: 0.97724783 \n",
            ", Mean Accs Foc [0.9978657  0.99874294 0.9952003  0.9979181  0.9982343  0.9985106\n",
            " 0.99710333] \n",
            ", Min Accs Foc: [0.98454857 0.9879181  0.98069996 0.9884113  0.982317   0.9837855\n",
            " 0.97724783] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 1600 , Mean Loss: 1.0991925e-05 , Max Loss: 0.00015475354 , Mean Acc: 0.99774605 , Min Acc: 0.9348248 , Learning rate: 0.001 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 1600 Mean Loss: 1.0392733e-05 , Max Loss: 0.00042461383 , Mean Acc: 0.99783975 , Min Acc: 0.97939384 \n",
            ", Mean Accs Foc [0.998076   0.99883056 0.99546176 0.9980993  0.9983571  0.99860287\n",
            " 0.99745023] \n",
            ", Min Accs Foc: [0.98556876 0.98729193 0.98045635 0.9893014  0.98327744 0.98337376\n",
            " 0.97939384] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 1700 , Mean Loss: 9.98275e-06 , Max Loss: 0.00014916474 , Mean Acc: 0.9978964 , Min Acc: 0.93440896 , Learning rate: 0.001 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 1700 Mean Loss: 9.365385e-06 , Max Loss: 0.00038201243 , Mean Acc: 0.9979929 , Min Acc: 0.98045486 \n",
            ", Mean Accs Foc [0.998265   0.99895954 0.99564993 0.99825203 0.9984579  0.99866295\n",
            " 0.99770224] \n",
            ", Min Accs Foc: [0.98604584 0.9869871  0.98045486 0.98912704 0.9841858  0.9828572\n",
            " 0.9808004 ] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 1800 , Mean Loss: 9.0833055e-06 , Max Loss: 0.00014373468 , Mean Acc: 0.99803895 , Min Acc: 0.94154894 , Learning rate: 0.001 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 1800 Mean Loss: 8.549317e-06 , Max Loss: 0.00034833164 , Mean Acc: 0.9981215 , Min Acc: 0.98133636 \n",
            ", Mean Accs Foc [0.9984375  0.9989151  0.99572104 0.9983867  0.99866676 0.99876684\n",
            " 0.99795616] \n",
            ", Min Accs Foc: [0.9864167  0.9875751  0.98133636 0.9894705  0.9854566  0.9847654\n",
            " 0.98174524] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 1900 , Mean Loss: 8.179737e-06 , Max Loss: 0.00013736944 , Mean Acc: 0.99818325 , Min Acc: 0.95801866 , Learning rate: 0.001 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 1900 Mean Loss: 8.136645e-06 , Max Loss: 0.00031648268 , Mean Acc: 0.99824166 , Min Acc: 0.98221004 \n",
            ", Mean Accs Foc [0.99855256 0.99904937 0.9957005  0.99849725 0.998901   0.99884856\n",
            " 0.9981425 ] \n",
            ", Min Accs Foc: [0.986411   0.98821944 0.98221004 0.98971546 0.9863064  0.9866222\n",
            " 0.98276925] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 2000 , Mean Loss: 7.4176683e-06 , Max Loss: 0.00013346605 , Mean Acc: 0.9983113 , Min Acc: 0.9553044 , Learning rate: 0.001 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 2000 Mean Loss: 7.0057986e-06 , Max Loss: 0.0003217554 , Mean Acc: 0.9983852 , Min Acc: 0.98206246 \n",
            ", Mean Accs Foc [0.99879247 0.999073   0.9959878  0.9986168  0.99889493 0.9989507\n",
            " 0.99837995] \n",
            ", Min Accs Foc: [0.9870993  0.9885374  0.98206246 0.98965514 0.9869206  0.98591185\n",
            " 0.98443794] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 2100 , Mean Loss: 6.699892e-06 , Max Loss: 0.00012944032 , Mean Acc: 0.998433 , Min Acc: 0.954271 , Learning rate: 0.0009996146 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 2100 Mean Loss: 6.4844353e-06 , Max Loss: 0.00029767153 , Mean Acc: 0.9984982 , Min Acc: 0.98274684 \n",
            ", Mean Accs Foc [0.998937   0.9991977  0.99604553 0.99869514 0.99903935 0.99904776\n",
            " 0.9985245 ] \n",
            ", Min Accs Foc: [0.9866234  0.9892333  0.98274684 0.9896214  0.98777723 0.9873171\n",
            " 0.9853138 ] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 2200 , Mean Loss: 6.1117094e-06 , Max Loss: 0.00012663248 , Mean Acc: 0.99853545 , Min Acc: 0.949284 , Learning rate: 0.0009984588 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 2200 Mean Loss: 5.692721e-06 , Max Loss: 0.0003031427 , Mean Acc: 0.99861354 , Min Acc: 0.982589 \n",
            ", Mean Accs Foc [0.99913526 0.99922854 0.9962569  0.9987933  0.9990455  0.9991393\n",
            " 0.99869573] \n",
            ", Min Accs Foc: [0.98619235 0.98942363 0.982589   0.9894401  0.98812234 0.9868034\n",
            " 0.9870126 ] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 2300 , Mean Loss: 5.5199507e-06 , Max Loss: 0.00012114297 , Mean Acc: 0.9986345 , Min Acc: 0.95520496 , Learning rate: 0.0009965346 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 2300 Mean Loss: 5.1461147e-06 , Max Loss: 0.00028263422 , Mean Acc: 0.99871206 , Min Acc: 0.9831883 \n",
            ", Mean Accs Foc [0.9992605  0.99935305 0.99635994 0.9988561  0.9991298  0.9992305\n",
            " 0.99879444] \n",
            ", Min Accs Foc: [0.985604   0.9899788  0.9831883  0.98932856 0.988763   0.98806\n",
            " 0.98836994] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 2400 , Mean Loss: 5.0163567e-06 , Max Loss: 0.000115783594 , Mean Acc: 0.9987224 , Min Acc: 0.95188504 , Learning rate: 0.0009938448 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 2400 Mean Loss: 4.6209148e-06 , Max Loss: 0.00027668162 , Mean Acc: 0.99880403 , Min Acc: 0.98336625 \n",
            ", Mean Accs Foc [0.9994112  0.99939036 0.99650645 0.99892986 0.9991716  0.99931294\n",
            " 0.9989054 ] \n",
            ", Min Accs Foc: [0.98540705 0.99056315 0.98336625 0.9907055  0.98894036 0.98810756\n",
            " 0.98961544] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 2500 , Mean Loss: 4.5781894e-06 , Max Loss: 0.00010995518 , Mean Acc: 0.99879986 , Min Acc: 0.95906645 , Learning rate: 0.0009903936 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 2500 Mean Loss: 4.2085176e-06 , Max Loss: 0.00027281666 , Mean Acc: 0.99886787 , Min Acc: 0.98348284 \n",
            ", Mean Accs Foc [0.9995122  0.99944353 0.99663913 0.99897027 0.9991845  0.9993652\n",
            " 0.9989604 ] \n",
            ", Min Accs Foc: [0.9850798  0.99070215 0.98348284 0.99092305 0.9893136  0.9881769\n",
            " 0.99012196] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 2600 , Mean Loss: 4.1732214e-06 , Max Loss: 0.00010420718 , Mean Acc: 0.9988731 , Min Acc: 0.9643882 , Learning rate: 0.0009861863 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 2600 Mean Loss: 3.7981915e-06 , Max Loss: 0.00026524012 , Mean Acc: 0.99893975 , Min Acc: 0.9837138 \n",
            ", Mean Accs Foc [0.999586   0.9994906  0.9967861  0.9990318  0.9992213  0.99941903\n",
            " 0.99904335] \n",
            ", Min Accs Foc: [0.9850674  0.9908606  0.9837138  0.99125123 0.9895799  0.98842657\n",
            " 0.99092805] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 2700 , Mean Loss: 3.8028554e-06 , Max Loss: 9.827692e-05 , Mean Acc: 0.99893934 , Min Acc: 0.96440625 , Learning rate: 0.0009812296 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 2700 Mean Loss: 3.4111147e-06 , Max Loss: 0.00024974358 , Mean Acc: 0.9990057 , Min Acc: 0.9841967 \n",
            ", Mean Accs Foc [0.99963593 0.9995359  0.996933   0.999093   0.9992613  0.99944794\n",
            " 0.99913204] \n",
            ", Min Accs Foc: [0.98560226 0.9913519  0.9841967  0.9916719  0.9900688  0.9886051\n",
            " 0.9915805 ] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 2800 , Mean Loss: 3.4820728e-06 , Max Loss: 9.2539514e-05 , Mean Acc: 0.99899703 , Min Acc: 0.95764655 , Learning rate: 0.0009755307 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 2800 Mean Loss: 3.0886563e-06 , Max Loss: 0.00023926645 , Mean Acc: 0.999049 , Min Acc: 0.98453176 \n",
            ", Mean Accs Foc [0.999615   0.9995699  0.99707615 0.99914217 0.99929464 0.9994625\n",
            " 0.99918234] \n",
            ", Min Accs Foc: [0.98624283 0.9917577  0.98453176 0.99197364 0.9905069  0.98878783\n",
            " 0.9920193 ] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 2900 , Mean Loss: 3.1565562e-06 , Max Loss: 8.606183e-05 , Mean Acc: 0.9990521 , Min Acc: 0.94877756 , Learning rate: 0.0009690989 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 2900 Mean Loss: 2.7737733e-06 , Max Loss: 0.0002256939 , Mean Acc: 0.9991009 , Min Acc: 0.9849769 \n",
            ", Mean Accs Foc [0.9997374  0.999444   0.9972342  0.99921805 0.9993684  0.99945945\n",
            " 0.9992447 ] \n",
            ", Min Accs Foc: [0.98682743 0.9920662  0.9849769  0.9922143  0.990703   0.9891897\n",
            " 0.9927579 ] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 3000 , Mean Loss: 2.8627983e-06 , Max Loss: 7.976954e-05 , Mean Acc: 0.9991026 , Min Acc: 0.96177185 , Learning rate: 0.0009619436 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 3000 Mean Loss: 2.5242507e-06 , Max Loss: 0.00020893727 , Mean Acc: 0.9991561 , Min Acc: 0.98554534 \n",
            ", Mean Accs Foc [0.99974495 0.9996018  0.9973325  0.9992544  0.9994022  0.99946773\n",
            " 0.99928904] \n",
            ", Min Accs Foc: [0.98740107 0.9932142  0.98554534 0.99253404 0.99137473 0.9895664\n",
            " 0.993042  ] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 3100 , Mean Loss: 2.6095306e-06 , Max Loss: 7.42969e-05 , Mean Acc: 0.99914604 , Min Acc: 0.95335984 , Learning rate: 0.00095407624 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 3100 Mean Loss: 2.2667084e-06 , Max Loss: 0.00019039134 , Mean Acc: 0.9992024 , Min Acc: 0.98620176 \n",
            ", Mean Accs Foc [0.9997481  0.9996339  0.9974575  0.99931777 0.99946356 0.99944377\n",
            " 0.9993516 ] \n",
            ", Min Accs Foc: [0.988075   0.99413437 0.98620176 0.9927827  0.9918828  0.9900474\n",
            " 0.99354064] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 3200 , Mean Loss: 2.346303e-06 , Max Loss: 6.766136e-05 , Mean Acc: 0.99919003 , Min Acc: 0.95658445 , Learning rate: 0.0009455087 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 3200 Mean Loss: 2.049847e-06 , Max Loss: 0.00017965474 , Mean Acc: 0.999243 , Min Acc: 0.98659647 \n",
            ", Mean Accs Foc [0.99975395 0.99962294 0.9975851  0.99936986 0.99951136 0.9994502\n",
            " 0.99940765] \n",
            ", Min Accs Foc: [0.98876333 0.9944321  0.98659647 0.99344623 0.99211633 0.99044394\n",
            " 0.99398077] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 3300 , Mean Loss: 2.1446738e-06 , Max Loss: 6.2787985e-05 , Mean Acc: 0.99922633 , Min Acc: 0.9661664 , Learning rate: 0.00093625445 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 3300 Mean Loss: 1.8416114e-06 , Max Loss: 0.0001629952 , Mean Acc: 0.99927795 , Min Acc: 0.98723304 \n",
            ", Mean Accs Foc [0.99973947 0.9996493  0.9977065  0.99941635 0.9995452  0.99943733\n",
            " 0.9994513 ] \n",
            ", Min Accs Foc: [0.9895106  0.99509156 0.98723304 0.9937643  0.992658   0.9910366\n",
            " 0.9943812 ] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 3400 , Mean Loss: 1.9415497e-06 , Max Loss: 5.7192356e-05 , Mean Acc: 0.99926114 , Min Acc: 0.9592153 , Learning rate: 0.0009263275 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 3400 Mean Loss: 1.7035776e-06 , Max Loss: 0.00015383765 , Mean Acc: 0.9992934 , Min Acc: 0.98759687 \n",
            ", Mean Accs Foc [0.99976385 0.9995103  0.9978081  0.9994434  0.9996039  0.99943006\n",
            " 0.9994937 ] \n",
            ", Min Accs Foc: [0.9902676  0.9949027  0.98759687 0.9941505  0.9927442  0.99159557\n",
            " 0.994364  ] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 3500 , Mean Loss: 1.7764911e-06 , Max Loss: 5.2760428e-05 , Mean Acc: 0.99929166 , Min Acc: 0.9639094 , Learning rate: 0.00091574324 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 3500 Mean Loss: 1.5105824e-06 , Max Loss: 0.00013712661 , Mean Acc: 0.9993384 , Min Acc: 0.9882899 \n",
            ", Mean Accs Foc [0.99973595 0.9996664  0.9979173  0.9994855  0.9996197  0.9994293\n",
            " 0.9995143 ] \n",
            ", Min Accs Foc: [0.99096775 0.9961203  0.9882899  0.99460185 0.99347055 0.9923219\n",
            " 0.9949802 ] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 3600 , Mean Loss: 1.5809311e-06 , Max Loss: 4.7232545e-05 , Mean Acc: 0.9993315 , Min Acc: 0.96691036 , Learning rate: 0.00090451806 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 3600 Mean Loss: 1.3742667e-06 , Max Loss: 0.00012498404 , Mean Acc: 0.999367 , Min Acc: 0.9888204 \n",
            ", Mean Accs Foc [0.9997504  0.9996777  0.9980119  0.9995162  0.99965346 0.99942064\n",
            " 0.99953854] \n",
            ", Min Accs Foc: [0.99166644 0.9963715  0.9888204  0.9947947  0.9938829  0.99297255\n",
            " 0.99525726] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 3700 , Mean Loss: 1.4587455e-06 , Max Loss: 4.3418164e-05 , Mean Acc: 0.99934876 , Min Acc: 0.95437336 , Learning rate: 0.00089266925 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 3700 Mean Loss: 1.2637393e-06 , Max Loss: 0.00011562264 , Mean Acc: 0.9993798 , Min Acc: 0.9892472 \n",
            ", Mean Accs Foc [0.99975604 0.99958575 0.9981047  0.9995371  0.9996821  0.9994323\n",
            " 0.9995605 ] \n",
            ", Min Accs Foc: [0.99241734 0.9962931  0.9892472  0.9951216  0.9941168  0.9933474\n",
            " 0.9954345 ] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 3800 , Mean Loss: 1.3160112e-06 , Max Loss: 3.926518e-05 , Mean Acc: 0.99938124 , Min Acc: 0.9618671 , Learning rate: 0.000880215 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 3800 Mean Loss: 1.1341483e-06 , Max Loss: 9.897724e-05 , Mean Acc: 0.99940324 , Min Acc: 0.99005127 \n",
            ", Mean Accs Foc [0.9997066  0.9996901  0.99819964 0.99957013 0.9997051  0.99937916\n",
            " 0.9995721 ] \n",
            ", Min Accs Foc: [0.99315363 0.9970596  0.99005127 0.9952041  0.99492157 0.99389756\n",
            " 0.99600494] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 3900 , Mean Loss: 1.2052317e-06 , Max Loss: 3.569806e-05 , Mean Acc: 0.9994008 , Min Acc: 0.9648613 , Learning rate: 0.0008671746 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 3900 Mean Loss: 1.0525652e-06 , Max Loss: 9.341362e-05 , Mean Acc: 0.99942 , Min Acc: 0.9903349 \n",
            ", Mean Accs Foc [0.9997171  0.99959695 0.998296   0.99957484 0.9997332  0.9994039\n",
            " 0.99961734] \n",
            ", Min Accs Foc: [0.9939228  0.9969944  0.9903349  0.99513984 0.99512076 0.99417365\n",
            " 0.9962369 ] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 4000 , Mean Loss: 1.0863258e-06 , Max Loss: 3.200409e-05 , Mean Acc: 0.99942815 , Min Acc: 0.9625826 , Learning rate: 0.0008535681 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 4000 Mean Loss: 9.516448e-07 , Max Loss: 8.83826e-05 , Mean Acc: 0.9994481 , Min Acc: 0.9905988 \n",
            ", Mean Accs Foc [0.9997652  0.9995814  0.99837494 0.99960756 0.99975324 0.999441\n",
            " 0.9996135 ] \n",
            ", Min Accs Foc: [0.9947748  0.9970035  0.9905988  0.99527127 0.9953921  0.99454427\n",
            " 0.996227  ] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 4100 , Mean Loss: 9.91003e-07 , Max Loss: 2.8950399e-05 , Mean Acc: 0.99944866 , Min Acc: 0.95316213 , Learning rate: 0.0008394164 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 4100 Mean Loss: 8.5348256e-07 , Max Loss: 7.9992555e-05 , Mean Acc: 0.99946964 , Min Acc: 0.99105614 \n",
            ", Mean Accs Foc [0.99971163 0.9996837  0.99845725 0.99963987 0.99977434 0.9994005\n",
            " 0.9996202 ] \n",
            ", Min Accs Foc: [0.9954534  0.99735975 0.99105614 0.99538934 0.9960722  0.994962\n",
            " 0.9965824 ] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 4200 , Mean Loss: 9.115377e-07 , Max Loss: 2.631651e-05 , Mean Acc: 0.99946564 , Min Acc: 0.9609567 , Learning rate: 0.00082474155 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 4200 Mean Loss: 7.775708e-07 , Max Loss: 7.515189e-05 , Mean Acc: 0.999495 , Min Acc: 0.991331 \n",
            ", Mean Accs Foc [0.9997337  0.99970365 0.998538   0.9996529  0.999788   0.9994233\n",
            " 0.99962544] \n",
            ", Min Accs Foc: [0.9960951  0.99732935 0.991331   0.99544317 0.99642324 0.99543166\n",
            " 0.99682486] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 4300 , Mean Loss: 8.289827e-07 , Max Loss: 2.3665903e-05 , Mean Acc: 0.99948514 , Min Acc: 0.9677681 , Learning rate: 0.00080956606 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 4300 Mean Loss: 7.165353e-07 , Max Loss: 7.041627e-05 , Mean Acc: 0.99950933 , Min Acc: 0.99160856 \n",
            ", Mean Accs Foc [0.99972403 0.99970627 0.99861014 0.99966097 0.9997963  0.9994346\n",
            " 0.99963325] \n",
            ", Min Accs Foc: [0.9962523  0.99718726 0.99160856 0.99542713 0.9967828  0.9957671\n",
            " 0.99701   ] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 4400 , Mean Loss: 7.612025e-07 , Max Loss: 2.1504042e-05 , Mean Acc: 0.9995031 , Min Acc: 0.9530297 , Learning rate: 0.00079391326 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 4400 Mean Loss: 6.5723884e-07 , Max Loss: 6.589182e-05 , Mean Acc: 0.99951506 , Min Acc: 0.9918826 \n",
            ", Mean Accs Foc [0.9997375  0.99961317 0.99868166 0.99966645 0.9998133  0.99947166\n",
            " 0.99962145] \n",
            ", Min Accs Foc: [0.99631494 0.9967269  0.9918826  0.99555415 0.9970678  0.99613154\n",
            " 0.9966164 ] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 4500 , Mean Loss: 6.870394e-07 , Max Loss: 1.9041601e-05 , Mean Acc: 0.9995223 , Min Acc: 0.9660139 , Learning rate: 0.0007778073 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 4500 Mean Loss: 6.0186704e-07 , Max Loss: 5.8388792e-05 , Mean Acc: 0.9995235 , Min Acc: 0.99235874 \n",
            ", Mean Accs Foc [0.9997412  0.9995922  0.9987532  0.99967325 0.9998234  0.99946547\n",
            " 0.99961567] \n",
            ", Min Accs Foc: [0.9962934  0.99658084 0.99235874 0.995857   0.99727714 0.9962701\n",
            " 0.9965067 ] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 4600 , Mean Loss: 6.3636924e-07 , Max Loss: 1.728713e-05 , Mean Acc: 0.9995339 , Min Acc: 0.9714177 , Learning rate: 0.0007612732 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 4600 Mean Loss: 5.529589e-07 , Max Loss: 5.323547e-05 , Mean Acc: 0.9995558 , Min Acc: 0.99270374 \n",
            ", Mean Accs Foc [0.9997153  0.9997078  0.99882185 0.9996885  0.99983144 0.99947506\n",
            " 0.99965096] \n",
            ", Min Accs Foc: [0.99635774 0.9962294  0.99270374 0.995873   0.99735355 0.996448\n",
            " 0.9964233 ] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 4700 , Mean Loss: 5.7951615e-07 , Max Loss: 1.5467447e-05 , Mean Acc: 0.9995516 , Min Acc: 0.9581821 , Learning rate: 0.0007443362 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 4700 Mean Loss: 5.0711446e-07 , Max Loss: 4.7934805e-05 , Mean Acc: 0.99955195 , Min Acc: 0.9930765 \n",
            ", Mean Accs Foc [0.99973154 0.9996084  0.9988787  0.9996943  0.9998429  0.9994904\n",
            " 0.99961746] \n",
            ", Min Accs Foc: [0.99639875 0.99659586 0.9930765  0.996197   0.99745715 0.9966008\n",
            " 0.99651027] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 4800 , Mean Loss: 5.3761266e-07 , Max Loss: 1.4032504e-05 , Mean Acc: 0.9995631 , Min Acc: 0.96941185 , Learning rate: 0.0007270226 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 4800 Mean Loss: 4.73947e-07 , Max Loss: 4.1784126e-05 , Mean Acc: 0.9995743 , Min Acc: 0.99353594 \n",
            ", Mean Accs Foc [0.99971056 0.99971175 0.9989251  0.9997119  0.999846   0.9994679\n",
            " 0.99964654] \n",
            ", Min Accs Foc: [0.9965047  0.9965199  0.99353594 0.99652815 0.9975114  0.9968489\n",
            " 0.99657243] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 4900 , Mean Loss: 4.910598e-07 , Max Loss: 1.2536256e-05 , Mean Acc: 0.99957824 , Min Acc: 0.9595079 , Learning rate: 0.00070935895 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 4900 Mean Loss: 4.2501034e-07 , Max Loss: 3.9862574e-05 , Mean Acc: 0.99959487 , Min Acc: 0.9936863 \n",
            ", Mean Accs Foc [0.9997435  0.99967724 0.9989935  0.9997057  0.99985886 0.99953437\n",
            " 0.9996506 ] \n",
            ", Min Accs Foc: [0.99645376 0.99690855 0.9936863  0.99647945 0.9976119  0.9969165\n",
            " 0.99666035] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 5000 , Mean Loss: 4.50336e-07 , Max Loss: 1.1222743e-05 , Mean Acc: 0.999592 , Min Acc: 0.96949065 , Learning rate: 0.00069137255 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 5000 Mean Loss: 3.965737e-07 , Max Loss: 3.483281e-05 , Mean Acc: 0.99960315 , Min Acc: 0.99409807 \n",
            ", Mean Accs Foc [0.99972296 0.9997057  0.9990381  0.99972653 0.999862   0.9995231\n",
            " 0.99964374] \n",
            ", Min Accs Foc: [0.9965595  0.9969363  0.99409807 0.9967646  0.9976542  0.9971016\n",
            " 0.99673104] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 5100 , Mean Loss: 4.173976e-07 , Max Loss: 1.0171074e-05 , Mean Acc: 0.999603 , Min Acc: 0.9687703 , Learning rate: 0.0006730912 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 5100 Mean Loss: 3.7109336e-07 , Max Loss: 3.1112548e-05 , Mean Acc: 0.9996199 , Min Acc: 0.99442214 \n",
            ", Mean Accs Foc [0.99974066 0.99971044 0.9990953  0.9997306  0.999861   0.99953413\n",
            " 0.9996672 ] \n",
            ", Min Accs Foc: [0.99651986 0.9970832  0.99442214 0.99676234 0.99769413 0.9972227\n",
            " 0.9968007 ] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 5200 , Mean Loss: 3.9060583e-07 , Max Loss: 9.372669e-06 , Mean Acc: 0.999613 , Min Acc: 0.9709709 , Learning rate: 0.00065454305 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 5200 Mean Loss: 3.371656e-07 , Max Loss: 2.9069968e-05 , Mean Acc: 0.9996357 , Min Acc: 0.99460834 \n",
            ", Mean Accs Foc [0.9997408  0.999709   0.99914896 0.9997333  0.9998739  0.9995712\n",
            " 0.9996724 ] \n",
            ", Min Accs Foc: [0.99652785 0.99729145 0.99460834 0.9968442  0.9978032  0.997199\n",
            " 0.996839  ] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 5300 , Mean Loss: 3.6065427e-07 , Max Loss: 8.424894e-06 , Mean Acc: 0.9996246 , Min Acc: 0.9698091 , Learning rate: 0.00063575665 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 5300 Mean Loss: 3.1531417e-07 , Max Loss: 2.6252656e-05 , Mean Acc: 0.99964446 , Min Acc: 0.99487627 \n",
            ", Mean Accs Foc [0.99975526 0.9997128  0.99919164 0.9997418  0.9998615  0.99958044\n",
            " 0.99966735] \n",
            ", Min Accs Foc: [0.99660057 0.99730575 0.99487627 0.99687606 0.9978541  0.9973117\n",
            " 0.99689984] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 5400 , Mean Loss: 3.360773e-07 , Max Loss: 7.673759e-06 , Mean Acc: 0.9996344 , Min Acc: 0.97281164 , Learning rate: 0.000616761 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 5400 Mean Loss: 2.9276924e-07 , Max Loss: 2.3217359e-05 , Mean Acc: 0.9996463 , Min Acc: 0.99518156 \n",
            ", Mean Accs Foc [0.99971855 0.99970734 0.9992367  0.9997449  0.99988186 0.99957603\n",
            " 0.99965817] \n",
            ", Min Accs Foc: [0.9966667  0.9974282  0.99518156 0.9968943  0.9979682  0.99745727\n",
            " 0.9969614 ] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 5500 , Mean Loss: 3.1395444e-07 , Max Loss: 6.9599014e-06 , Mean Acc: 0.9996429 , Min Acc: 0.9696578 , Learning rate: 0.0005975854 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 5500 Mean Loss: 2.7240424e-07 , Max Loss: 2.0772348e-05 , Mean Acc: 0.9996431 , Min Acc: 0.99544233 \n",
            ", Mean Accs Foc [0.9997414  0.9996494  0.99927175 0.9997297  0.99988735 0.99958515\n",
            " 0.9996362 ] \n",
            ", Min Accs Foc: [0.99661565 0.99758244 0.99544233 0.99705774 0.9979925  0.99756026\n",
            " 0.9970767 ] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 5600 , Mean Loss: 2.9345833e-07 , Max Loss: 6.378224e-06 , Mean Acc: 0.99965286 , Min Acc: 0.96973675 , Learning rate: 0.0005782594 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 5600 Mean Loss: 2.5474947e-07 , Max Loss: 2.0245992e-05 , Mean Acc: 0.99967456 , Min Acc: 0.99550045 \n",
            ", Mean Accs Foc [0.9997386  0.99971277 0.9993161  0.9997544  0.99989307 0.99963385\n",
            " 0.9996728 ] \n",
            ", Min Accs Foc: [0.99674356 0.9973314  0.99550045 0.9969963  0.9980637  0.9976554\n",
            " 0.9970048 ] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 5700 , Mean Loss: 2.7334718e-07 , Max Loss: 5.79144e-06 , Mean Acc: 0.9996623 , Min Acc: 0.9777795 , Learning rate: 0.00055881275 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 5700 Mean Loss: 2.360689e-07 , Max Loss: 1.799459e-05 , Mean Acc: 0.99967057 , Min Acc: 0.995758 \n",
            ", Mean Accs Foc [0.9997301  0.99967706 0.999352   0.9997479  0.999898   0.9996339\n",
            " 0.99965465] \n",
            ", Min Accs Foc: [0.99675876 0.9975226  0.995758   0.99707067 0.9980866  0.9977707\n",
            " 0.99710274] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 5800 , Mean Loss: 2.588977e-07 , Max Loss: 5.394772e-06 , Mean Acc: 0.9996693 , Min Acc: 0.9665599 , Learning rate: 0.0005392756 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 5800 Mean Loss: 2.2302675e-07 , Max Loss: 1.6355352e-05 , Mean Acc: 0.9996803 , Min Acc: 0.9959558 \n",
            ", Mean Accs Foc [0.9997339  0.99969876 0.9993864  0.9997621  0.9998914  0.9996378\n",
            " 0.99965143] \n",
            ", Min Accs Foc: [0.9967703  0.9974649  0.9959558  0.9970627  0.99805355 0.9978636\n",
            " 0.99712646] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 5900 , Mean Loss: 2.43433e-07 , Max Loss: 5.022184e-06 , Mean Acc: 0.9996783 , Min Acc: 0.97007895 , Learning rate: 0.0005196779 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 5900 Mean Loss: 2.1025508e-07 , Max Loss: 1.4881635e-05 , Mean Acc: 0.9996872 , Min Acc: 0.9961423 \n",
            ", Mean Accs Foc [0.99972755 0.9996971  0.9994147  0.99976146 0.9999034  0.9996464\n",
            " 0.9996592 ] \n",
            ", Min Accs Foc: [0.9968365  0.99744844 0.9961423  0.9971269  0.9981011  0.99786806\n",
            " 0.99708253] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 6000 , Mean Loss: 2.3218563e-07 , Max Loss: 4.7107487e-06 , Mean Acc: 0.9996842 , Min Acc: 0.9670781 , Learning rate: 0.0005000499 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 6000 Mean Loss: 2.0066301e-07 , Max Loss: 1.46325165e-05 , Mean Acc: 0.99970484 , Min Acc: 0.99617475 \n",
            ", Mean Accs Foc [0.9997461  0.9997098  0.9994503  0.9997649  0.99990356 0.999686\n",
            " 0.99967253] \n",
            ", Min Accs Foc: [0.9968154  0.99737227 0.99617475 0.9971087  0.99809134 0.99788314\n",
            " 0.9970535 ] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 6100 , Mean Loss: 2.1908987e-07 , Max Loss: 4.3552727e-06 , Mean Acc: 0.99969137 , Min Acc: 0.9798353 , Learning rate: 0.000480422 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 6100 Mean Loss: 1.8842499e-07 , Max Loss: 1.2992646e-05 , Mean Acc: 0.99970484 , Min Acc: 0.99639547 \n",
            ", Mean Accs Foc [0.99974406 0.9996898  0.99947715 0.99975795 0.99990743 0.99968994\n",
            " 0.9996674 ] \n",
            ", Min Accs Foc: [0.9968749  0.997476   0.99639547 0.9971755  0.998178   0.9979795\n",
            " 0.99707747] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 6200 , Mean Loss: 2.1238364e-07 , Max Loss: 4.2205925e-06 , Mean Acc: 0.9996963 , Min Acc: 0.9675721 , Learning rate: 0.00046082438 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 6200 Mean Loss: 1.7943196e-07 , Max Loss: 1.1597102e-05 , Mean Acc: 0.9997059 , Min Acc: 0.99659455 \n",
            ", Mean Accs Foc [0.9997508  0.99968237 0.9995028  0.9997547  0.99990284 0.9996902\n",
            " 0.9996572 ] \n",
            ", Min Accs Foc: [0.996872   0.9975003  0.99659455 0.99722403 0.99815845 0.99807173\n",
            " 0.9970854 ] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 6300 , Mean Loss: 1.9923354e-07 , Max Loss: 3.8894214e-06 , Mean Acc: 0.9997042 , Min Acc: 0.97563726 , Learning rate: 0.00044128712 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 6300 Mean Loss: 1.7354795e-07 , Max Loss: 1.0242255e-05 , Mean Acc: 0.9997079 , Min Acc: 0.99679965 \n",
            ", Mean Accs Foc [0.99974054 0.99969894 0.9995179  0.9997704  0.99990153 0.9996741\n",
            " 0.99965143] \n",
            ", Min Accs Foc: [0.9970109  0.9974532  0.99679965 0.99721724 0.99819696 0.998195\n",
            " 0.997045  ] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 6400 , Mean Loss: 1.9184331e-07 , Max Loss: 3.7152074e-06 , Mean Acc: 0.999709 , Min Acc: 0.9644611 , Learning rate: 0.00042184055 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 6400 Mean Loss: 1.6461806e-07 , Max Loss: 9.755271e-06 , Mean Acc: 0.99971724 , Min Acc: 0.99687666 \n",
            ", Mean Accs Foc [0.9997519  0.9996948  0.99954665 0.9997629  0.999901   0.99970615\n",
            " 0.99965703] \n",
            ", Min Accs Foc: [0.99695736 0.9974847  0.99687666 0.99725246 0.99817324 0.9981968\n",
            " 0.99702954] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 6500 , Mean Loss: 1.836949e-07 , Max Loss: 3.5356234e-06 , Mean Acc: 0.9997146 , Min Acc: 0.97330314 , Learning rate: 0.00040251453 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 6500 Mean Loss: 1.5945697e-07 , Max Loss: 9.131854e-06 , Mean Acc: 0.99971616 , Min Acc: 0.9969781 \n",
            ", Mean Accs Foc [0.9997473  0.99965954 0.9995676  0.9997586  0.9999128  0.9997132\n",
            " 0.99965423] \n",
            ", Min Accs Foc: [0.99704754 0.9975549  0.99701    0.99729145 0.99823725 0.99818534\n",
            " 0.9969781 ] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 6600 , Mean Loss: 1.7759233e-07 , Max Loss: 3.3933056e-06 , Mean Acc: 0.9997189 , Min Acc: 0.9766234 , Learning rate: 0.00038333892 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 6600 Mean Loss: 1.5337613e-07 , Max Loss: 9.347455e-06 , Mean Acc: 0.9997324 , Min Acc: 0.99694264 \n",
            ", Mean Accs Foc [0.9997435  0.999703   0.9995934  0.9997625  0.9999182  0.9997366\n",
            " 0.99966913] \n",
            ", Min Accs Foc: [0.9970441  0.9974619  0.99707323 0.9972752  0.9982822  0.998113\n",
            " 0.99694264] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 6700 , Mean Loss: 1.7094993e-07 , Max Loss: 3.2398436e-06 , Mean Acc: 0.9997236 , Min Acc: 0.9626273 , Learning rate: 0.00036434326 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 6700 Mean Loss: 1.4751373e-07 , Max Loss: 9.504463e-06 , Mean Acc: 0.99973345 , Min Acc: 0.99691707 \n",
            ", Mean Accs Foc [0.99973917 0.99969727 0.9996072  0.99976933 0.9999182  0.9997364\n",
            " 0.99966645] \n",
            ", Min Accs Foc: [0.9971029  0.9974829  0.9972076  0.9973076  0.9982815  0.9982623\n",
            " 0.99691707] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 6800 , Mean Loss: 1.6668633e-07 , Max Loss: 3.1815623e-06 , Mean Acc: 0.9997274 , Min Acc: 0.9713573 , Learning rate: 0.00034555688 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 6800 Mean Loss: 1.4365628e-07 , Max Loss: 9.969031e-06 , Mean Acc: 0.99973965 , Min Acc: 0.9968426 \n",
            ", Mean Accs Foc [0.9997388  0.9997137  0.99962157 0.999774   0.9999199  0.99973786\n",
            " 0.9996714 ] \n",
            ", Min Accs Foc: [0.99720204 0.9973333  0.9973236  0.9973244  0.99828815 0.9983806\n",
            " 0.9968426 ] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 6900 , Mean Loss: 1.6044851e-07 , Max Loss: 3.0493543e-06 , Mean Acc: 0.9997323 , Min Acc: 0.9733386 , Learning rate: 0.0003270087 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 6900 Mean Loss: 1.392776e-07 , Max Loss: 9.980326e-06 , Mean Acc: 0.9997417 , Min Acc: 0.99684083 \n",
            ", Mean Accs Foc [0.99974215 0.99970067 0.99964195 0.99977726 0.9999161  0.9997498\n",
            " 0.9996634 ] \n",
            ", Min Accs Foc: [0.99717474 0.9972794  0.99739575 0.9972895  0.99828935 0.9984038\n",
            " 0.99684083] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 7000 , Mean Loss: 1.5616777e-07 , Max Loss: 2.9541898e-06 , Mean Acc: 0.9997354 , Min Acc: 0.9780092 , Learning rate: 0.00030872732 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 7000 Mean Loss: 1.3541046e-07 , Max Loss: 1.0218995e-05 , Mean Acc: 0.99974525 , Min Acc: 0.9968033 \n",
            ", Mean Accs Foc [0.99974704 0.9996989  0.99965715 0.999768   0.9999201  0.99975777\n",
            " 0.99966735] \n",
            ", Min Accs Foc: [0.997197   0.99722767 0.9974911  0.99735373 0.9982799  0.9984261\n",
            " 0.9968033 ] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 7100 , Mean Loss: 1.5213988e-07 , Max Loss: 2.8843008e-06 , Mean Acc: 0.9997391 , Min Acc: 0.97525555 , Learning rate: 0.00029074104 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 7100 Mean Loss: 1.3251599e-07 , Max Loss: 1.0550899e-05 , Mean Acc: 0.99974936 , Min Acc: 0.9967518 \n",
            ", Mean Accs Foc [0.9997531  0.99969864 0.9996689  0.99976516 0.9999198  0.99976957\n",
            " 0.99967027] \n",
            ", Min Accs Foc: [0.9972008  0.99715436 0.99755085 0.99735826 0.9982854  0.9984686\n",
            " 0.9967518 ] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 7200 , Mean Loss: 1.4941607e-07 , Max Loss: 2.8458505e-06 , Mean Acc: 0.9997418 , Min Acc: 0.97191465 , Learning rate: 0.0002730774 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 7200 Mean Loss: 1.2961081e-07 , Max Loss: 1.0894008e-05 , Mean Acc: 0.9997515 , Min Acc: 0.9966994 \n",
            ", Mean Accs Foc [0.99974096 0.99970734 0.9996797  0.99977845 0.9999199  0.9997643\n",
            " 0.9996698 ] \n",
            ", Min Accs Foc: [0.9973169  0.99702084 0.9976537  0.99736315 0.9982852  0.99852616\n",
            " 0.9966994 ] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 7300 , Mean Loss: 1.4479727e-07 , Max Loss: 2.733785e-06 , Mean Acc: 0.99974525 , Min Acc: 0.9806003 , Learning rate: 0.00025576376 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 7300 Mean Loss: 1.2817284e-07 , Max Loss: 1.1167587e-05 , Mean Acc: 0.99975806 , Min Acc: 0.9966582 \n",
            ", Mean Accs Foc [0.9997442 0.9997123 0.9996941 0.9997807 0.9999186 0.9997847 0.9996717] \n",
            ", Min Accs Foc: [0.9973297  0.99694836 0.9976588  0.99734086 0.99833083 0.9984969\n",
            " 0.9966582 ] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 7400 , Mean Loss: 1.435901e-07 , Max Loss: 2.7346348e-06 , Mean Acc: 0.9997473 , Min Acc: 0.97478735 , Learning rate: 0.00023882677 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 7400 Mean Loss: 1.264967e-07 , Max Loss: 1.1183926e-05 , Mean Acc: 0.9997512 , Min Acc: 0.99665576 \n",
            ", Mean Accs Foc [0.9997521  0.99966204 0.9997039  0.9997723  0.9999167  0.9997908\n",
            " 0.9996605 ] \n",
            ", Min Accs Foc: [0.9973544  0.9969928  0.9977172  0.9973851  0.998368   0.9985136\n",
            " 0.99665576] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 7500 , Mean Loss: 1.4153397e-07 , Max Loss: 2.7010944e-06 , Mean Acc: 0.9997493 , Min Acc: 0.9743824 , Learning rate: 0.0002222926 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 7500 Mean Loss: 1.2278464e-07 , Max Loss: 1.1529e-05 , Mean Acc: 0.9997565 , Min Acc: 0.99660456 \n",
            ", Mean Accs Foc [0.9997544  0.9996911  0.9997132  0.99976826 0.9999147  0.9997883\n",
            " 0.9996654 ] \n",
            ", Min Accs Foc: [0.9973629  0.99683    0.99781805 0.9973909  0.9983916  0.9985652\n",
            " 0.99660456] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 7600 , Mean Loss: 1.371581e-07 , Max Loss: 2.6087841e-06 , Mean Acc: 0.9997527 , Min Acc: 0.9803701 , Learning rate: 0.0002061867 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 7600 Mean Loss: 1.2066685e-07 , Max Loss: 1.1784186e-05 , Mean Acc: 0.99975705 , Min Acc: 0.9965672 \n",
            ", Mean Accs Foc [0.99973583 0.9996953  0.9997195  0.99977255 0.99992514 0.9997859\n",
            " 0.999665  ] \n",
            ", Min Accs Foc: [0.99747473 0.9967451  0.997885   0.9974146  0.99846053 0.99862474\n",
            " 0.9965672 ] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 7700 , Mean Loss: 1.3636667e-07 , Max Loss: 2.6162934e-06 , Mean Acc: 0.99975425 , Min Acc: 0.97820354 , Learning rate: 0.0001905339 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 7700 Mean Loss: 1.1915009e-07 , Max Loss: 1.1825145e-05 , Mean Acc: 0.9997597 , Min Acc: 0.9965612 \n",
            ", Mean Accs Foc [0.99974537 0.9996916  0.9997275  0.9997715  0.99992406 0.9997907\n",
            " 0.9996667 ] \n",
            ", Min Accs Foc: [0.9974579  0.99671793 0.99794334 0.99742436 0.9984937  0.99862933\n",
            " 0.9965612 ] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 7800 , Mean Loss: 1.3398903e-07 , Max Loss: 2.5759282e-06 , Mean Acc: 0.99975646 , Min Acc: 0.9745511 , Learning rate: 0.00017535838 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 7800 Mean Loss: 1.1781071e-07 , Max Loss: 1.2181147e-05 , Mean Acc: 0.99976546 , Min Acc: 0.99650985 \n",
            ", Mean Accs Foc [0.9997468  0.999699   0.99973667 0.99977434 0.9999255  0.9998027\n",
            " 0.9996729 ] \n",
            ", Min Accs Foc: [0.99750656 0.99665666 0.99795353 0.9974096  0.9985299  0.99861306\n",
            " 0.99650985] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 7900 , Mean Loss: 1.3418479e-07 , Max Loss: 2.5907234e-06 , Mean Acc: 0.9997566 , Min Acc: 0.9702157 , Learning rate: 0.00016068357 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 7900 Mean Loss: 1.1639564e-07 , Max Loss: 1.2533143e-05 , Mean Acc: 0.99976563 , Min Acc: 0.9964598 \n",
            ", Mean Accs Foc [0.99974704 0.99969256 0.9997423  0.99977434 0.99992657 0.99980557\n",
            " 0.999671  ] \n",
            ", Min Accs Foc: [0.99754506 0.99656403 0.99799615 0.99743545 0.9985558  0.99864477\n",
            " 0.9964598 ] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 8000 , Mean Loss: 1.3195596e-07 , Max Loss: 2.54313e-06 , Mean Acc: 0.9997585 , Min Acc: 0.9812326 , Learning rate: 0.0001465319 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 8000 Mean Loss: 1.1604821e-07 , Max Loss: 1.2551296e-05 , Mean Acc: 0.9997707 , Min Acc: 0.9964572 \n",
            ", Mean Accs Foc [0.9997453  0.9997128  0.99974966 0.9997808  0.99992335 0.9998088\n",
            " 0.9996741 ] \n",
            ", Min Accs Foc: [0.9975344  0.99648714 0.9980327  0.9973996  0.9985733  0.9986309\n",
            " 0.9964572 ] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 8100 , Mean Loss: 1.3119893e-07 , Max Loss: 2.5456882e-06 , Mean Acc: 0.99976 , Min Acc: 0.9714682 , Learning rate: 0.00013292544 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 8100 Mean Loss: 1.14111e-07 , Max Loss: 1.2668131e-05 , Mean Acc: 0.99976605 , Min Acc: 0.99644077 \n",
            ", Mean Accs Foc [0.99974906 0.9996972  0.999753   0.9997715  0.9999197  0.9998055\n",
            " 0.99966574] \n",
            ", Min Accs Foc: [0.99756736 0.9964663  0.99809283 0.99744266 0.9985713  0.9986937\n",
            " 0.99644077] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 8200 , Mean Loss: 1.2922771e-07 , Max Loss: 2.505312e-06 , Mean Acc: 0.99976146 , Min Acc: 0.9790499 , Learning rate: 0.00011988496 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 8200 Mean Loss: 1.1341166e-07 , Max Loss: 1.2960868e-05 , Mean Acc: 0.9997695 , Min Acc: 0.9963999 \n",
            ", Mean Accs Foc [0.9997429  0.9997064  0.99975836 0.9997785  0.99992216 0.99980783\n",
            " 0.99967   ] \n",
            ", Min Accs Foc: [0.99757105 0.9963999  0.9981256  0.99743474 0.9986006  0.9986968\n",
            " 0.9964158 ] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 8300 , Mean Loss: 1.2917958e-07 , Max Loss: 2.5039005e-06 , Mean Acc: 0.99976176 , Min Acc: 0.97999704 , Learning rate: 0.00010743071 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 8300 Mean Loss: 1.12735435e-07 , Max Loss: 1.3027905e-05 , Mean Acc: 0.99977046 , Min Acc: 0.9963906 \n",
            ", Mean Accs Foc [0.99975145 0.9996992  0.99976224 0.9997729  0.9999202  0.99981666\n",
            " 0.99967045] \n",
            ", Min Accs Foc: [0.99752593 0.9963906  0.9981223  0.99745405 0.99861574 0.99867535\n",
            " 0.99639547] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 8400 , Mean Loss: 1.2820415e-07 , Max Loss: 2.488673e-06 , Mean Acc: 0.999763 , Min Acc: 0.97062075 , Learning rate: 9.558193e-05 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 8400 Mean Loss: 1.114886e-07 , Max Loss: 1.32343885e-05 , Mean Acc: 0.9997703 , Min Acc: 0.9963621 \n",
            ", Mean Accs Foc [0.99974275 0.99970394 0.99976504 0.999776   0.99992245 0.999813\n",
            " 0.99966854] \n",
            ", Min Accs Foc: [0.99754065 0.9963621  0.99817294 0.9974535  0.998634   0.9987249\n",
            " 0.9963963 ] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 8500 , Mean Loss: 1.2732838e-07 , Max Loss: 2.4790409e-06 , Mean Acc: 0.9997641 , Min Acc: 0.98193735 , Learning rate: 8.435669e-05 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 8500 Mean Loss: 1.11223734e-07 , Max Loss: 1.2933416e-05 , Mean Acc: 0.99977005 , Min Acc: 0.9964037 \n",
            ", Mean Accs Foc [0.9997442  0.9996924  0.9997692  0.9997755  0.9999232  0.9998182\n",
            " 0.99966717] \n",
            ", Min Accs Foc: [0.99753696 0.9964037  0.99818194 0.99745107 0.9986527  0.9986783\n",
            " 0.9964041 ] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 8600 , Mean Loss: 1.2557373e-07 , Max Loss: 2.4535962e-06 , Mean Acc: 0.9997657 , Min Acc: 0.9808386 , Learning rate: 7.377253e-05 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 8600 Mean Loss: 1.1021376e-07 , Max Loss: 1.3124465e-05 , Mean Acc: 0.99976885 , Min Acc: 0.9963772 \n",
            ", Mean Accs Foc [0.9997437  0.9996964  0.9997702  0.99977446 0.999923   0.99980664\n",
            " 0.99966687] \n",
            ", Min Accs Foc: [0.99754226 0.9963772  0.99825233 0.99747753 0.998651   0.9987747\n",
            " 0.99641037] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 8700 , Mean Loss: 1.2523618e-07 , Max Loss: 2.4303308e-06 , Mean Acc: 0.99976593 , Min Acc: 0.97907716 , Learning rate: 6.384553e-05 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 8700 Mean Loss: 1.10022214e-07 , Max Loss: 1.3104606e-05 , Mean Acc: 0.99977463 , Min Acc: 0.99638 \n",
            ", Mean Accs Foc [0.9997488  0.9997065  0.9997745  0.9997773  0.9999241  0.9998183\n",
            " 0.99967265] \n",
            ", Min Accs Foc: [0.9975363  0.99638    0.99823934 0.997452   0.99867904 0.9986729\n",
            " 0.996407  ] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 8800 , Mean Loss: 1.2490771e-07 , Max Loss: 2.4345677e-06 , Mean Acc: 0.9997663 , Min Acc: 0.9809374 , Learning rate: 5.459126e-05 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 8800 Mean Loss: 1.09309454e-07 , Max Loss: 1.321618e-05 , Mean Acc: 0.99977446 , Min Acc: 0.9963646 \n",
            ", Mean Accs Foc [0.9997445 0.9997092 0.9997753 0.9997769 0.9999256 0.9998169 0.9996724] \n",
            ", Min Accs Foc: [0.9975371  0.9963646  0.99825776 0.9974734  0.9986874  0.998724\n",
            " 0.99639404] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 8900 , Mean Loss: 1.2494846e-07 , Max Loss: 2.4572234e-06 , Mean Acc: 0.9997671 , Min Acc: 0.9776864 , Learning rate: 4.60238e-05 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 8900 Mean Loss: 1.0893655e-07 , Max Loss: 1.31910565e-05 , Mean Acc: 0.999774 , Min Acc: 0.99636805 \n",
            ", Mean Accs Foc [0.9997444  0.999705   0.99977803 0.99977946 0.99992335 0.9998173\n",
            " 0.99967015] \n",
            ", Min Accs Foc: [0.99753606 0.99636805 0.99827534 0.99746686 0.9986899  0.9987132\n",
            " 0.9964028 ] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 9000 , Mean Loss: 1.2271421e-07 , Max Loss: 2.3880748e-06 , Mean Acc: 0.9997685 , Min Acc: 0.9754226 , Learning rate: 3.8156384e-05 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 9000 Mean Loss: 1.08842436e-07 , Max Loss: 1.2749726e-05 , Mean Acc: 0.99977165 , Min Acc: 0.9964293 \n",
            ", Mean Accs Foc [0.99974436 0.9996961  0.9997793  0.99977404 0.9999247  0.99981445\n",
            " 0.99966824] \n",
            ", Min Accs Foc: [0.99756074 0.9964293  0.99830693 0.9974841  0.9986985  0.9987033\n",
            " 0.9964317 ] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 9100 , Mean Loss: 1.2292199e-07 , Max Loss: 2.380465e-06 , Mean Acc: 0.999768 , Min Acc: 0.98167 , Learning rate: 3.1001204e-05 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 9100 Mean Loss: 1.0835667e-07 , Max Loss: 1.295057e-05 , Mean Acc: 0.9997731 , Min Acc: 0.9964013 \n",
            ", Mean Accs Foc [0.99974203 0.9996995  0.9997803  0.9997759  0.99992657 0.99981743\n",
            " 0.99966943] \n",
            ", Min Accs Foc: [0.99754804 0.9964013  0.9983049  0.99748653 0.9987111  0.9987206\n",
            " 0.99641424] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 9200 , Mean Loss: 1.2234283e-07 , Max Loss: 2.3891562e-06 , Mean Acc: 0.9997692 , Min Acc: 0.97503245 , Learning rate: 2.4569254e-05 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 9200 Mean Loss: 1.08261155e-07 , Max Loss: 1.279915e-05 , Mean Acc: 0.9997735 , Min Acc: 0.9964224 \n",
            ", Mean Accs Foc [0.9997456  0.9996975  0.9997816  0.9997754  0.99992454 0.9998205\n",
            " 0.99966925] \n",
            ", Min Accs Foc: [0.99755    0.9964224  0.99830616 0.99748194 0.99871206 0.99868715\n",
            " 0.99642575] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 9300 , Mean Loss: 1.2288196e-07 , Max Loss: 2.4142164e-06 , Mean Acc: 0.9997688 , Min Acc: 0.9716769 , Learning rate: 1.8870487e-05 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 9300 Mean Loss: 1.0793737e-07 , Max Loss: 1.3032208e-05 , Mean Acc: 0.9997746 , Min Acc: 0.99639 \n",
            ", Mean Accs Foc [0.99974406 0.999704   0.9997823  0.99977756 0.999925   0.99981797\n",
            " 0.99967104] \n",
            ", Min Accs Foc: [0.9975461  0.99639    0.99832106 0.9974761  0.99871445 0.998717\n",
            " 0.99641186] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 9400 , Mean Loss: 1.2277236e-07 , Max Loss: 2.4312742e-06 , Mean Acc: 0.9997694 , Min Acc: 0.9761096 , Learning rate: 1.3913634e-05 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 9400 Mean Loss: 1.07765565e-07 , Max Loss: 1.2992646e-05 , Mean Acc: 0.99977326 , Min Acc: 0.99639547 \n",
            ", Mean Accs Foc [0.9997452  0.99969625 0.9997831  0.999774   0.9999256  0.9998189\n",
            " 0.9996696 ] \n",
            ", Min Accs Foc: [0.9975359  0.99639547 0.9983266  0.9974869  0.9987172  0.99871993\n",
            " 0.9964073 ] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 9500 , Mean Loss: 1.2304372e-07 , Max Loss: 2.4055553e-06 , Mean Acc: 0.9997685 , Min Acc: 0.97505045 , Learning rate: 9.706384e-06 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 9500 Mean Loss: 1.0772287e-07 , Max Loss: 1.2957435e-05 , Mean Acc: 0.99977505 , Min Acc: 0.99640036 \n",
            ", Mean Accs Foc [0.9997444  0.99970275 0.99978364 0.99977607 0.9999261  0.9998209\n",
            " 0.999671  ] \n",
            ", Min Accs Foc: [0.9975444  0.99640036 0.99832386 0.9974869  0.9987253  0.9986988\n",
            " 0.9964157 ] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 9600 , Mean Loss: 1.2281113e-07 , Max Loss: 2.4238648e-06 , Mean Acc: 0.9997693 , Min Acc: 0.9744671 , Learning rate: 6.255203e-06 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 9600 Mean Loss: 1.0751404e-07 , Max Loss: 1.30830385e-05 , Mean Acc: 0.99977434 , Min Acc: 0.99638295 \n",
            ", Mean Accs Foc [0.99974394 0.9997023  0.9997835  0.9997755  0.9999256  0.99981964\n",
            " 0.9996697 ] \n",
            ", Min Accs Foc: [0.99753845 0.99638295 0.9983287  0.9974895  0.99872434 0.9987211\n",
            " 0.9964107 ] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 9700 , Mean Loss: 1.2189314e-07 , Max Loss: 2.3784269e-06 , Mean Acc: 0.9997694 , Min Acc: 0.97416663 , Learning rate: 3.5653954e-06 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 9700 Mean Loss: 1.07547386e-07 , Max Loss: 1.29995215e-05 , Mean Acc: 0.99977475 , Min Acc: 0.9963945 \n",
            ", Mean Accs Foc [0.99974424 0.9997031  0.99978393 0.9997759  0.99992573 0.99981964\n",
            " 0.9996704 ] \n",
            ", Min Accs Foc: [0.9975454  0.9963945  0.99833244 0.9974867  0.9987261  0.9987082\n",
            " 0.99641764] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 9800 , Mean Loss: 1.2229692e-07 , Max Loss: 2.3795708e-06 , Mean Acc: 0.999769 , Min Acc: 0.9776955 , Learning rate: 1.6411624e-06 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 9800 Mean Loss: 1.07563615e-07 , Max Loss: 1.2917129e-05 , Mean Acc: 0.99977374 , Min Acc: 0.99640596 \n",
            ", Mean Accs Foc [0.99974215 0.9996994  0.999784   0.99977666 0.99992585 0.99981916\n",
            " 0.9996686 ] \n",
            ", Min Accs Foc: [0.9975499  0.99640596 0.99833435 0.99748665 0.99872625 0.9987149\n",
            " 0.9964219 ] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 9900 , Mean Loss: 1.2226928e-07 , Max Loss: 2.3959292e-06 , Mean Acc: 0.99976957 , Min Acc: 0.97972274 , Learning rate: 4.854545e-07 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 9900 Mean Loss: 1.07543904e-07 , Max Loss: 1.2957435e-05 , Mean Acc: 0.9997746 , Min Acc: 0.99640036 \n",
            ", Mean Accs Foc [0.99974346 0.9997019  0.9997842  0.99977654 0.99992573 0.99982\n",
            " 0.9996699 ] \n",
            ", Min Accs Foc: [0.9975479  0.99640036 0.998333   0.9974852  0.9987271  0.9987054\n",
            " 0.99641913] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 10000 , Mean Loss: 1.234629e-07 , Max Loss: 2.4215126e-06 , Mean Acc: 0.9997687 , Min Acc: 0.9747608 , Learning rate: 1e-07 \n",
            "\n",
            "Minimum mean loss attained in evaluation: 1.075439044484483e-07\n",
            "Minimum max loss attained in evaluation: 9.98032555799e-06\n",
            "Maximum mean accuracy attained in evaluation: 0.9997745752334595\n",
            "Maximum min accuracy attained in evaluation: 0.9968408346176147\n",
            "Time Elapsed for Full Experiment: 0.7830625017484029 minutes\n"
          ]
        }
      ],
      "source": [
        "final_train_state = run_experiment(econ_model, config)\n",
        "\n",
        "# DISCONNECT SESSION (uncomment next 2 lines if you do large run)\n",
        "# from google.colab import runtime\n",
        "# runtime.unassign()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DISCONNECT SESSION (uncomment next 2 lines if you do large run)\n",
        "from google.colab import runtime\n",
        "runtime.unassign()"
      ],
      "metadata": {
        "id": "suVNiqThVOl9"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuClass": "premium",
      "gpuType": "T4",
      "toc_visible": true,
      "authorship_tag": "ABX9TyNhfmhY2A9OHc3bM87zQlA2",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}