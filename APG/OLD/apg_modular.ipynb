{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# APG Algorithm with Modular Components\n",
        "\n",
        "This notebook trains a neural net to output the optimal policy of a nonlinear RBC model using the Analytical Policy Gradient (APG) algorithm. The code has been organized into modular components.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Standard imports\n",
        "import jax\n",
        "import flax\n",
        "import optax\n",
        "import os\n",
        "import json\n",
        "from jax import numpy as jnp, random\n",
        "from flax import linen as nn\n",
        "from flax.training import train_state as ts_class, checkpoints\n",
        "from time import time\n",
        "\n",
        "# Import our modular components\n",
        "from neural_nets.neural_nets import ActorCritic\n",
        "from environemnts.RbcMultiSector import RbcMultiSector\n",
        "from algorithm.epoch_train import get_apg_train_fn\n",
        "from algorithm.eval import get_eval_fn\n",
        "from utilities.plot_results import plot_results\n",
        "\n",
        "print(\"JAX devices:\", jax.devices())\n",
        "print(\"JAX version:\", jax.__version__)\n",
        "print(\"Flax version:\", flax.__version__)\n",
        "print(\"Optax version:\", optax.__version__)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "## Test Environment and Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "env = RbcMultiSector(N=8)\n",
        "rng_test = random.PRNGKey(2)\n",
        "obs_init, state_init = env.reset(rng_test)\n",
        "\n",
        "# Test neural network\n",
        "nn_test = ActorCritic(\n",
        "    actions_dim=env.action_dim,\n",
        "    hidden_dims_actor=[16, 8],\n",
        "    hidden_dims_critic=[16, 8],\n",
        "    activation_final_actor=nn.softmax\n",
        ")\n",
        "params_test = nn_test.init(rng_test, obs_init)\n",
        "action_test, value_test = nn_test.apply(params_test, obs_init)\n",
        "\n",
        "# Test environment step\n",
        "new_obs, new_state, reward, done, info = env.step(rng_test, state_init, action_test)\n",
        "print(\"Environment step test:\")\n",
        "print(f\"New obs shape: {new_obs.shape}\")\n",
        "print(f\"Reward: {reward}\")\n",
        "print(f\"Done: {done}\")\n",
        "print(f\"Action shape: {action_test.shape}\")\n",
        "print(f\"Value: {value_test}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "## Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CREATE LEARNING RATE SCHEDULE\n",
        "lr_schedule = optax.join_schedules(\n",
        "    schedules=[\n",
        "        optax.linear_schedule(0, 0.01, 100),\n",
        "        optax.constant_schedule(0.01),\n",
        "        optax.constant_schedule(0.001),\n",
        "        optax.constant_schedule(0.0001),\n",
        "        optax.cosine_decay_schedule(0.0001, 1000)\n",
        "    ],\n",
        "    boundaries=[300, 1000, 1500, 2000]\n",
        ")\n",
        "\n",
        "config_apg = {\n",
        "    \"learning_rate\": lr_schedule,\n",
        "    \"n_epochs\": 60,\n",
        "    \"steps_per_epoch\": 50,\n",
        "    \"epis_per_step\": 1024*8,\n",
        "    \"periods_per_epis\": 32,\n",
        "    \"eval_n_epis\": 1024*32,\n",
        "    \"eval_periods_per_epis\": 32,\n",
        "    \"gae_lambda\": 0.95,\n",
        "    \"max_grad_norm\": None,\n",
        "    \"layers_actor\": [16, 8],\n",
        "    \"layers_critic\": [8, 4],\n",
        "    \"seed\": 42,\n",
        "    \"fp64_precision\": False,\n",
        "    \"run_name\": \"apg_RbcMS_modular\",\n",
        "    \"date\": \"modular_implementation\",\n",
        "    \"working_dir\": \"./results/\"\n",
        "}\n",
        "\n",
        "print(\"Configuration loaded successfully\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "## Main Experiment Function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_experiment(env, config):\n",
        "    \"\"\"Runs experiment.\"\"\"\n",
        "    \n",
        "    print(\"Starting experiment...\\n\")\n",
        "    if config[\"fp64_precision\"]:\n",
        "        from jax.config import config as config_jax\n",
        "        config_jax.update(\"jax_enable_x64\", True)\n",
        "    \n",
        "    n_cores = len(jax.devices())\n",
        "    \n",
        "    # CREATE NN, RNGS, TRAIN_STATE AND EPOCH UPDATE\n",
        "    nn_policy = ActorCritic(\n",
        "        actions_dim=env.action_dim,\n",
        "        hidden_dims_actor=config[\"layers_actor\"],\n",
        "        hidden_dims_critic=config[\"layers_critic\"],\n",
        "        activation_final_actor=nn.softmax\n",
        "    )\n",
        "    \n",
        "    if config[\"max_grad_norm\"]:\n",
        "        optim = optax.chain(\n",
        "            optax.clip_by_global_norm(config[\"max_grad_norm\"]),\n",
        "            optax.adam(config[\"learning_rate\"])\n",
        "        )\n",
        "    else:\n",
        "        optim = optax.chain(optax.adam(config[\"learning_rate\"]))\n",
        "    \n",
        "    print(\"Neural Net and Optimizer Created...\\n\")\n",
        "    \n",
        "    # INITIALIZE ENV AND ALGO STATES\n",
        "    rng, rng_pol, rng_env, rng_epoch, rng_eval = random.split(\n",
        "        random.PRNGKey(config[\"seed\"]), num=5\n",
        "    )\n",
        "    \n",
        "    obs, env_state = env.reset(rng_env)\n",
        "    train_state = ts_class.TrainState.create(\n",
        "        apply_fn=nn_policy.apply,\n",
        "        params=nn_policy.init(rng_pol, obs),\n",
        "        tx=optim\n",
        "    )\n",
        "    \n",
        "    # GET EPOCH TRAIN AND EVAL FUNCTIONS\n",
        "    epoch_update = jax.jit(get_apg_train_fn(env, config))\n",
        "    eval_fn = jax.jit(get_eval_fn(env, config))\n",
        "    \n",
        "    # COMPILE CODE\n",
        "    print(\"Starting compilation...\\n\")\n",
        "    time_start = time()\n",
        "    epoch_update(train_state, rng_epoch)  # compiles\n",
        "    eval_fn(train_state, rng_eval)\n",
        "    time_compilation = time() - time_start\n",
        "    print(\"Time Elapsed for Compilation:\", time_compilation, \"seconds\")\n",
        "    \n",
        "    print(\"Compilation completed. Proceeding to run an epoch and calculate performance statistics...\\n\")\n",
        "    \n",
        "    # RUN AN EPOCH TO GET TIME STATS\n",
        "    time_start = time()\n",
        "    epoch_update(train_state, rng_epoch)\n",
        "    time_epoch = time() - time_start\n",
        "    print(\"Time Elapsed for Epoch:\", time_epoch, \"seconds\")\n",
        "    print(\"Steps per second:\", n_cores*config[\"steps_per_epoch\"]*config[\"epis_per_step\"]*config[\"periods_per_epis\"]/time_epoch, \"st/s\")\n",
        "    \n",
        "    # RUN AN EVAL TO GET TIME STATS\n",
        "    time_start = time()\n",
        "    eval_fn(train_state, rng_eval)\n",
        "    time_eval = time() - time_start\n",
        "    print(\"Time Elapsed for Eval:\", time_eval, \"seconds\")\n",
        "    \n",
        "    print(\"Estimated time for full experiment\", (time_epoch+time_eval)*config[\"n_epochs\"]/60, \"minutes\\n\")\n",
        "    \n",
        "    print(\"Proceeding to run all epochs...\\n\")\n",
        "    \n",
        "    # CREATE LISTS TO STORE METRICS\n",
        "    mean_losses, mean_actor_losses, mean_critic_losses, mean_critic_accs, mean_grads, max_grads = [], [], [], [], [], []\n",
        "    \n",
        "    # RUN ALL THE EPOCHS\n",
        "    time_start = time()\n",
        "    for i in range(1, config[\"n_epochs\"]+1):\n",
        "        train_state, rng_epoch, epoch_metrics = epoch_update(train_state, rng_epoch)\n",
        "        eval_metrics = eval_fn(train_state, rng_eval)\n",
        "        \n",
        "        mean_losses.append(float(jnp.mean(epoch_metrics[0][0])))\n",
        "        mean_actor_losses.append(float(jnp.mean(epoch_metrics[0][1][0])))\n",
        "        mean_critic_losses.append(float(jnp.mean(epoch_metrics[0][1][1])))\n",
        "        mean_critic_accs.append(float((1-jnp.abs(jnp.mean(epoch_metrics[0][1][2])))*100))\n",
        "        mean_grads.append(float(jnp.mean(epoch_metrics[1][0])))\n",
        "        max_grads.append(float(jnp.mean(jnp.max(epoch_metrics[1][1]))))\n",
        "        \n",
        "        print('Iteration:', i*config[\"steps_per_epoch\"],\n",
        "              \", Mean_loss:\", jnp.mean(epoch_metrics[0][0]),\n",
        "              \", Mean_actor_loss:\", jnp.mean(epoch_metrics[0][1][0]),\n",
        "              \", Mean_critic_loss:\", jnp.mean(epoch_metrics[0][1][1]),\n",
        "              \", Mean_critic_acc:\", (1-jnp.abs(jnp.mean(epoch_metrics[0][1][2])))*100,\n",
        "              \", Mean_grads:\", jnp.mean(epoch_metrics[1][0]),\n",
        "              \", Max_grads:\", jnp.max(epoch_metrics[1][1]),\n",
        "              \", Learning rate:\", config[\"learning_rate\"](i*config[\"steps_per_epoch\"]),\n",
        "              \"\\n\")\n",
        "        \n",
        "        print('Evaluation:     ',\n",
        "              \", Mean_loss:\", eval_metrics[0],\n",
        "              \", Mean_actor_loss:\", eval_metrics[1],\n",
        "              \", Mean_critic_loss:\", eval_metrics[2],\n",
        "              \", Mean_critic_acc:\", eval_metrics[3],\n",
        "              \", Mean_grads:\", eval_metrics[4],\n",
        "              \", Max_grads:\", eval_metrics[5],\n",
        "              \"\\n\")\n",
        "    \n",
        "    # STORE RESULTS\n",
        "    print(\"Minimum loss attained in training:\", min(mean_losses))\n",
        "    \n",
        "    time_fullexp = (time() - time_start)/60\n",
        "    print(\"Time Elapsed for Full Experiment:\", time_fullexp, \"minutes\")\n",
        "    \n",
        "    results = {\n",
        "        \"min_loss\": min(mean_losses),\n",
        "        \"min_actor_loss\": min(mean_actor_losses),\n",
        "        \"min_critic_loss\": min(mean_critic_losses),\n",
        "        \"last_critic_accs\": mean_critic_accs[-1],\n",
        "        \"Time for Full Experiment (m)\": time_fullexp,\n",
        "        \"Time for epoch (s)\": time_epoch,\n",
        "        \"Time for Compilation (s)\": time_compilation,\n",
        "        \"Steps per second\": n_cores * config[\"steps_per_epoch\"] * config[\"periods_per_epis\"]/time_epoch,\n",
        "        \"n_cores\": n_cores,\n",
        "        \"periods_per_epis\": config[\"periods_per_epis\"],\n",
        "        \"epis_per_step\": config[\"epis_per_step\"],\n",
        "        \"steps_per_epoch\": config[\"steps_per_epoch\"],\n",
        "        \"n_epochs\": config[\"n_epochs\"],\n",
        "        \"layers_actor\": config[\"layers_actor\"],\n",
        "        \"layers_critic\": config[\"layers_critic\"],\n",
        "        \"date\": config[\"date\"],\n",
        "        \"seed\": config[\"seed\"],\n",
        "        \"Losses_list\": mean_losses,\n",
        "        \"Actor_losses_list\": mean_actor_losses,\n",
        "        \"Critic_losses_list\": mean_critic_losses,\n",
        "        \"Critic_accs_list\": mean_critic_accs,\n",
        "        \"Mean_grads_list\": mean_grads,\n",
        "        \"Max_grads_list\": max_grads,\n",
        "    }\n",
        "    \n",
        "    # Create results directory if it doesn't exist\n",
        "    if not os.path.exists(config['working_dir']):\n",
        "        os.makedirs(config['working_dir'])\n",
        "    if not os.path.exists(config['working_dir']+config['run_name']):\n",
        "        os.mkdir(config['working_dir']+config['run_name'])\n",
        "    \n",
        "    # Save results\n",
        "    with open(config['working_dir']+config['run_name']+\"/results.json\", \"w\") as write_file:\n",
        "        json.dump(results, write_file)\n",
        "    \n",
        "    # Store checkpoint\n",
        "    checkpoints.save_checkpoint(\n",
        "        ckpt_dir=config['working_dir']+config['run_name'],\n",
        "        target=train_state,\n",
        "        step=config[\"n_epochs\"]*config[\"steps_per_epoch\"]\n",
        "    )\n",
        "    \n",
        "    return train_state, results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "## Run Experiment\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run the main experiment\n",
        "final_train_state, results = run_experiment(RbcMultiSector(N=8), config_apg)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "## Plot Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot the training results\n",
        "plot_results(config_apg, results)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "## Test Trained Policy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test policies in steady state\n",
        "env_test = RbcMultiSector(N=8)\n",
        "params_test = final_train_state.params\n",
        "nn_policy_test = final_train_state.apply_fn\n",
        "rng_test = random.PRNGKey(1)\n",
        "\n",
        "# Test steady state policies\n",
        "obs_init, _ = env_test.reset(rng_test)\n",
        "obs_ss = jnp.zeros_like(obs_init, dtype=jnp.float32)\n",
        "policy_ss = nn_policy_test(params_test, obs_ss)\n",
        "print(\"Trained Policy in steady state (should be ~ 1):\")\n",
        "print(f\"Policy: {policy_ss[0]}\")\n",
        "print(f\"Value: {policy_ss[1]}\")\n",
        "print(f\"Policy sum: {jnp.sum(policy_ss[0])} (should be close to 1)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "## Summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n=== EXPERIMENT SUMMARY ===\")\n",
        "print(f\"Minimum loss achieved: {results['min_loss']:.6f}\")\n",
        "print(f\"Final critic accuracy: {results['last_critic_accs']:.2f}%\")\n",
        "print(f\"Total experiment time: {results['Time for Full Experiment (m)']:.2f} minutes\")\n",
        "print(f\"Steps per second: {results['Steps per second']:.0f}\")\n",
        "print(f\"Results saved to: {config_apg['working_dir']}{config_apg['run_name']}\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
