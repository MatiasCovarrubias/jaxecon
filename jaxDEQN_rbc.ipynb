{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MatiasCovarrubias/jaxecon/blob/main/jaxDEQN_rbc.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmNe6o_4tTEy"
      },
      "source": [
        "# DEQN Solver in Jax: Prelims\n",
        "\n",
        "This notebook trains a neural net to output the optimal policy of a nonlinear Rbc model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ue0dX6Q14A1Q",
        "outputId": "8da2163c-7236-4867-f503-167a29147861"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Mar 11 08:45:50 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   42C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n",
            "Cloning into 'jaxecon'...\n",
            "remote: Enumerating objects: 168, done.\u001b[K\n",
            "remote: Counting objects: 100% (168/168), done.\u001b[K\n",
            "remote: Compressing objects: 100% (119/119), done.\u001b[K\n",
            "remote: Total 168 (delta 89), reused 108 (delta 40), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (168/168), 219.53 KiB | 6.46 MiB/s, done.\n",
            "Resolving deltas: 100% (89/89), done.\n",
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# BACKEND RELATED: the default backend is CPU (change in Edit -> Notebook settings)\n",
        "GPU = True # set True if using GPU (only to see GPU)\n",
        "if GPU:\n",
        "  !nvidia-smi\n",
        "\n",
        "# precision\n",
        "from jax import numpy as jnp, lax, random, config\n",
        "double_precision = True\n",
        "if double_precision:\n",
        "  config.update(\"jax_enable_x64\", True)\n",
        "  precision = jnp.float64\n",
        "else:\n",
        "  precision = jnp.float32\n",
        "\n",
        "# Imports\n",
        "import matplotlib.pyplot as plt, flax.linen as nn, pandas as pd, jax, flax, optax, os, json\n",
        "from flax.training.train_state import TrainState  # Useful dataclass to keep train state\n",
        "from flax.training import checkpoints\n",
        "from time import time\n",
        "from typing import Sequence\n",
        "config.update(\"jax_debug_nans\", True)\n",
        "\n",
        "! git clone https://github.com/MatiasCovarrubias/jaxecon\n",
        "import sys\n",
        "sys.path.insert(0,'/content/jaxecon')\n",
        "from DEQN.neural_nets.neural_nets import NeuralNet\n",
        "from DEQN.econ_models.rbc import Rbc\n",
        "from DEQN.algorithm.simulation import create_episode_simul_fn\n",
        "from DEQN.algorithm.loss import create_batch_loss_fn\n",
        "from DEQN.algorithm.epoch_train import create_epoch_train_fn\n",
        "from DEQN.algorithm.eval import create_eval_fn\n",
        "\n",
        "# Mount Google Drive to store results (a pop up will appear, follow instructions)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "working_dir = \"/content/drive/MyDrive/Jaxecon/Rbc/Experiments/\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create csv file for all experiments related to this econ model"
      ],
      "metadata": {
        "id": "FL5UxCy9Njzo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "columns = [\n",
        "  \"exper_name\",\n",
        "  \"min_mean_loss\",\n",
        "  \"min_max_loss\",\n",
        "  \"max_mean_acc\",\n",
        "  \"max_min_acc\",\n",
        "  \"time_full_exp_minutes\",\n",
        "  \"time_epoque_seconds\",\n",
        "  \"time_compilation_seconds\",\n",
        "  \"steps_per_second\",\n",
        "  \"config\",\n",
        "  \"mean_losses_list\",\n",
        "  \"max_losses_list\",\n",
        "  \"mean_acc_list\",\n",
        "  \"min_acc_list\",\n",
        "]\n",
        "\n",
        "# Create an empty DataFrame with the specified columns\n",
        "df = pd.DataFrame(columns=columns)\n",
        "\n",
        "# Specify the file path for the CSV file in your working directory\n",
        "csv_filename = os.path.join(working_dir, 'experiment_results.csv')\n",
        "# Save the DataFrame to a CSV file if it doesn't exist\n",
        "if not os.path.isfile(csv_filename):\n",
        "  df.to_csv(csv_filename, index=False)\n",
        "  print(f\"New experiments csv saved as {csv_filename}\")\n",
        "else:\n",
        "  print(\"The experiments csv already exists\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VjyKKcptNg3y",
        "outputId": "8bfb2ba2-2bed-43d3-9114-d8ebc544c0bf"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The experiments csv already exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PlXarixBjTC2"
      },
      "source": [
        "# Configure experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "3zWgbr0HjQua",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4717a7e-b785-4c3a-c75a-dea5ce00d8f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of parameters:\n",
            "\n",
            "\u001b[3m                           NeuralNet Summary                            \u001b[0m\n",
            "┏━━━━━━━━━┳━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━┓\n",
            "┃\u001b[1m \u001b[0m\u001b[1mpath   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mmodule   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1minputs    \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1moutputs   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mparams              \u001b[0m\u001b[1m \u001b[0m┃\n",
            "┡━━━━━━━━━╇━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━┩\n",
            "│         │ NeuralNet │ \u001b[2mfloat32\u001b[0m[2] │ \u001b[2mfloat32\u001b[0m[1] │                      │\n",
            "├─────────┼───────────┼────────────┼────────────┼──────────────────────┤\n",
            "│ Dense_0 │ Dense     │ \u001b[2mfloat32\u001b[0m[2] │ \u001b[2mfloat32\u001b[0m[8] │ bias: \u001b[2mfloat32\u001b[0m[8]     │\n",
            "│         │           │            │            │ kernel: \u001b[2mfloat32\u001b[0m[2,8] │\n",
            "│         │           │            │            │                      │\n",
            "│         │           │            │            │ \u001b[1m24 \u001b[0m\u001b[1;2m(96 B)\u001b[0m            │\n",
            "├─────────┼───────────┼────────────┼────────────┼──────────────────────┤\n",
            "│ Dense_1 │ Dense     │ \u001b[2mfloat32\u001b[0m[8] │ \u001b[2mfloat32\u001b[0m[8] │ bias: \u001b[2mfloat32\u001b[0m[8]     │\n",
            "│         │           │            │            │ kernel: \u001b[2mfloat32\u001b[0m[8,8] │\n",
            "│         │           │            │            │                      │\n",
            "│         │           │            │            │ \u001b[1m72 \u001b[0m\u001b[1;2m(288 B)\u001b[0m           │\n",
            "├─────────┼───────────┼────────────┼────────────┼──────────────────────┤\n",
            "│ Dense_2 │ Dense     │ \u001b[2mfloat32\u001b[0m[8] │ \u001b[2mfloat32\u001b[0m[1] │ bias: \u001b[2mfloat32\u001b[0m[1]     │\n",
            "│         │           │            │            │ kernel: \u001b[2mfloat32\u001b[0m[8,1] │\n",
            "│         │           │            │            │                      │\n",
            "│         │           │            │            │ \u001b[1m9 \u001b[0m\u001b[1;2m(36 B)\u001b[0m             │\n",
            "├─────────┼───────────┼────────────┼────────────┼──────────────────────┤\n",
            "│\u001b[1m \u001b[0m\u001b[1m       \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m         \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m          \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m     Total\u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m105 \u001b[0m\u001b[1;2m(420 B)\u001b[0m\u001b[1m         \u001b[0m\u001b[1m \u001b[0m│\n",
            "└─────────┴───────────┴────────────┴────────────┴──────────────────────┘\n",
            "\u001b[1m                                                                        \u001b[0m\n",
            "\u001b[1m                     Total Parameters: 105 \u001b[0m\u001b[1;2m(420 B)\u001b[0m\u001b[1m                      \u001b[0m\n",
            "\n",
            "\n",
            "TOTAL Number of steps (NN updates): 10000 episodes \n",
            "\n"
          ]
        }
      ],
      "source": [
        "'''Config dictionary'''\n",
        "\n",
        "# CREATE CONFIG DICT\n",
        "config = {\n",
        "    # general\n",
        "    \"seed\": 48,\n",
        "    \"exper_name\": \"rbc_smallNN_Mar10_24\",\n",
        "    \"save_dir\": working_dir,\n",
        "    \"restore\": False,                                                            # True if start from restored checkpoint\n",
        "    \"restore_run_name\": None,\n",
        "    \"restore_exper_name\": \"\",\n",
        "    \"seed\": 5,\n",
        "\n",
        "    # neural net\n",
        "    \"layers\": [8,8],              # layers of the NN\n",
        "\n",
        "    # learning rate schedule\n",
        "    \"lr_sch_values\": [0.001,0.001],                                        # values (from the last, we do cosine decay to 0)\n",
        "    \"lr_sch_transitions\": [2000],\n",
        "    \"lr_end_value\": 1e-7,\n",
        "\n",
        "    # simulation\n",
        "    \"periods_per_epis\": 32,\n",
        "    \"simul_vol_scale\": 1.5,        # scale of volatility while simul\n",
        "    \"init_range\": 10,\n",
        "\n",
        "    # loss calculation\n",
        "    \"mc_draws\": 128,               # monte-carlo draws\n",
        "\n",
        "    # training\n",
        "    \"epis_per_step\": 256,         # epoch per steps\n",
        "    \"steps_per_epoch\": 100,       # steps per epoch\n",
        "    \"n_epochs\": 100,               # number of epochs\n",
        "    \"batch_size\": 16,             # size of batch of obs to calculate grads\n",
        "    \"init_range\": 0,\n",
        "    \"checkpoint_frequency\": 1000,\n",
        "\n",
        "    \"config_eval\": {\n",
        "      \"periods_per_epis\": 64,      # periods per episode\n",
        "      \"mc_draws\": 128,         # number of mc draws\n",
        "      \"simul_vol_scale\": 1,        # scale of volatility while simul\n",
        "      \"eval_n_epis\": 128,           # episodes to sample for eval\n",
        "      \"init_range\": 0\n",
        "    }\n",
        "}\n",
        "\n",
        "#create auxiliary config variables for readability\n",
        "config[\"periods_per_step\"] =config[\"periods_per_epis\"]*config[\"epis_per_step\"]\n",
        "config[\"n_batches\"] = config[\"periods_per_step\"]//config[\"batch_size\"]\n",
        "\n",
        "# PRINT AND PLOT KEY CONFIGS\n",
        "print(\"Number of parameters:\")\n",
        "print(NeuralNet(config[\"layers\"] + [Rbc().n_actions]).tabulate(\n",
        "    random.PRNGKey(0),\n",
        "    Rbc().initial_obs(random.PRNGKey(0))\n",
        "    ))\n",
        "\n",
        "print(\"TOTAL Number of steps (NN updates):\", config[\"steps_per_epoch\"]*config[\"n_epochs\"], \"episodes \\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CEAiCNRxC1AJ"
      },
      "source": [
        "# Create experiment\n",
        "Now we create code for the entire experiment as a function to call later."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def run_experiment(econ_model, config):\n",
        "  \"\"\"Runs experiment.\"\"\"\n",
        "\n",
        "\n",
        "  # CREATE NN, RNGS, TRAIN_STATE AND EPOQUE UPDATE\n",
        "  nn = NeuralNet(config[\"layers\"] + [econ_model.n_actions])\n",
        "  rng, rng_pol, rng_econ_model, rng_epoch, rng_eval = random.split(random.PRNGKey(config[\"seed\"]), num=5)  # random number generator\n",
        "\n",
        "  # CREATE LR SCHEDULE\n",
        "  lr_schedule = optax.join_schedules(\n",
        "    schedules= [optax.constant_schedule(i) for i in config[\"lr_sch_values\"][:-1]]\n",
        "                  + [optax.warmup_cosine_decay_schedule(\n",
        "                    init_value=config[\"lr_sch_values\"][-1],\n",
        "                    peak_value=config[\"lr_sch_values\"][-1],\n",
        "                    warmup_steps=0,\n",
        "                    decay_steps=config[\"n_epochs\"]*config[\"steps_per_epoch\"]-config[\"lr_sch_transitions\"][-1],\n",
        "                    end_value=config[\"lr_end_value\"],)],\n",
        "      boundaries=config[\"lr_sch_transitions\"] # the number of episodes at which to switch\n",
        "      )\n",
        "\n",
        "  # INITIALIZE OR RESTORE FULL NN TRAIN STATE\n",
        "  if not config[\"restore\"]:\n",
        "    params=nn.init(rng_pol, jnp.zeros_like(econ_model.initial_obs(rng_econ_model)))\n",
        "    train_state = TrainState.create(apply_fn=nn.apply, params=params, tx=optax.adam(lr_schedule))\n",
        "  else:\n",
        "    train_state_restored = checkpoints.restore_checkpoint(ckpt_dir=config[\"working_dir\"]+config[\"restore_run_name\"], target = None)\n",
        "    params = train_state_restored[\"params\"]\n",
        "    opt_state = train_state_restored[\"opt_state\"]\n",
        "    train_state = TrainState.create(apply_fn=nn.apply, params=params, tx=optax.adam(lr_schedule))\n",
        "    train_state.replace(opt_state=opt_state)\n",
        "\n",
        "  # GET TRAIN AND EVAL FUNCTIONS\n",
        "  simul_fn = jax.jit(create_episode_simul_fn(econ_model,config))\n",
        "  loss_fn = jax.jit(create_batch_loss_fn(econ_model,config))\n",
        "  train_epoch_fn  = jax.jit(create_epoch_train_fn(econ_model, config, simul_fn, loss_fn))\n",
        "  eval_fn  = jax.jit(create_eval_fn(config, simul_fn, loss_fn))\n",
        "\n",
        "  # COMPILE CODE\n",
        "  time_start = time()\n",
        "  train_epoch_fn(train_state, rng_epoch)  # compiles\n",
        "  eval_fn(train_state, rng_epoch) # compiles\n",
        "  time_compilation = time() - time_start\n",
        "  print(\"Time Elapsed for Compilation:\", time_compilation, \"seconds\")\n",
        "\n",
        "  # RUN AN EPOCH TO GET TIME STATS\n",
        "  time_start = time()\n",
        "  train_epoch_fn(train_state, rng_epoch) # run one epoque\n",
        "  time_epoch = time() - time_start\n",
        "  print(\"Time Elapsed for epoch:\", time_epoch, \"seconds\")\n",
        "\n",
        "  time_start = time()\n",
        "  eval_fn(train_state, rng_epoch) # run one epoque\n",
        "  time_eval = time() - time_start\n",
        "  print(\"Time Elapsed for eval:\", time_eval, \"seconds\")\n",
        "\n",
        "  time_experiment = (time_epoch + time_eval)*config[\"n_epochs\"]/60\n",
        "  print(\"Estimated time for full experiment\", time_experiment, \"minutes\")\n",
        "\n",
        "  steps_per_second = config[\"steps_per_epoch\"]*config[\"periods_per_step\"]/time_epoch\n",
        "  print(\"Steps per second:\", steps_per_second, \"st/s\")\n",
        "\n",
        "  # CREATE LISTS TO STORE METRICS\n",
        "  mean_losses, max_losses, mean_accuracy, min_accuracy = [], [], [], []\n",
        "\n",
        "  # RUN ALL THE EPOCHS\n",
        "  time_start = time()\n",
        "  for i in range(1,config[\"n_epochs\"]+1):\n",
        "\n",
        "    # eval\n",
        "    eval_metrics = eval_fn(train_state, rng_eval)\n",
        "    print('EVALUATION:\\n',\n",
        "      'Iteration:', train_state.step,\n",
        "      \"Mean Loss:\", eval_metrics[0],\n",
        "      \", Max Loss:\", eval_metrics[1],\n",
        "      \", Mean Acc:\", eval_metrics[2],\n",
        "      \", Min Acc:\", eval_metrics[3], \"\\n\"\n",
        "      \", Mean Accs Foc\", eval_metrics[4], \"\\n\"\n",
        "      \", Min Accs Foc:\", eval_metrics[5],\n",
        "      \"\\n\")\n",
        "\n",
        "    # run epoch\n",
        "    train_state, rng_epoch, epoch_metrics = train_epoch_fn(train_state, rng_epoch)\n",
        "    print('TRAINING:\\n',\n",
        "          'Iteration:', train_state.step,\n",
        "          \", Mean Loss:\", jnp.mean(epoch_metrics[0]),\n",
        "          \", Max Loss:\", jnp.mean(epoch_metrics[1]),\n",
        "          \", Mean Acc:\", jnp.mean(epoch_metrics[2]),\n",
        "          \", Min Acc:\", jnp.min(epoch_metrics[3]),\n",
        "          \", Learning rate:\", lr_schedule(train_state.step),\n",
        "          \"\\n\"\n",
        "          )\n",
        "\n",
        "    # checkpoint\n",
        "    if train_state.step>=config[\"checkpoint_frequency\"] and train_state.step%config[\"checkpoint_frequency\"]==0:\n",
        "      checkpoints.save_checkpoint(ckpt_dir=config['save_dir']+config['exper_name'], target=train_state, step=train_state.step)\n",
        "\n",
        "      # store results\n",
        "      mean_losses.append(float(eval_metrics[0]))\n",
        "      max_losses.append(float(eval_metrics[1]))\n",
        "      mean_accuracy.append(float(eval_metrics[2]))\n",
        "      min_accuracy.append(float(eval_metrics[3]))\n",
        "\n",
        "    #end of inner loop\n",
        "\n",
        "  # PRINT RESULTS\n",
        "  print(\"Minimum mean loss attained in evaluation:\", min(mean_losses))\n",
        "  print(\"Minimum max loss attained in evaluation:\", min(max_losses))\n",
        "  print(\"Maximum mean accuracy attained in evaluation:\", max(mean_accuracy))\n",
        "  print(\"Maximum min accuracy attained in evaluation:\", max(min_accuracy))\n",
        "  time_fullexp = (time() - time_start)/60\n",
        "  print(\"Time Elapsed for Full Experiment:\", time_fullexp, \"minutes\")\n",
        "\n",
        "  # STORE RESULTS\n",
        "  results = {\n",
        "    \"exper_name\": config[\"exper_name\"],\n",
        "    \"min_mean_loss\":  min(mean_losses),\n",
        "    \"min_max_loss\": max(max_losses),\n",
        "    \"max_mean_acc\": max(mean_accuracy),\n",
        "    \"max_min_acc\": max(min_accuracy),\n",
        "    \"time_full_exp_minutes\": time_fullexp,\n",
        "    \"time_epoque_seconds\": time_epoch,\n",
        "    \"time_compilation_seconds\": time_compilation,\n",
        "    \"steps_per_second\": steps_per_second,\n",
        "    \"config\": config,\n",
        "    \"mean_losses_list\": mean_losses,\n",
        "    \"max_losses_list\": max_losses,\n",
        "    \"mean_acc_list\": mean_accuracy,\n",
        "    \"min_acc_list\": min_accuracy,\n",
        "  }\n",
        "\n",
        "  # store to json\n",
        "  if not os.path.exists(config['save_dir']+config['exper_name']):\n",
        "    os.mkdir(config['save_dir']+config['exper_name'])\n",
        "  with open(config['save_dir']+config['exper_name']+\"/results.json\", \"w\") as write_file:\n",
        "    json.dump(results, write_file)\n",
        "\n",
        "  # PLOT LEARNING\n",
        "\n",
        "  # Mean Losses\n",
        "  plt.plot([(i+1)*config[\"checkpoint_frequency\"] for i in range(len(mean_losses))], mean_losses)\n",
        "  plt.xlabel('Steps (NN updates)')\n",
        "  plt.ylabel('Mean Losses')\n",
        "  plt.savefig(config['save_dir']+config['exper_name']+'/mean_losses.jpg')\n",
        "  plt.close()\n",
        "\n",
        "  plt.plot([(i+1)*config[\"checkpoint_frequency\"] for i in range(len(max_losses))], max_losses)\n",
        "  plt.xlabel('Steps (NN updates)')\n",
        "  plt.ylabel('Max Losses')\n",
        "  plt.savefig(config['save_dir']+config['exper_name']+'/mean_losses.jpg')\n",
        "  plt.close()\n",
        "\n",
        "  # Mean Accuracy\n",
        "  plt.plot([(i+1)*config[\"checkpoint_frequency\"] for i in range(len(mean_accuracy))], mean_accuracy)\n",
        "  plt.xlabel('Steps (NN updates)')\n",
        "  plt.ylabel('Mean Accuracy (%)')\n",
        "  plt.savefig(config['save_dir']+config['exper_name']+'/mean_accuracy.jpg')\n",
        "  plt.close()\n",
        "\n",
        "  # Min Accuracy\n",
        "  plt.plot([(i+1)*config[\"checkpoint_frequency\"] for i in range(len(min_accuracy))], min_accuracy)\n",
        "  plt.xlabel('Steps (NN updates)')\n",
        "  plt.ylabel('Minimum Accuracy (%)')\n",
        "  plt.savefig(config['save_dir']+config['exper_name']+'/min_accuracy.jpg')\n",
        "  plt.close()\n",
        "\n",
        "  # Learning rate schedule\n",
        "  plt.plot([(i+1)*config[\"checkpoint_frequency\"] for i in range(len(mean_losses))], [lr_schedule((i+1)*config[\"checkpoint_frequency\"]) for i in range(len(mean_losses))])\n",
        "  plt.xlabel('Steps (NN updates)')\n",
        "  plt.ylabel('Learning Rate')\n",
        "  plt.savefig(config['save_dir']+config['exper_name']+'/learning_rate.jpg')\n",
        "  plt.close()\n",
        "\n",
        "  return train_state"
      ],
      "metadata": {
        "id": "tw69_Ic-dcVr"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run experiment\n",
        "*Finally*, we run the experiment abd get the trained parameter plus useful info."
      ],
      "metadata": {
        "id": "WdkzmdmHk_Il"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "awmY1xXgDOcU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9493bea9-b288-4b62-faa0-700be9abc3f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time Elapsed for Compilation: 6.7579779624938965 seconds\n",
            "Time Elapsed for epoch: 0.6061084270477295 seconds\n",
            "Time Elapsed for eval: 0.004477977752685547 seconds\n",
            "Estimated time for full experiment 1.0176440080006917 minutes\n",
            "Steps per second: 1351573.3546062214 st/s\n",
            "EVALUATION:\n",
            " Iteration: 0 Mean Loss: 0.0033413086 , Max Loss: 0.032399423 , Mean Acc: 0.94753325 , Min Acc: 0.8200016 \n",
            ", Mean Accs Foc [0.94753325] \n",
            ", Min Accs Foc: [0.8200016] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 100 , Mean Loss: 0.0016367657 , Max Loss: 0.0051183635 , Mean Acc: 0.96434903 , Min Acc: 0.8352863 , Learning rate: 0.001 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 100 Mean Loss: 0.000878623 , Max Loss: 0.005064266 , Mean Acc: 0.9751673 , Min Acc: 0.92883635 \n",
            ", Mean Accs Foc [0.9751673] \n",
            ", Min Accs Foc: [0.92883635] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 200 , Mean Loss: 0.0005626963 , Max Loss: 0.0024158438 , Mean Acc: 0.9809046 , Min Acc: 0.868834 , Learning rate: 0.001 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 200 Mean Loss: 0.00036315792 , Max Loss: 0.008054408 , Mean Acc: 0.98558724 , Min Acc: 0.91025364 \n",
            ", Mean Accs Foc [0.98558724] \n",
            ", Min Accs Foc: [0.91025364] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 300 , Mean Loss: 0.00037504552 , Max Loss: 0.0024904625 , Mean Acc: 0.98611355 , Min Acc: 0.8287842 , Learning rate: 0.001 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 300 Mean Loss: 0.00037986494 , Max Loss: 0.013642785 , Mean Acc: 0.98553985 , Min Acc: 0.88319767 \n",
            ", Mean Accs Foc [0.98553985] \n",
            ", Min Accs Foc: [0.88319767] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 400 , Mean Loss: 0.00022919725 , Max Loss: 0.0015371314 , Mean Acc: 0.98950666 , Min Acc: 0.8516896 , Learning rate: 0.001 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 400 Mean Loss: 5.289616e-05 , Max Loss: 0.0033915292 , Mean Acc: 0.99472666 , Min Acc: 0.94176316 \n",
            ", Mean Accs Foc [0.99472666] \n",
            ", Min Accs Foc: [0.94176316] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 500 , Mean Loss: 3.981487e-05 , Max Loss: 0.0003318291 , Mean Acc: 0.99587286 , Min Acc: 0.88874626 , Learning rate: 0.001 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 500 Mean Loss: 2.5763109e-05 , Max Loss: 0.0014835133 , Mean Acc: 0.9965354 , Min Acc: 0.9614836 \n",
            ", Mean Accs Foc [0.9965354] \n",
            ", Min Accs Foc: [0.9614836] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 600 , Mean Loss: 2.276816e-05 , Max Loss: 0.00018809068 , Mean Acc: 0.9968589 , Min Acc: 0.9224167 , Learning rate: 0.001 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 600 Mean Loss: 1.905805e-05 , Max Loss: 0.0011252122 , Mean Acc: 0.99711776 , Min Acc: 0.9664558 \n",
            ", Mean Accs Foc [0.99711776] \n",
            ", Min Accs Foc: [0.9664558] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 700 , Mean Loss: 1.7204831e-05 , Max Loss: 0.00014530907 , Mean Acc: 0.9973115 , Min Acc: 0.93388486 , Learning rate: 0.001 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 700 Mean Loss: 1.5710222e-05 , Max Loss: 0.001027937 , Mean Acc: 0.9974713 , Min Acc: 0.96793854 \n",
            ", Mean Accs Foc [0.9974713] \n",
            ", Min Accs Foc: [0.96793854] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 800 , Mean Loss: 1.3869456e-05 , Max Loss: 0.00011809169 , Mean Acc: 0.9976066 , Min Acc: 0.92737794 , Learning rate: 0.001 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 800 Mean Loss: 1.2871427e-05 , Max Loss: 0.00092181546 , Mean Acc: 0.99772227 , Min Acc: 0.9696386 \n",
            ", Mean Accs Foc [0.99772227] \n",
            ", Min Accs Foc: [0.9696386] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 900 , Mean Loss: 1.1250436e-05 , Max Loss: 9.540405e-05 , Mean Acc: 0.99784005 , Min Acc: 0.9399078 , Learning rate: 0.001 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 900 Mean Loss: 1.0413318e-05 , Max Loss: 0.00079227943 , Mean Acc: 0.99794006 , Min Acc: 0.97185254 \n",
            ", Mean Accs Foc [0.99794006] \n",
            ", Min Accs Foc: [0.97185254] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 1000 , Mean Loss: 9.1822785e-06 , Max Loss: 7.701443e-05 , Mean Acc: 0.9980363 , Min Acc: 0.9483187 , Learning rate: 0.001 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 1000 Mean Loss: 8.573459e-06 , Max Loss: 0.0005567904 , Mean Acc: 0.99811995 , Min Acc: 0.9764036 \n",
            ", Mean Accs Foc [0.99811995] \n",
            ", Min Accs Foc: [0.9764036] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 1100 , Mean Loss: 7.579507e-06 , Max Loss: 6.243034e-05 , Mean Acc: 0.9981938 , Min Acc: 0.9463723 , Learning rate: 0.001 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 1100 Mean Loss: 6.9580756e-06 , Max Loss: 0.00040516086 , Mean Acc: 0.998271 , Min Acc: 0.9798714 \n",
            ", Mean Accs Foc [0.998271] \n",
            ", Min Accs Foc: [0.9798714] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 1200 , Mean Loss: 6.2505956e-06 , Max Loss: 5.0287366e-05 , Mean Acc: 0.9983337 , Min Acc: 0.9489362 , Learning rate: 0.001 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 1200 Mean Loss: 5.702378e-06 , Max Loss: 0.00032432648 , Mean Acc: 0.9984132 , Min Acc: 0.98199093 \n",
            ", Mean Accs Foc [0.9984132] \n",
            ", Min Accs Foc: [0.98199093] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 1300 , Mean Loss: 5.114248e-06 , Max Loss: 3.9838353e-05 , Mean Acc: 0.99846065 , Min Acc: 0.94822645 , Learning rate: 0.001 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 1300 Mean Loss: 4.6747336e-06 , Max Loss: 0.00026789293 , Mean Acc: 0.99852395 , Min Acc: 0.98363256 \n",
            ", Mean Accs Foc [0.99852395] \n",
            ", Min Accs Foc: [0.98363256] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 1400 , Mean Loss: 4.260102e-06 , Max Loss: 3.2402077e-05 , Mean Acc: 0.99857426 , Min Acc: 0.954615 , Learning rate: 0.001 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 1400 Mean Loss: 3.8667717e-06 , Max Loss: 0.00021573779 , Mean Acc: 0.99864125 , Min Acc: 0.985312 \n",
            ", Mean Accs Foc [0.99864125] \n",
            ", Min Accs Foc: [0.985312] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 1500 , Mean Loss: 3.6129952e-06 , Max Loss: 2.7481643e-05 , Mean Acc: 0.9986845 , Min Acc: 0.94658566 , Learning rate: 0.001 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 1500 Mean Loss: 3.2076123e-06 , Max Loss: 0.00017909914 , Mean Acc: 0.9987483 , Min Acc: 0.9866172 \n",
            ", Mean Accs Foc [0.9987483] \n",
            ", Min Accs Foc: [0.9866172] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 1600 , Mean Loss: 2.9199582e-06 , Max Loss: 2.1134561e-05 , Mean Acc: 0.9987939 , Min Acc: 0.96364546 , Learning rate: 0.001 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 1600 Mean Loss: 2.684852e-06 , Max Loss: 0.0001453096 , Mean Acc: 0.99884754 , Min Acc: 0.98794556 \n",
            ", Mean Accs Foc [0.99884754] \n",
            ", Min Accs Foc: [0.98794556] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 1700 , Mean Loss: 2.581781e-06 , Max Loss: 1.9115983e-05 , Mean Acc: 0.9988761 , Min Acc: 0.9452239 , Learning rate: 0.001 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 1700 Mean Loss: 2.2868862e-06 , Max Loss: 0.0001229044 , Mean Acc: 0.99892926 , Min Acc: 0.9889138 \n",
            ", Mean Accs Foc [0.99892926] \n",
            ", Min Accs Foc: [0.9889138] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 1800 , Mean Loss: 2.2121696e-06 , Max Loss: 1.635601e-05 , Mean Acc: 0.9989595 , Min Acc: 0.9444464 , Learning rate: 0.001 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 1800 Mean Loss: 1.9243632e-06 , Max Loss: 0.00010296837 , Mean Acc: 0.9990103 , Min Acc: 0.98985267 \n",
            ", Mean Accs Foc [0.9990103] \n",
            ", Min Accs Foc: [0.98985267] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 1900 , Mean Loss: 1.9126778e-06 , Max Loss: 1.40944885e-05 , Mean Acc: 0.9990299 , Min Acc: 0.9332762 , Learning rate: 0.001 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 1900 Mean Loss: 1.6642521e-06 , Max Loss: 8.627937e-05 , Mean Acc: 0.9990745 , Min Acc: 0.99071133 \n",
            ", Mean Accs Foc [0.9990745] \n",
            ", Min Accs Foc: [0.99071133] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 2000 , Mean Loss: 1.7187533e-06 , Max Loss: 1.2668141e-05 , Mean Acc: 0.99907917 , Min Acc: 0.9429813 , Learning rate: 0.001 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 2000 Mean Loss: 1.510703e-06 , Max Loss: 7.593519e-05 , Mean Acc: 0.999111 , Min Acc: 0.9912859 \n",
            ", Mean Accs Foc [0.999111] \n",
            ", Min Accs Foc: [0.9912859] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 2100 , Mean Loss: 1.6069079e-06 , Max Loss: 1.1862728e-05 , Mean Acc: 0.9991096 , Min Acc: 0.9454311 , Learning rate: 0.0009996145566685496 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 2100 Mean Loss: 1.3715644e-06 , Max Loss: 6.203011e-05 , Mean Acc: 0.9991448 , Min Acc: 0.9921241 \n",
            ", Mean Accs Foc [0.9991448] \n",
            ", Min Accs Foc: [0.9921241] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 2200 , Mean Loss: 1.462161e-06 , Max Loss: 1.0529981e-05 , Mean Acc: 0.99914145 , Min Acc: 0.91730255 , Learning rate: 0.0009984588209998775 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 2200 Mean Loss: 1.2946459e-06 , Max Loss: 5.145794e-05 , Mean Acc: 0.9991639 , Min Acc: 0.9928266 \n",
            ", Mean Accs Foc [0.9991639] \n",
            ", Min Accs Foc: [0.9928266] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 2300 , Mean Loss: 1.3965828e-06 , Max Loss: 1.0044458e-05 , Mean Acc: 0.99915975 , Min Acc: 0.9462443 , Learning rate: 0.0009965345750546153 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 2300 Mean Loss: 1.2243949e-06 , Max Loss: 4.3241445e-05 , Mean Acc: 0.99918306 , Min Acc: 0.9934242 \n",
            ", Mean Accs Foc [0.99918306] \n",
            ", Min Accs Foc: [0.9934242] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 2400 , Mean Loss: 1.3304941e-06 , Max Loss: 9.398306e-06 , Mean Acc: 0.9991731 , Min Acc: 0.92243123 , Learning rate: 0.0009938447858805393 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 2400 Mean Loss: 1.1814849e-06 , Max Loss: 4.2070496e-05 , Mean Acc: 0.9991965 , Min Acc: 0.9935138 \n",
            ", Mean Accs Foc [0.9991965] \n",
            ", Min Accs Foc: [0.9935138] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 2500 , Mean Loss: 1.3071395e-06 , Max Loss: 9.38838e-06 , Mean Acc: 0.99918514 , Min Acc: 0.92365426 , Learning rate: 0.000990393600937595 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 2500 Mean Loss: 1.1470029e-06 , Max Loss: 4.1570947e-05 , Mean Acc: 0.9992056 , Min Acc: 0.99355245 \n",
            ", Mean Accs Foc [0.9992056] \n",
            ", Min Accs Foc: [0.99355245] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 2600 , Mean Loss: 1.2470628e-06 , Max Loss: 8.658231e-06 , Mean Acc: 0.99919355 , Min Acc: 0.93535364 , Learning rate: 0.0009861863417028184 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 2600 Mean Loss: 1.1173645e-06 , Max Loss: 4.302223e-05 , Mean Acc: 0.9992117 , Min Acc: 0.99344087 \n",
            ", Mean Accs Foc [0.9992117] \n",
            ", Min Accs Foc: [0.99344087] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 2700 , Mean Loss: 1.2467265e-06 , Max Loss: 8.800612e-06 , Mean Acc: 0.99919784 , Min Acc: 0.93303794 , Learning rate: 0.000981229495465001 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 2700 Mean Loss: 1.0947952e-06 , Max Loss: 3.8060498e-05 , Mean Acc: 0.9992111 , Min Acc: 0.9938307 \n",
            ", Mean Accs Foc [0.9992111] \n",
            ", Min Accs Foc: [0.9938307] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 2800 , Mean Loss: 1.1858706e-06 , Max Loss: 7.992182e-06 , Mean Acc: 0.9992044 , Min Acc: 0.9501421 , Learning rate: 0.0009755307053217621 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 2800 Mean Loss: 1.0759193e-06 , Max Loss: 4.2224507e-05 , Mean Acc: 0.9992224 , Min Acc: 0.99350196 \n",
            ", Mean Accs Foc [0.9992224] \n",
            ", Min Accs Foc: [0.99350196] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 2900 , Mean Loss: 1.1653453e-06 , Max Loss: 7.841033e-06 , Mean Acc: 0.9992108 , Min Acc: 0.9279988 , Learning rate: 0.000969098758394446 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 2900 Mean Loss: 1.0613312e-06 , Max Loss: 4.6364865e-05 , Mean Acc: 0.99922705 , Min Acc: 0.9931908 \n",
            ", Mean Accs Foc [0.99922705] \n",
            ", Min Accs Foc: [0.9931908] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 3000 , Mean Loss: 1.1645352e-06 , Max Loss: 7.836367e-06 , Mean Acc: 0.99921143 , Min Acc: 0.94603026 , Learning rate: 0.0009619435722790178 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 3000 Mean Loss: 1.0516783e-06 , Max Loss: 4.2912056e-05 , Mean Acc: 0.9992341 , Min Acc: 0.9934493 \n",
            ", Mean Accs Foc [0.9992341] \n",
            ", Min Accs Foc: [0.9934493] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 3100 , Mean Loss: 1.1868341e-06 , Max Loss: 8.304684e-06 , Mean Acc: 0.99921405 , Min Acc: 0.9339464 , Learning rate: 0.0009540761797538494 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 3100 Mean Loss: 1.037776e-06 , Max Loss: 3.6259895e-05 , Mean Acc: 0.99923277 , Min Acc: 0.9939784 \n",
            ", Mean Accs Foc [0.99923277] \n",
            ", Min Accs Foc: [0.9939784] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 3200 , Mean Loss: 1.172317e-06 , Max Loss: 8.034522e-06 , Mean Acc: 0.9992132 , Min Acc: 0.9441493 , Learning rate: 0.0009455087117679745 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 3200 Mean Loss: 1.0393013e-06 , Max Loss: 4.2356296e-05 , Mean Acc: 0.99924004 , Min Acc: 0.9934918 \n",
            ", Mean Accs Foc [0.99924004] \n",
            ", Min Accs Foc: [0.9934918] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 3300 , Mean Loss: 1.1176832e-06 , Max Loss: 7.4148084e-06 , Mean Acc: 0.9992232 , Min Acc: 0.9516609 , Learning rate: 0.000936254378736045 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 3300 Mean Loss: 1.01278e-06 , Max Loss: 3.931952e-05 , Mean Acc: 0.9992368 , Min Acc: 0.9937295 \n",
            ", Mean Accs Foc [0.9992368] \n",
            ", Min Accs Foc: [0.9937295] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 3400 , Mean Loss: 1.1351565e-06 , Max Loss: 7.718572e-06 , Mean Acc: 0.9992232 , Min Acc: 0.94379216 , Learning rate: 0.0009263274501688283 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 3400 Mean Loss: 1.0115975e-06 , Max Loss: 3.9703173e-05 , Mean Acc: 0.9992473 , Min Acc: 0.99369895 \n",
            ", Mean Accs Foc [0.9992473] \n",
            ", Min Accs Foc: [0.99369895] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 3500 , Mean Loss: 1.1376547e-06 , Max Loss: 7.754198e-06 , Mean Acc: 0.99922276 , Min Acc: 0.9391972 , Learning rate: 0.0009157432326706575 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 3500 Mean Loss: 1.0213589e-06 , Max Loss: 3.7722217e-05 , Mean Acc: 0.99924207 , Min Acc: 0.99385816 \n",
            ", Mean Accs Foc [0.99924207] \n",
            ", Min Accs Foc: [0.99385816] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 3600 , Mean Loss: 1.1154411e-06 , Max Loss: 7.5560574e-06 , Mean Acc: 0.9992297 , Min Acc: 0.9360398 , Learning rate: 0.000904518046337755 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 3600 Mean Loss: 1.0061127e-06 , Max Loss: 4.1729432e-05 , Mean Acc: 0.99925095 , Min Acc: 0.99354017 \n",
            ", Mean Accs Foc [0.99925095] \n",
            ", Min Accs Foc: [0.99354017] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 3700 , Mean Loss: 1.1255082e-06 , Max Loss: 7.783636e-06 , Mean Acc: 0.99923146 , Min Acc: 0.9354596 , Learning rate: 0.0008926691995938285 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 3700 Mean Loss: 9.836631e-07 , Max Loss: 4.1022446e-05 , Mean Acc: 0.9992555 , Min Acc: 0.9935951 \n",
            ", Mean Accs Foc [0.9992555] \n",
            ", Min Accs Foc: [0.9935951] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 3800 , Mean Loss: 1.1070414e-06 , Max Loss: 7.542998e-06 , Mean Acc: 0.99923307 , Min Acc: 0.94316494 , Learning rate: 0.0008802149625017355 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 3800 Mean Loss: 9.765567e-07 , Max Loss: 3.577127e-05 , Mean Acc: 0.99925566 , Min Acc: 0.9940191 \n",
            ", Mean Accs Foc [0.99925566] \n",
            ", Min Accs Foc: [0.9940191] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 3900 , Mean Loss: 1.1223416e-06 , Max Loss: 7.698312e-06 , Mean Acc: 0.9992297 , Min Acc: 0.938889 , Learning rate: 0.0008671745385923711 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 3900 Mean Loss: 9.794653e-07 , Max Loss: 3.3286342e-05 , Mean Acc: 0.99924207 , Min Acc: 0.99423057 \n",
            ", Mean Accs Foc [0.99924207] \n",
            ", Min Accs Foc: [0.99423057] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 4000 , Mean Loss: 1.093184e-06 , Max Loss: 7.366963e-06 , Mean Acc: 0.9992363 , Min Acc: 0.9450676 , Learning rate: 0.0008535680352542144 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 4000 Mean Loss: 9.805744e-07 , Max Loss: 4.0360115e-05 , Mean Acc: 0.999252 , Min Acc: 0.99364704 \n",
            ", Mean Accs Foc [0.999252] \n",
            ", Min Accs Foc: [0.99364704] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 4100 , Mean Loss: 1.078068e-06 , Max Loss: 7.0455935e-06 , Mean Acc: 0.9992333 , Min Acc: 0.95908266 , Learning rate: 0.0008394164327291943 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 4100 Mean Loss: 9.752881e-07 , Max Loss: 3.8573347e-05 , Mean Acc: 0.9992609 , Min Acc: 0.99378926 \n",
            ", Mean Accs Foc [0.9992609] \n",
            ", Min Accs Foc: [0.99378926] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 4200 , Mean Loss: 1.0885617e-06 , Max Loss: 7.3578412e-06 , Mean Acc: 0.99923825 , Min Acc: 0.9228096 , Learning rate: 0.0008247415517626754 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 4200 Mean Loss: 9.60212e-07 , Max Loss: 3.4254088e-05 , Mean Acc: 0.99925745 , Min Acc: 0.9941473 \n",
            ", Mean Accs Foc [0.99925745] \n",
            ", Min Accs Foc: [0.9941473] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 4300 , Mean Loss: 1.0688112e-06 , Max Loss: 7.02138e-06 , Mean Acc: 0.99923766 , Min Acc: 0.95708644 , Learning rate: 0.0008095660199574516 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 4300 Mean Loss: 9.673836e-07 , Max Loss: 3.233585e-05 , Mean Acc: 0.9992503 , Min Acc: 0.99431354 \n",
            ", Mean Accs Foc [0.9992503] \n",
            ", Min Accs Foc: [0.99431354] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 4400 , Mean Loss: 1.0765348e-06 , Max Loss: 7.2402936e-06 , Mean Acc: 0.9992413 , Min Acc: 0.9331088 , Learning rate: 0.000793913236883622 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 4400 Mean Loss: 9.57957e-07 , Max Loss: 3.8121565e-05 , Mean Acc: 0.9992674 , Min Acc: 0.99382573 \n",
            ", Mean Accs Foc [0.9992674] \n",
            ", Min Accs Foc: [0.99382573] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 4500 , Mean Loss: 1.0621175e-06 , Max Loss: 7.125891e-06 , Mean Acc: 0.99924606 , Min Acc: 0.9315878 , Learning rate: 0.0007778073379981501 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 4500 Mean Loss: 9.503527e-07 , Max Loss: 3.4178778e-05 , Mean Acc: 0.99926674 , Min Acc: 0.99415374 \n",
            ", Mean Accs Foc [0.99926674] \n",
            ", Min Accs Foc: [0.99415374] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 4600 , Mean Loss: 1.0428704e-06 , Max Loss: 6.7970664e-06 , Mean Acc: 0.99924594 , Min Acc: 0.95067513 , Learning rate: 0.0007612731574297385 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 4600 Mean Loss: 9.46469e-07 , Max Loss: 4.613948e-05 , Mean Acc: 0.99926007 , Min Acc: 0.9932074 \n",
            ", Mean Accs Foc [0.99926007] \n",
            ", Min Accs Foc: [0.9932074] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 4700 , Mean Loss: 1.0343846e-06 , Max Loss: 6.6209286e-06 , Mean Acc: 0.9992445 , Min Acc: 0.9566879 , Learning rate: 0.0007443361896864027 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 4700 Mean Loss: 9.682813e-07 , Max Loss: 4.5751625e-05 , Mean Acc: 0.9992673 , Min Acc: 0.993236 \n",
            ", Mean Accs Foc [0.9992673] \n",
            ", Min Accs Foc: [0.993236] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 4800 , Mean Loss: 1.0251139e-06 , Max Loss: 6.6388607e-06 , Mean Acc: 0.9992515 , Min Acc: 0.93432295 , Learning rate: 0.0007270225503447864 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 4800 Mean Loss: 9.412968e-07 , Max Loss: 4.4451514e-05 , Mean Acc: 0.9992677 , Min Acc: 0.9933328 \n",
            ", Mean Accs Foc [0.9992677] \n",
            ", Min Accs Foc: [0.9933328] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 4900 , Mean Loss: 1.0180254e-06 , Max Loss: 6.59736e-06 , Mean Acc: 0.9992535 , Min Acc: 0.9483644 , Learning rate: 0.0007093589357818372 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 4900 Mean Loss: 9.2850667e-07 , Max Loss: 5.5726297e-05 , Mean Acc: 0.9992641 , Min Acc: 0.992535 \n",
            ", Mean Accs Foc [0.9992641] \n",
            ", Min Accs Foc: [0.992535] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 5000 , Mean Loss: 1.0177771e-06 , Max Loss: 6.563511e-06 , Mean Acc: 0.99925274 , Min Acc: 0.95579106 , Learning rate: 0.0006913725820109266 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 5000 Mean Loss: 9.152337e-07 , Max Loss: 3.7131493e-05 , Mean Acc: 0.99927485 , Min Acc: 0.99390644 \n",
            ", Mean Accs Foc [0.99927485] \n",
            ", Min Accs Foc: [0.99390644] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 5100 , Mean Loss: 1.0035453e-06 , Max Loss: 6.420044e-06 , Mean Acc: 0.99925625 , Min Acc: 0.95585614 , Learning rate: 0.0006730912226858926 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 5100 Mean Loss: 8.983388e-07 , Max Loss: 3.3607612e-05 , Mean Acc: 0.99928033 , Min Acc: 0.9942028 \n",
            ", Mean Accs Foc [0.99928033] \n",
            ", Min Accs Foc: [0.9942028] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 5200 , Mean Loss: 9.884878e-07 , Max Loss: 6.2382546e-06 , Mean Acc: 0.9992592 , Min Acc: 0.9491914 , Learning rate: 0.000654543046337755 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 5200 Mean Loss: 9.0339836e-07 , Max Loss: 3.493631e-05 , Mean Acc: 0.9992797 , Min Acc: 0.9940893 \n",
            ", Mean Accs Foc [0.9992797] \n",
            ", Min Accs Foc: [0.9940893] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 5300 , Mean Loss: 9.787079e-07 , Max Loss: 6.1113433e-06 , Mean Acc: 0.999261 , Min Acc: 0.9657633 , Learning rate: 0.0006357566529100438 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 5300 Mean Loss: 8.8680787e-07 , Max Loss: 3.1053398e-05 , Mean Acc: 0.9992799 , Min Acc: 0.99442744 \n",
            ", Mean Accs Foc [0.9992799] \n",
            ", Min Accs Foc: [0.99442744] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 5400 , Mean Loss: 9.681836e-07 , Max Loss: 6.049429e-06 , Mean Acc: 0.99926513 , Min Acc: 0.9562616 , Learning rate: 0.00061676100965976 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 5400 Mean Loss: 8.812926e-07 , Max Loss: 2.8795528e-05 , Mean Acc: 0.9992729 , Min Acc: 0.99463385 \n",
            ", Mean Accs Foc [0.9992729] \n",
            ", Min Accs Foc: [0.99463385] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 5500 , Mean Loss: 9.578478e-07 , Max Loss: 5.9653235e-06 , Mean Acc: 0.99926776 , Min Acc: 0.9559201 , Learning rate: 0.0005975854064919633 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 5500 Mean Loss: 8.7221554e-07 , Max Loss: 2.544598e-05 , Mean Acc: 0.99928427 , Min Acc: 0.9949556 \n",
            ", Mean Accs Foc [0.99928427] \n",
            ", Min Accs Foc: [0.9949556] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 5600 , Mean Loss: 9.374205e-07 , Max Loss: 5.7389516e-06 , Mean Acc: 0.9992721 , Min Acc: 0.96987695 , Learning rate: 0.0005782594107968635 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 5600 Mean Loss: 8.523099e-07 , Max Loss: 2.5588093e-05 , Mean Acc: 0.9992897 , Min Acc: 0.99494153 \n",
            ", Mean Accs Foc [0.9992897] \n",
            ", Min Accs Foc: [0.99494153] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 5700 , Mean Loss: 9.748841e-07 , Max Loss: 6.251059e-06 , Mean Acc: 0.999268 , Min Acc: 0.949999 , Learning rate: 0.000558812821859046 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 5700 Mean Loss: 8.362138e-07 , Max Loss: 2.3963083e-05 , Mean Acc: 0.99929494 , Min Acc: 0.9951048 \n",
            ", Mean Accs Foc [0.99929494] \n",
            ", Min Accs Foc: [0.9951048] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 5800 , Mean Loss: 9.300761e-07 , Max Loss: 5.7143334e-06 , Mean Acc: 0.9992764 , Min Acc: 0.94849294 , Learning rate: 0.0005392756249091361 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 5800 Mean Loss: 8.3815644e-07 , Max Loss: 2.3488114e-05 , Mean Acc: 0.99929583 , Min Acc: 0.99515355 \n",
            ", Mean Accs Foc [0.99929583] \n",
            ", Min Accs Foc: [0.99515355] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 5900 , Mean Loss: 9.329522e-07 , Max Loss: 5.851768e-06 , Mean Acc: 0.9992793 , Min Acc: 0.95245206 , Learning rate: 0.0005196779448887464 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 5900 Mean Loss: 8.403289e-07 , Max Loss: 2.3273684e-05 , Mean Acc: 0.9992953 , Min Acc: 0.9951757 \n",
            ", Mean Accs Foc [0.9992953] \n",
            ", Min Accs Foc: [0.9951757] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 6000 , Mean Loss: 9.131058e-07 , Max Loss: 5.653391e-06 , Mean Acc: 0.9992845 , Min Acc: 0.9490203 , Learning rate: 0.00050005 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 6000 Mean Loss: 8.353121e-07 , Max Loss: 2.4148427e-05 , Mean Acc: 0.99929273 , Min Acc: 0.9950859 \n",
            ", Mean Accs Foc [0.99929273] \n",
            ", Min Accs Foc: [0.9950859] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 6100 , Mean Loss: 9.2485607e-07 , Max Loss: 5.80949e-06 , Mean Acc: 0.99928313 , Min Acc: 0.96268356 , Learning rate: 0.0004804220551112537 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 6100 Mean Loss: 8.224295e-07 , Max Loss: 1.84659e-05 , Mean Acc: 0.99929655 , Min Acc: 0.9957028 \n",
            ", Mean Accs Foc [0.99929655] \n",
            ", Min Accs Foc: [0.9957028] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 6200 , Mean Loss: 8.8235436e-07 , Max Loss: 5.359944e-06 , Mean Acc: 0.9992936 , Min Acc: 0.95214224 , Learning rate: 0.00046082437509086395 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 6200 Mean Loss: 8.192667e-07 , Max Loss: 2.2614184e-05 , Mean Acc: 0.9993044 , Min Acc: 0.99524456 \n",
            ", Mean Accs Foc [0.9993044] \n",
            ", Min Accs Foc: [0.99524456] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 6300 , Mean Loss: 8.7921995e-07 , Max Loss: 5.367402e-06 , Mean Acc: 0.99929535 , Min Acc: 0.96427184 , Learning rate: 0.00044128717814095414 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 6300 Mean Loss: 8.1782997e-07 , Max Loss: 2.4435736e-05 , Mean Acc: 0.99930966 , Min Acc: 0.99505675 \n",
            ", Mean Accs Foc [0.99930966] \n",
            ", Min Accs Foc: [0.99505675] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 6400 , Mean Loss: 8.913493e-07 , Max Loss: 5.614035e-06 , Mean Acc: 0.99929637 , Min Acc: 0.9389094 , Learning rate: 0.0004218405892031366 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 6400 Mean Loss: 8.1001826e-07 , Max Loss: 2.0992975e-05 , Mean Acc: 0.99930453 , Min Acc: 0.9954182 \n",
            ", Mean Accs Foc [0.99930453] \n",
            ", Min Accs Foc: [0.9954182] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 6500 , Mean Loss: 8.717201e-07 , Max Loss: 5.3598988e-06 , Mean Acc: 0.9993001 , Min Acc: 0.9502942 , Learning rate: 0.0004025145935080367 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 6500 Mean Loss: 7.999797e-07 , Max Loss: 2.3570803e-05 , Mean Acc: 0.9993106 , Min Acc: 0.995145 \n",
            ", Mean Accs Foc [0.9993106] \n",
            ", Min Accs Foc: [0.995145] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 6600 , Mean Loss: 8.5983567e-07 , Max Loss: 5.2517125e-06 , Mean Acc: 0.9993036 , Min Acc: 0.94824046 , Learning rate: 0.00038333899034024015 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 6600 Mean Loss: 7.8773434e-07 , Max Loss: 1.9734332e-05 , Mean Acc: 0.9993173 , Min Acc: 0.99555767 \n",
            ", Mean Accs Foc [0.9993173] \n",
            ", Min Accs Foc: [0.99555767] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 6700 , Mean Loss: 8.5806164e-07 , Max Loss: 5.280515e-06 , Mean Acc: 0.9993054 , Min Acc: 0.9543288 , Learning rate: 0.00036434334708995616 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 6700 Mean Loss: 7.922298e-07 , Max Loss: 2.8166978e-05 , Mean Acc: 0.9993143 , Min Acc: 0.99469274 \n",
            ", Mean Accs Foc [0.9993143] \n",
            ", Min Accs Foc: [0.99469274] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 6800 , Mean Loss: 8.432844e-07 , Max Loss: 5.1387374e-06 , Mean Acc: 0.99930954 , Min Acc: 0.9294368 , Learning rate: 0.00034555695366224516 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 6800 Mean Loss: 7.870163e-07 , Max Loss: 2.005442e-05 , Mean Acc: 0.9993171 , Min Acc: 0.9955218 \n",
            ", Mean Accs Foc [0.9993171] \n",
            ", Min Accs Foc: [0.9955218] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 6900 , Mean Loss: 8.547175e-07 , Max Loss: 5.317375e-06 , Mean Acc: 0.9993093 , Min Acc: 0.9513961 , Learning rate: 0.0003270087773141074 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 6900 Mean Loss: 7.785176e-07 , Max Loss: 2.5820174e-05 , Mean Acc: 0.99932194 , Min Acc: 0.99491864 \n",
            ", Mean Accs Foc [0.99932194] \n",
            ", Min Accs Foc: [0.99491864] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 7000 , Mean Loss: 8.318673e-07 , Max Loss: 5.050189e-06 , Mean Acc: 0.9993135 , Min Acc: 0.9579127 , Learning rate: 0.0003087274179890734 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 7000 Mean Loss: 7.734702e-07 , Max Loss: 2.1043254e-05 , Mean Acc: 0.99932164 , Min Acc: 0.9954127 \n",
            ", Mean Accs Foc [0.99932164] \n",
            ", Min Accs Foc: [0.9954127] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 7100 , Mean Loss: 8.3062355e-07 , Max Loss: 5.051374e-06 , Mean Acc: 0.9993148 , Min Acc: 0.94696426 , Learning rate: 0.00029074106421816276 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 7100 Mean Loss: 7.6842787e-07 , Max Loss: 1.909928e-05 , Mean Acc: 0.9993238 , Min Acc: 0.9956297 \n",
            ", Mean Accs Foc [0.9993238] \n",
            ", Min Accs Foc: [0.9956297] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 7200 , Mean Loss: 8.3797306e-07 , Max Loss: 5.206595e-06 , Mean Acc: 0.9993162 , Min Acc: 0.9417002 , Learning rate: 0.0002730774496552136 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 7200 Mean Loss: 7.678734e-07 , Max Loss: 1.8952645e-05 , Mean Acc: 0.9993243 , Min Acc: 0.99564654 \n",
            ", Mean Accs Foc [0.9993243] \n",
            ", Min Accs Foc: [0.99564654] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 7300 , Mean Loss: 8.199492e-07 , Max Loss: 4.9236487e-06 , Mean Acc: 0.9993165 , Min Acc: 0.9693758 , Learning rate: 0.0002557638103135973 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 7300 Mean Loss: 7.6459025e-07 , Max Loss: 1.8464876e-05 , Mean Acc: 0.99932337 , Min Acc: 0.9957029 \n",
            ", Mean Accs Foc [0.99932337] \n",
            ", Min Accs Foc: [0.9957029] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 7400 , Mean Loss: 8.117022e-07 , Max Loss: 4.836007e-06 , Mean Acc: 0.9993188 , Min Acc: 0.95907915 , Learning rate: 0.00023882684257026137 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 7400 Mean Loss: 7.55334e-07 , Max Loss: 1.8834504e-05 , Mean Acc: 0.9993268 , Min Acc: 0.9956601 \n",
            ", Mean Accs Foc [0.9993268] \n",
            ", Min Accs Foc: [0.9956601] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 7500 , Mean Loss: 8.055541e-07 , Max Loss: 4.8093048e-06 , Mean Acc: 0.9993217 , Min Acc: 0.9619444 , Learning rate: 0.00022229266200185 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 7500 Mean Loss: 7.575569e-07 , Max Loss: 1.9469386e-05 , Mean Acc: 0.9993267 , Min Acc: 0.9955876 \n",
            ", Mean Accs Foc [0.9993267] \n",
            ", Min Accs Foc: [0.9955876] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 7600 , Mean Loss: 8.2112456e-07 , Max Loss: 4.992715e-06 , Mean Acc: 0.99931896 , Min Acc: 0.95669085 , Learning rate: 0.0002061867631163781 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 7600 Mean Loss: 7.525855e-07 , Max Loss: 2.0584786e-05 , Mean Acc: 0.99932766 , Min Acc: 0.99546295 \n",
            ", Mean Accs Foc [0.99932766] \n",
            ", Min Accs Foc: [0.99546295] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 7700 , Mean Loss: 8.178726e-07 , Max Loss: 5.03743e-06 , Mean Acc: 0.9993229 , Min Acc: 0.9387243 , Learning rate: 0.00019053398004254863 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 7700 Mean Loss: 7.523524e-07 , Max Loss: 2.1151669e-05 , Mean Acc: 0.99932903 , Min Acc: 0.9954009 \n",
            ", Mean Accs Foc [0.99932903] \n",
            ", Min Accs Foc: [0.9954009] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 7800 , Mean Loss: 8.1131657e-07 , Max Loss: 4.9308896e-06 , Mean Acc: 0.99932307 , Min Acc: 0.9453461 , Learning rate: 0.00017535844823732472 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 7800 Mean Loss: 7.5468176e-07 , Max Loss: 2.0663285e-05 , Mean Acc: 0.99932766 , Min Acc: 0.9954543 \n",
            ", Mean Accs Foc [0.99932766] \n",
            ", Min Accs Foc: [0.9954543] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 7900 , Mean Loss: 8.016324e-07 , Max Loss: 4.7666636e-06 , Mean Acc: 0.9993229 , Min Acc: 0.9656047 , Learning rate: 0.00016068356727080588 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 7900 Mean Loss: 7.5716065e-07 , Max Loss: 2.0847394e-05 , Mean Acc: 0.99932766 , Min Acc: 0.9954341 \n",
            ", Mean Accs Foc [0.99932766] \n",
            ", Min Accs Foc: [0.9954341] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 8000 , Mean Loss: 8.0613466e-07 , Max Loss: 4.8571546e-06 , Mean Acc: 0.9993234 , Min Acc: 0.95551515 , Learning rate: 0.0001465319647457856 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 8000 Mean Loss: 7.5553817e-07 , Max Loss: 2.0389461e-05 , Mean Acc: 0.99932694 , Min Acc: 0.99548453 \n",
            ", Mean Accs Foc [0.99932694] \n",
            ", Min Accs Foc: [0.99548453] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 8100 , Mean Loss: 8.042647e-07 , Max Loss: 4.840948e-06 , Mean Acc: 0.99932414 , Min Acc: 0.94798356 , Learning rate: 0.000132925461407629 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 8100 Mean Loss: 7.5024286e-07 , Max Loss: 2.0435242e-05 , Mean Acc: 0.9993297 , Min Acc: 0.99547946 \n",
            ", Mean Accs Foc [0.9993297] \n",
            ", Min Accs Foc: [0.99547946] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 8200 , Mean Loss: 7.953531e-07 , Max Loss: 4.7180433e-06 , Mean Acc: 0.9993249 , Min Acc: 0.9519511 , Learning rate: 0.00011988503749826454 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 8200 Mean Loss: 7.481877e-07 , Max Loss: 2.0732163e-05 , Mean Acc: 0.99933016 , Min Acc: 0.99544674 \n",
            ", Mean Accs Foc [0.99933016] \n",
            ", Min Accs Foc: [0.99544674] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 8300 , Mean Loss: 8.013824e-07 , Max Loss: 4.809698e-06 , Mean Acc: 0.9993248 , Min Acc: 0.93267316 , Learning rate: 0.00010743080040617152 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 8300 Mean Loss: 7.4953084e-07 , Max Loss: 2.0342119e-05 , Mean Acc: 0.9993304 , Min Acc: 0.9954898 \n",
            ", Mean Accs Foc [0.9993304] \n",
            ", Min Accs Foc: [0.9954898] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 8400 , Mean Loss: 7.9788805e-07 , Max Loss: 4.795043e-06 , Mean Acc: 0.99932617 , Min Acc: 0.94806015 , Learning rate: 9.558195366224507e-05 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 8400 Mean Loss: 7.5034393e-07 , Max Loss: 2.0838686e-05 , Mean Acc: 0.99933004 , Min Acc: 0.99543506 \n",
            ", Mean Accs Foc [0.99933004] \n",
            ", Min Accs Foc: [0.99543506] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 8500 , Mean Loss: 7.999102e-07 , Max Loss: 4.82081e-06 , Mean Acc: 0.99932563 , Min Acc: 0.9556814 , Learning rate: 8.435676732934246e-05 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 8500 Mean Loss: 7.473275e-07 , Max Loss: 2.049726e-05 , Mean Acc: 0.9993302 , Min Acc: 0.9954726 \n",
            ", Mean Accs Foc [0.9993302] \n",
            ", Min Accs Foc: [0.9954726] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 8600 , Mean Loss: 7.9280954e-07 , Max Loss: 4.6887144e-06 , Mean Acc: 0.9993255 , Min Acc: 0.9385486 , Learning rate: 7.377254983117162e-05 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 8600 Mean Loss: 7.466207e-07 , Max Loss: 2.078376e-05 , Mean Acc: 0.99933076 , Min Acc: 0.9954411 \n",
            ", Mean Accs Foc [0.99933076] \n",
            ", Min Accs Foc: [0.9954411] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 8700 , Mean Loss: 8.028942e-07 , Max Loss: 4.8528104e-06 , Mean Acc: 0.9993248 , Min Acc: 0.9625691 , Learning rate: 6.384562126395506e-05 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 8700 Mean Loss: 7.454326e-07 , Max Loss: 2.1113308e-05 , Mean Acc: 0.99932927 , Min Acc: 0.9954051 \n",
            ", Mean Accs Foc [0.99932927] \n",
            ", Min Accs Foc: [0.9954051] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 8800 , Mean Loss: 7.936139e-07 , Max Loss: 4.697162e-06 , Mean Acc: 0.999325 , Min Acc: 0.9574518 , Learning rate: 5.459128823202553e-05 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 8800 Mean Loss: 7.4598444e-07 , Max Loss: 2.1301608e-05 , Mean Acc: 0.99933136 , Min Acc: 0.99538463 \n",
            ", Mean Accs Foc [0.99933136] \n",
            ", Min Accs Foc: [0.99538463] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 8900 , Mean Loss: 7.8727095e-07 , Max Loss: 4.643093e-06 , Mean Acc: 0.9993269 , Min Acc: 0.97611994 , Learning rate: 4.6023820246150694e-05 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 8900 Mean Loss: 7.454872e-07 , Max Loss: 2.1259264e-05 , Mean Acc: 0.9993314 , Min Acc: 0.9953892 \n",
            ", Mean Accs Foc [0.9993314] \n",
            ", Min Accs Foc: [0.9953892] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 9000 , Mean Loss: 7.977367e-07 , Max Loss: 4.795591e-06 , Mean Acc: 0.9993265 , Min Acc: 0.9471966 , Learning rate: 3.81564277209822e-05 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 9000 Mean Loss: 7.447585e-07 , Max Loss: 2.1818589e-05 , Mean Acc: 0.9993317 , Min Acc: 0.99532896 \n",
            ", Mean Accs Foc [0.9993317] \n",
            ", Min Accs Foc: [0.99532896] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 9100 , Mean Loss: 7.9063494e-07 , Max Loss: 4.6718915e-06 , Mean Acc: 0.9993264 , Min Acc: 0.95097 , Learning rate: 3.10012416055541e-05 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 9100 Mean Loss: 7.419445e-07 , Max Loss: 2.1440483e-05 , Mean Acc: 0.9993322 , Min Acc: 0.9953696 \n",
            ", Mean Accs Foc [0.9993322] \n",
            ", Min Accs Foc: [0.9953696] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 9200 , Mean Loss: 7.8324706e-07 , Max Loss: 4.594448e-06 , Mean Acc: 0.9993282 , Min Acc: 0.9612054 , Learning rate: 2.4569294678237992e-05 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 9200 Mean Loss: 7.435981e-07 , Max Loss: 2.1612494e-05 , Mean Acc: 0.9993323 , Min Acc: 0.9953511 \n",
            ", Mean Accs Foc [0.9993323] \n",
            ", Min Accs Foc: [0.9953511] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 9300 , Mean Loss: 7.989215e-07 , Max Loss: 4.8369425e-06 , Mean Acc: 0.99932706 , Min Acc: 0.93845206 , Learning rate: 1.8870504534999097e-05 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 9300 Mean Loss: 7.407686e-07 , Max Loss: 2.136052e-05 , Mean Acc: 0.99933267 , Min Acc: 0.99537826 \n",
            ", Mean Accs Foc [0.99933267] \n",
            ", Min Accs Foc: [0.99537826] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 9400 , Mean Loss: 7.9298775e-07 , Max Loss: 4.72393e-06 , Mean Acc: 0.9993264 , Min Acc: 0.9674649 , Learning rate: 1.3913658297181605e-05 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 9400 Mean Loss: 7.4244235e-07 , Max Loss: 2.172903e-05 , Mean Acc: 0.9993324 , Min Acc: 0.99533856 \n",
            ", Mean Accs Foc [0.9993324] \n",
            ", Min Accs Foc: [0.99533856] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 9500 , Mean Loss: 7.877282e-07 , Max Loss: 4.655815e-06 , Mean Acc: 0.9993279 , Min Acc: 0.96455073 , Learning rate: 9.706399062404945e-06 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 9500 Mean Loss: 7.4137523e-07 , Max Loss: 2.1659625e-05 , Mean Acc: 0.9993326 , Min Acc: 0.995346 \n",
            ", Mean Accs Foc [0.9993326] \n",
            ", Min Accs Foc: [0.995346] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 9600 , Mean Loss: 7.864303e-07 , Max Loss: 4.661484e-06 , Mean Acc: 0.9993284 , Min Acc: 0.9604217 , Learning rate: 6.255214119460928e-06 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 9600 Mean Loss: 7.409611e-07 , Max Loss: 2.1680713e-05 , Mean Acc: 0.9993325 , Min Acc: 0.99534374 \n",
            ", Mean Accs Foc [0.9993325] \n",
            ", Min Accs Foc: [0.99534374] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 9700 , Mean Loss: 7.9553524e-07 , Max Loss: 4.7750204e-06 , Mean Acc: 0.9993273 , Min Acc: 0.9449446 , Learning rate: 3.5654249453846e-06 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 9700 Mean Loss: 7.418922e-07 , Max Loss: 2.1884343e-05 , Mean Acc: 0.9993324 , Min Acc: 0.9953219 \n",
            ", Mean Accs Foc [0.9993324] \n",
            ", Min Accs Foc: [0.9953219] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 9800 , Mean Loss: 7.815122e-07 , Max Loss: 4.557849e-06 , Mean Acc: 0.99932814 , Min Acc: 0.9653669 , Learning rate: 1.6411790001226746e-06 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 9800 Mean Loss: 7.416854e-07 , Max Loss: 2.182193e-05 , Mean Acc: 0.9993325 , Min Acc: 0.9953286 \n",
            ", Mean Accs Foc [0.9993325] \n",
            ", Min Accs Foc: [0.9953286] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 9900 , Mean Loss: 7.7983856e-07 , Max Loss: 4.5687652e-06 , Mean Acc: 0.99932975 , Min Acc: 0.96825045 , Learning rate: 4.854433314505857e-07 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 9900 Mean Loss: 7.4175273e-07 , Max Loss: 2.179632e-05 , Mean Acc: 0.99933255 , Min Acc: 0.99533135 \n",
            ", Mean Accs Foc [0.99933255] \n",
            ", Min Accs Foc: [0.99533135] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 10000 , Mean Loss: 7.901133e-07 , Max Loss: 4.6814557e-06 , Mean Acc: 0.99932736 , Min Acc: 0.95669675 , Learning rate: 1e-07 \n",
            "\n",
            "Minimum mean loss attained in evaluation: 7.417527285724645e-07\n",
            "Minimum max loss attained in evaluation: 2.0847393898293376e-05\n",
            "Maximum mean accuracy attained in evaluation: 0.9993325471878052\n",
            "Maximum min accuracy attained in evaluation: 0.9954341053962708\n",
            "Time Elapsed for Full Experiment: 1.09529287815094 minutes\n"
          ]
        }
      ],
      "source": [
        "econ_model = Rbc()\n",
        "final_train_state = run_experiment(econ_model, config)\n",
        "\n",
        "# DISCONNECT SESSION (uncomment next 2 lines if you do large run)\n",
        "# from google.colab import runtime\n",
        "# runtime.unassign()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuClass": "premium",
      "gpuType": "T4",
      "toc_visible": true,
      "authorship_tag": "ABX9TyOyIwPIkPsRQHlwzC3mjUY9",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}