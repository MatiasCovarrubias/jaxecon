{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MatiasCovarrubias/jaxecon/blob/main/Rbc_CES.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmNe6o_4tTEy"
      },
      "source": [
        "# DEQN Solver in Jax: Prelims\n",
        "\n",
        "This notebook trains a neural net to output the optimal policy of an RBC model with CES production function.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ue0dX6Q14A1Q",
        "outputId": "0a0ca0cd-f600-4bb4-b074-60f51e262858"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon May 20 19:39:24 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  NVIDIA A100-SXM4-40GB          Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P0              43W / 400W |      2MiB / 40960MiB |      0%      Default |\n",
            "|                                         |                      |             Disabled |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n",
            "Collecting jaxopt\n",
            "  Downloading jaxopt-0.8.3-py3-none-any.whl (172 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.3/172.3 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jax>=0.2.18 in /usr/local/lib/python3.10/dist-packages (from jaxopt) (0.4.26)\n",
            "Requirement already satisfied: jaxlib>=0.1.69 in /usr/local/lib/python3.10/dist-packages (from jaxopt) (0.4.26+cuda12.cudnn89)\n",
            "Requirement already satisfied: numpy>=1.18.4 in /usr/local/lib/python3.10/dist-packages (from jaxopt) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from jaxopt) (1.11.4)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.2.18->jaxopt) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax>=0.2.18->jaxopt) (3.3.0)\n",
            "Installing collected packages: jaxopt\n",
            "Successfully installed jaxopt-0.8.3\n",
            "Cloning into 'jaxecon'...\n",
            "remote: Enumerating objects: 377, done.\u001b[K\n",
            "remote: Counting objects: 100% (115/115), done.\u001b[K\n",
            "remote: Compressing objects: 100% (83/83), done.\u001b[K\n",
            "remote: Total 377 (delta 74), reused 67 (delta 32), pack-reused 262\u001b[K\n",
            "Receiving objects: 100% (377/377), 267.38 KiB | 24.31 MiB/s, done.\n",
            "Resolving deltas: 100% (236/236), done.\n",
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# BACKEND RELATED: the default backend is CPU (change in Edit -> Notebook settings)\n",
        "GPU = True # set True if using GPU (only to see GPU)\n",
        "if GPU:\n",
        "  !nvidia-smi\n",
        "\n",
        "# precision\n",
        "from jax import numpy as jnp, config as jax_config,  lax, random\n",
        "double_precision = True\n",
        "if double_precision:\n",
        "  jax_config.update(\"jax_enable_x64\", True)\n",
        "  precision = jnp.float64\n",
        "else:\n",
        "  precision = jnp.float32\n",
        "\n",
        "# Imports\n",
        "import matplotlib.pyplot as plt, flax.linen as nn, pandas as pd, jax, flax, optax, os, json\n",
        "from flax.training.train_state import TrainState  # Useful dataclass to keep train state\n",
        "from flax.training import checkpoints\n",
        "# from jax.scipy.optimize import minimize\n",
        "%pip install jaxopt\n",
        "import jaxopt\n",
        "from time import time\n",
        "from typing import Sequence\n",
        "jax_config.update(\"jax_debug_nans\", True)\n",
        "\n",
        "! git clone https://github.com/MatiasCovarrubias/jaxecon\n",
        "import sys\n",
        "sys.path.insert(0,'/content/jaxecon')\n",
        "from DEQN.neural_nets.neural_nets import NeuralNet\n",
        "from DEQN.econ_models.rbc_ces import RbcCES_SteadyState, RbcCES\n",
        "from DEQN.algorithm.simulation import create_episode_simul_fn\n",
        "from DEQN.algorithm.loss import create_batch_loss_fn\n",
        "from DEQN.algorithm.epoch_train import create_epoch_train_fn\n",
        "from DEQN.algorithm.eval import create_eval_fn\n",
        "from DEQN.analysis.simul_analysis import create_episode_simul_verbose_fn, create_descstats_fn\n",
        "from DEQN.analysis.stochastic_ss import create_stochss_fn\n",
        "# Mount Google Drive to store results (a pop up will appear, follow instructions)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "working_dir = \"/content/drive/MyDrive/Jaxecon/RbcCES/Experiments/Params_compstat/\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Econ model\n"
      ],
      "metadata": {
        "id": "uxCik716xRk1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set parameters\n",
        "\n",
        "beta=0.96\n",
        "alpha=0.31\n",
        "delta=0.057\n",
        "sigma_y=0.8\n",
        "eps_c=0.5\n",
        "eps_l=0.5\n",
        "rho=0.69\n",
        "phi=5\n",
        "shock_sd=0.0153\n",
        "\n",
        "# Find steady state and theta\n",
        "econ_model_ss = RbcCES_SteadyState(precision=precision, beta=beta, alpha=alpha, delta=delta, sigma_y=sigma_y, eps_c=eps_c, eps_l=eps_l)\n",
        "initial_policy = jnp.array([1.0000126, 0.41989392, 2.2284806, 0.12702352, 0.99998146, 0.99996126, 1.1270372, 12.25385])\n",
        "\n",
        "@jax.jit\n",
        "def optimize_policy(initial_policy):\n",
        "    # result = minimize_sc(jax.jit(econ_model_ss.loss), initial_policy, method='BFGS', options={'disp': True})\n",
        "    solver = jaxopt.BFGS(econ_model_ss.loss, tol=1e-09, verbose=False)\n",
        "    ss_policy, state = solver.run(initial_policy)\n",
        "    return ss_policy, state\n",
        "\n",
        "\n",
        "ss_policy, state = optimize_policy(initial_policy)\n",
        "print(\"loss\", state.error)\n",
        "print(\"steady state\", ss_policy)\n",
        "\n",
        "policies_ss = jnp.log(ss_policy[:7])\n",
        "theta = ss_policy[-1]\n",
        "print(\"theta\", theta)\n",
        "# create econ_model\n",
        "econ_model = RbcCES(precision=precision, policies_ss=policies_ss, theta=theta, beta=beta, alpha=alpha, delta=delta, sigma_y=sigma_y, eps_c=eps_c, eps_l=eps_l, rho=rho, phi=phi, shock_sd=shock_sd)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wgnaEMZhxNkX",
        "outputId": "d3624b36-98fa-412d-bf84-5535f4b14182"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO: jaxopt.ZoomLineSearch: Iter: 1 Minimum Decrease & Curvature Errors (stop. crit.): 4.0726188426530533e-10 Stepsize:1.0  Decrease Error:2.0012576681408925e-10  Curvature Error:4.0726188426530533e-10 \n",
            "INFO: jaxopt.ZoomLineSearch: Iter: 2 Minimum Decrease & Curvature Errors (stop. crit.): 0.0 Stepsize:0.12981847422057885  Decrease Error:0.0  Curvature Error:0.0 \n",
            "INFO: jaxopt.ZoomLineSearch: Iter: 1 Minimum Decrease & Curvature Errors (stop. crit.): 0.0 Stepsize:0.19472771133086827  Decrease Error:0.0  Curvature Error:0.0 \n",
            "INFO: jaxopt.ZoomLineSearch: Iter: 1 Minimum Decrease & Curvature Errors (stop. crit.): 0.0 Stepsize:0.2920915669963024  Decrease Error:0.0  Curvature Error:0.0 \n",
            "INFO: jaxopt.ZoomLineSearch: Iter: 1 Minimum Decrease & Curvature Errors (stop. crit.): 3.1800239501256695e-10 Stepsize:0.43813735049445357  Decrease Error:6.044458097745855e-11  Curvature Error:3.1800239501256695e-10 \n",
            "INFO: jaxopt.ZoomLineSearch: Iter: 2 Minimum Decrease & Curvature Errors (stop. crit.): 0.0 Stepsize:0.16508472013690867  Decrease Error:0.0  Curvature Error:0.0 \n",
            "INFO: jaxopt.ZoomLineSearch: Iter: 1 Minimum Decrease & Curvature Errors (stop. crit.): 0.0 Stepsize:0.247627080205363  Decrease Error:0.0  Curvature Error:0.0 \n",
            "INFO: jaxopt.ZoomLineSearch: Iter: 1 Minimum Decrease & Curvature Errors (stop. crit.): 0.0 Stepsize:0.3714406203080445  Decrease Error:0.0  Curvature Error:0.0 \n",
            "INFO: jaxopt.ZoomLineSearch: Iter: 1 Minimum Decrease & Curvature Errors (stop. crit.): 0.0 Stepsize:0.5571609304620667  Decrease Error:0.0  Curvature Error:0.0 \n",
            "INFO: jaxopt.ZoomLineSearch: Iter: 1 Minimum Decrease & Curvature Errors (stop. crit.): 0.0 Stepsize:0.8357413956931001  Decrease Error:0.0  Curvature Error:0.0 \n",
            "INFO: jaxopt.ZoomLineSearch: Iter: 1 Minimum Decrease & Curvature Errors (stop. crit.): 0.0 Stepsize:1.0  Decrease Error:0.0  Curvature Error:0.0 \n",
            "INFO: jaxopt.ZoomLineSearch: Iter: 1 Minimum Decrease & Curvature Errors (stop. crit.): 0.0 Stepsize:1.0  Decrease Error:0.0  Curvature Error:0.0 \n",
            "INFO: jaxopt.ZoomLineSearch: Iter: 1 Minimum Decrease & Curvature Errors (stop. crit.): 0.0 Stepsize:1.0  Decrease Error:0.0  Curvature Error:0.0 \n",
            "INFO: jaxopt.ZoomLineSearch: Iter: 1 Minimum Decrease & Curvature Errors (stop. crit.): 0.0 Stepsize:1.0  Decrease Error:0.0  Curvature Error:0.0 \n",
            "INFO: jaxopt.ZoomLineSearch: Iter: 1 Minimum Decrease & Curvature Errors (stop. crit.): 0.0 Stepsize:1.0  Decrease Error:0.0  Curvature Error:0.0 \n",
            "INFO: jaxopt.ZoomLineSearch: Iter: 1 Minimum Decrease & Curvature Errors (stop. crit.): 0.0 Stepsize:1.0  Decrease Error:0.0  Curvature Error:0.0 \n",
            "INFO: jaxopt.ZoomLineSearch: Iter: 1 Minimum Decrease & Curvature Errors (stop. crit.): 0.0 Stepsize:1.0  Decrease Error:0.0  Curvature Error:0.0 \n",
            "INFO: jaxopt.ZoomLineSearch: Iter: 1 Minimum Decrease & Curvature Errors (stop. crit.): 0.0 Stepsize:1.0  Decrease Error:0.0  Curvature Error:0.0 \n",
            "INFO: jaxopt.ZoomLineSearch: Iter: 1 Minimum Decrease & Curvature Errors (stop. crit.): 0.0 Stepsize:1.0  Decrease Error:0.0  Curvature Error:0.0 \n",
            "INFO: jaxopt.ZoomLineSearch: Iter: 1 Minimum Decrease & Curvature Errors (stop. crit.): 0.0 Stepsize:1.0  Decrease Error:0.0  Curvature Error:0.0 \n",
            "INFO: jaxopt.ZoomLineSearch: Iter: 1 Minimum Decrease & Curvature Errors (stop. crit.): 0.0 Stepsize:1.0  Decrease Error:0.0  Curvature Error:0.0 \n",
            "INFO: jaxopt.ZoomLineSearch: Iter: 1 Minimum Decrease & Curvature Errors (stop. crit.): 0.0 Stepsize:1.0  Decrease Error:0.0  Curvature Error:0.0 \n",
            "INFO: jaxopt.ZoomLineSearch: Iter: 1 Minimum Decrease & Curvature Errors (stop. crit.): 0.0 Stepsize:1.0  Decrease Error:0.0  Curvature Error:0.0 \n",
            "INFO: jaxopt.ZoomLineSearch: Iter: 1 Minimum Decrease & Curvature Errors (stop. crit.): 0.0 Stepsize:1.0  Decrease Error:0.0  Curvature Error:0.0 \n",
            "INFO: jaxopt.ZoomLineSearch: Iter: 1 Minimum Decrease & Curvature Errors (stop. crit.): 0.0 Stepsize:1.0  Decrease Error:0.0  Curvature Error:0.0 \n",
            "INFO: jaxopt.ZoomLineSearch: Iter: 1 Minimum Decrease & Curvature Errors (stop. crit.): 0.0 Stepsize:1.0  Decrease Error:0.0  Curvature Error:0.0 \n",
            "INFO: jaxopt.ZoomLineSearch: Iter: 1 Minimum Decrease & Curvature Errors (stop. crit.): 0.0 Stepsize:1.0  Decrease Error:0.0  Curvature Error:0.0 \n",
            "INFO: jaxopt.ZoomLineSearch: Iter: 1 Minimum Decrease & Curvature Errors (stop. crit.): 0.0 Stepsize:1.0  Decrease Error:0.0  Curvature Error:0.0 \n",
            "INFO: jaxopt.ZoomLineSearch: Iter: 1 Minimum Decrease & Curvature Errors (stop. crit.): 0.0 Stepsize:1.0  Decrease Error:0.0  Curvature Error:0.0 \n",
            "INFO: jaxopt.ZoomLineSearch: Iter: 1 Minimum Decrease & Curvature Errors (stop. crit.): 0.0 Stepsize:1.0  Decrease Error:0.0  Curvature Error:0.0 \n",
            "INFO: jaxopt.ZoomLineSearch: Iter: 1 Minimum Decrease & Curvature Errors (stop. crit.): 0.0 Stepsize:1.0  Decrease Error:0.0  Curvature Error:0.0 \n",
            "INFO: jaxopt.ZoomLineSearch: Iter: 1 Minimum Decrease & Curvature Errors (stop. crit.): 0.0 Stepsize:1.0  Decrease Error:0.0  Curvature Error:0.0 \n",
            "INFO: jaxopt.ZoomLineSearch: Iter: 1 Minimum Decrease & Curvature Errors (stop. crit.): 0.0 Stepsize:1.0  Decrease Error:0.0  Curvature Error:0.0 \n",
            "INFO: jaxopt.ZoomLineSearch: Iter: 1 Minimum Decrease & Curvature Errors (stop. crit.): 0.0 Stepsize:1.0  Decrease Error:0.0  Curvature Error:0.0 \n",
            "INFO: jaxopt.ZoomLineSearch: Iter: 1 Minimum Decrease & Curvature Errors (stop. crit.): 0.0 Stepsize:1.0  Decrease Error:0.0  Curvature Error:0.0 \n",
            "INFO: jaxopt.ZoomLineSearch: Iter: 1 Minimum Decrease & Curvature Errors (stop. crit.): 0.0 Stepsize:1.0  Decrease Error:0.0  Curvature Error:0.0 \n",
            "INFO: jaxopt.ZoomLineSearch: Iter: 1 Minimum Decrease & Curvature Errors (stop. crit.): 0.0 Stepsize:1.0  Decrease Error:0.0  Curvature Error:0.0 \n",
            "INFO: jaxopt.ZoomLineSearch: Iter: 1 Minimum Decrease & Curvature Errors (stop. crit.): 0.0 Stepsize:1.0  Decrease Error:0.0  Curvature Error:0.0 \n",
            "INFO: jaxopt.ZoomLineSearch: Iter: 1 Minimum Decrease & Curvature Errors (stop. crit.): 0.0 Stepsize:1.0  Decrease Error:0.0  Curvature Error:0.0 \n",
            "loss 7.373685450483826e-10\n",
            "steady state [ 1.          0.41989881  2.2281879   0.12700671  1.          1.\n",
            "  1.12700671 12.25319648]\n",
            "theta 12.25319647631729\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PlXarixBjTC2"
      },
      "source": [
        "# Configure experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3zWgbr0HjQua",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "355f687e-a7d9-46aa-da79-91f24c9c09a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of parameters:\n",
            "\n",
            "\u001b[3m                             NeuralNet Summary                              \u001b[0m\n",
            "┏━━━━━━━━━┳━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
            "┃\u001b[1m \u001b[0m\u001b[1mpath   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mmodule   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1minputs     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1moutputs    \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mparams                \u001b[0m\u001b[1m \u001b[0m┃\n",
            "┡━━━━━━━━━╇━━━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
            "│         │ NeuralNet │ \u001b[2mfloat64\u001b[0m[2]  │ \u001b[2mfloat64\u001b[0m[7]  │                        │\n",
            "├─────────┼───────────┼─────────────┼─────────────┼────────────────────────┤\n",
            "│ Dense_0 │ Dense     │ \u001b[2mfloat64\u001b[0m[2]  │ \u001b[2mfloat64\u001b[0m[64] │ bias: \u001b[2mfloat64\u001b[0m[64]      │\n",
            "│         │           │             │             │ kernel: \u001b[2mfloat64\u001b[0m[2,64]  │\n",
            "│         │           │             │             │                        │\n",
            "│         │           │             │             │ \u001b[1m192 \u001b[0m\u001b[1;2m(1.5 KB)\u001b[0m           │\n",
            "├─────────┼───────────┼─────────────┼─────────────┼────────────────────────┤\n",
            "│ Dense_1 │ Dense     │ \u001b[2mfloat64\u001b[0m[64] │ \u001b[2mfloat64\u001b[0m[64] │ bias: \u001b[2mfloat64\u001b[0m[64]      │\n",
            "│         │           │             │             │ kernel: \u001b[2mfloat64\u001b[0m[64,64] │\n",
            "│         │           │             │             │                        │\n",
            "│         │           │             │             │ \u001b[1m4,160 \u001b[0m\u001b[1;2m(33.3 KB)\u001b[0m        │\n",
            "├─────────┼───────────┼─────────────┼─────────────┼────────────────────────┤\n",
            "│ Dense_2 │ Dense     │ \u001b[2mfloat64\u001b[0m[64] │ \u001b[2mfloat64\u001b[0m[7]  │ bias: \u001b[2mfloat64\u001b[0m[7]       │\n",
            "│         │           │             │             │ kernel: \u001b[2mfloat64\u001b[0m[64,7]  │\n",
            "│         │           │             │             │                        │\n",
            "│         │           │             │             │ \u001b[1m455 \u001b[0m\u001b[1;2m(3.6 KB)\u001b[0m           │\n",
            "├─────────┼───────────┼─────────────┼─────────────┼────────────────────────┤\n",
            "│\u001b[1m \u001b[0m\u001b[1m       \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m         \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m           \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m      Total\u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m4,807 \u001b[0m\u001b[1;2m(38.5 KB)\u001b[0m\u001b[1m       \u001b[0m\u001b[1m \u001b[0m│\n",
            "└─────────┴───────────┴─────────────┴─────────────┴────────────────────────┘\n",
            "\u001b[1m                                                                            \u001b[0m\n",
            "\u001b[1m                     Total Parameters: 4,807 \u001b[0m\u001b[1;2m(38.5 KB)\u001b[0m\u001b[1m                      \u001b[0m\n",
            "\n",
            "\n",
            "TOTAL Number of steps (NN updates): 10000 episodes \n",
            "\n"
          ]
        }
      ],
      "source": [
        "'''Config dictionary'''\n",
        "\n",
        "# CREATE CONFIG DICT\n",
        "config = {\n",
        "    # general\n",
        "    \"seed\": 48,\n",
        "    \"exper_name\": \"May20_correctedv3\",\n",
        "    \"save_dir\": working_dir,\n",
        "    \"restore\": False,                                                            # True if start from restored checkpoint\n",
        "    \"restore_exper_name\": \"\",\n",
        "    \"seed\": 5,\n",
        "\n",
        "    # neural net\n",
        "    \"layers\": [64,64],              # layers of the NN\n",
        "\n",
        "    # learning rate schedule\n",
        "    \"lr_sch_values\": [0.0005,0.0005],                                        # values (from the last, we do cosine decay to 0)\n",
        "    \"lr_sch_transitions\": [2000],\n",
        "    \"lr_end_value\": 1e-7,\n",
        "\n",
        "    # simulation\n",
        "    \"periods_per_epis\": 32,\n",
        "    \"simul_vol_scale\": 1.5,        # scale of volatility while simul\n",
        "    \"init_range\": 10,\n",
        "\n",
        "    # loss calculation\n",
        "    \"mc_draws\": 16,               # monte-carlo draws\n",
        "\n",
        "    # training\n",
        "    \"epis_per_step\": 512,         # epoch per steps\n",
        "    \"steps_per_epoch\": 100,       # steps per epoch\n",
        "    \"n_epochs\": 100,               # number of epochs\n",
        "    \"batch_size\": 16,             # size of batch of obs to calculate grads\n",
        "    \"init_range\": 0,\n",
        "    \"checkpoint_frequency\": 1000,\n",
        "\n",
        "    \"config_eval\": {\n",
        "      \"periods_per_epis\": 64,      # periods per episode\n",
        "      \"mc_draws\": 128,         # number of mc draws\n",
        "      \"simul_vol_scale\": 1,        # scale of volatility while simul\n",
        "      \"eval_n_epis\": 128,           # episodes to sample for eval\n",
        "      \"init_range\": 0\n",
        "    }\n",
        "}\n",
        "\n",
        "#create auxiliary config variables for readability\n",
        "config[\"periods_per_step\"] =config[\"periods_per_epis\"]*config[\"epis_per_step\"]\n",
        "config[\"n_batches\"] = config[\"periods_per_step\"]//config[\"batch_size\"]\n",
        "\n",
        "# PRINT AND PLOT KEY CONFIGS\n",
        "print(\"Number of parameters:\")\n",
        "print(NeuralNet(config[\"layers\"] + [RbcCES().n_actions], precision).tabulate(\n",
        "    random.PRNGKey(0),\n",
        "    RbcCES(precision=precision).initial_obs(random.PRNGKey(0))\n",
        "    ))\n",
        "\n",
        "print(\"TOTAL Number of steps (NN updates):\", config[\"steps_per_epoch\"]*config[\"n_epochs\"], \"episodes \\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CEAiCNRxC1AJ"
      },
      "source": [
        "# Create experiment\n",
        "Now we create code for the entire experiment as a function to call later."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def run_experiment(econ_model, config):\n",
        "  \"\"\"Runs experiment.\"\"\"\n",
        "\n",
        "\n",
        "  # CREATE NN, RNGS, TRAIN_STATE AND EPOQUE UPDATE\n",
        "  nn = NeuralNet(features = config[\"layers\"] + [econ_model.n_actions], precision = precision)\n",
        "  rng, rng_pol, rng_econ_model, rng_epoch, rng_eval = random.split(random.PRNGKey(config[\"seed\"]), num=5)  # random number generator\n",
        "\n",
        "  # CREATE LR SCHEDULE\n",
        "  lr_schedule = optax.join_schedules(\n",
        "    schedules= [optax.constant_schedule(i) for i in config[\"lr_sch_values\"][:-1]]\n",
        "                  + [optax.warmup_cosine_decay_schedule(\n",
        "                    init_value=config[\"lr_sch_values\"][-1],\n",
        "                    peak_value=config[\"lr_sch_values\"][-1],\n",
        "                    warmup_steps=0,\n",
        "                    decay_steps=config[\"n_epochs\"]*config[\"steps_per_epoch\"]-config[\"lr_sch_transitions\"][-1],\n",
        "                    end_value=config[\"lr_end_value\"],)],\n",
        "      boundaries=config[\"lr_sch_transitions\"] # the number of episodes at which to switch\n",
        "      )\n",
        "\n",
        "  # INITIALIZE OR RESTORE FULL NN TRAIN STATE\n",
        "  if not config[\"restore\"]:\n",
        "    params=nn.init(rng_pol, jnp.zeros_like(econ_model.initial_obs(rng_econ_model)))\n",
        "    train_state = TrainState.create(apply_fn=nn.apply, params=params, tx=optax.adam(lr_schedule))\n",
        "  else:\n",
        "    train_state_restored = checkpoints.restore_checkpoint(ckpt_dir=config[\"working_dir\"]+config[\"restore_run_name\"], target = None)\n",
        "    params = train_state_restored[\"params\"]\n",
        "    opt_state = train_state_restored[\"opt_state\"]\n",
        "    train_state = TrainState.create(apply_fn=nn.apply, params=params, tx=optax.adam(lr_schedule))\n",
        "    train_state.replace(opt_state=opt_state)\n",
        "\n",
        "  # GET TRAIN AND EVAL FUNCTIONS\n",
        "  simul_fn = jax.jit(create_episode_simul_fn(econ_model,config))\n",
        "  loss_fn = jax.jit(create_batch_loss_fn(econ_model,config))\n",
        "  train_epoch_fn  = jax.jit(create_epoch_train_fn(econ_model, config, simul_fn, loss_fn))\n",
        "  eval_fn  = jax.jit(create_eval_fn(config, simul_fn, loss_fn))\n",
        "\n",
        "  # COMPILE CODE\n",
        "  time_start = time()\n",
        "  train_epoch_fn(train_state, rng_epoch)  # compiles\n",
        "  eval_fn(train_state, rng_epoch) # compiles\n",
        "  time_compilation = time() - time_start\n",
        "  print(\"Time Elapsed for Compilation:\", time_compilation, \"seconds\")\n",
        "\n",
        "  # RUN AN EPOCH TO GET TIME STATS\n",
        "  time_start = time()\n",
        "  train_epoch_fn(train_state, rng_epoch) # run one epoque\n",
        "  time_epoch = time() - time_start\n",
        "  print(\"Time Elapsed for epoch:\", time_epoch, \"seconds\")\n",
        "\n",
        "  time_start = time()\n",
        "  eval_fn(train_state, rng_epoch) # run one epoque\n",
        "  time_eval = time() - time_start\n",
        "  print(\"Time Elapsed for eval:\", time_eval, \"seconds\")\n",
        "\n",
        "  time_experiment = (time_epoch + time_eval)*config[\"n_epochs\"]/60\n",
        "  print(\"Estimated time for full experiment\", time_experiment, \"minutes\")\n",
        "\n",
        "  steps_per_second = config[\"steps_per_epoch\"]*config[\"periods_per_step\"]/time_epoch\n",
        "  print(\"Steps per second:\", steps_per_second, \"st/s\")\n",
        "\n",
        "  # CREATE LISTS TO STORE METRICS\n",
        "  mean_losses, max_losses, mean_accuracy, min_accuracy = [], [], [], []\n",
        "\n",
        "  # RUN ALL THE EPOCHS\n",
        "  time_start = time()\n",
        "  for i in range(1,config[\"n_epochs\"]+1):\n",
        "\n",
        "    # eval\n",
        "    eval_metrics = eval_fn(train_state, rng_eval)\n",
        "    print('EVALUATION:\\n',\n",
        "      'Iteration:', train_state.step,\n",
        "      \"Mean Loss:\", eval_metrics[0],\n",
        "      \", Max Loss:\", eval_metrics[1],\n",
        "      \", Mean Acc:\", eval_metrics[2],\n",
        "      \", Min Acc:\", eval_metrics[3], \"\\n\"\n",
        "      \", Mean Accs Foc\", eval_metrics[4], \"\\n\"\n",
        "      \", Min Accs Foc:\", eval_metrics[5],\n",
        "      \"\\n\")\n",
        "\n",
        "    # run epoch\n",
        "    train_state, rng_epoch, epoch_metrics = train_epoch_fn(train_state, rng_epoch)\n",
        "    print('TRAINING:\\n',\n",
        "          'Iteration:', train_state.step,\n",
        "          \", Mean Loss:\", jnp.mean(epoch_metrics[0]),\n",
        "          \", Max Loss:\", jnp.mean(epoch_metrics[1]),\n",
        "          \", Mean Acc:\", jnp.mean(epoch_metrics[2]),\n",
        "          \", Min Acc:\", jnp.min(epoch_metrics[3]),\n",
        "          \", Learning rate:\", lr_schedule(train_state.step),\n",
        "          \"\\n\"\n",
        "          )\n",
        "\n",
        "    # checkpoint\n",
        "    if train_state.step>=config[\"checkpoint_frequency\"] and train_state.step%config[\"checkpoint_frequency\"]==0:\n",
        "      checkpoints.save_checkpoint(ckpt_dir=config['save_dir']+config['exper_name'], target=train_state, step=train_state.step)\n",
        "\n",
        "      # store results\n",
        "      mean_losses.append(float(eval_metrics[0]))\n",
        "      max_losses.append(float(eval_metrics[1]))\n",
        "      mean_accuracy.append(float(eval_metrics[2]))\n",
        "      min_accuracy.append(float(eval_metrics[3]))\n",
        "\n",
        "    #end of inner loop\n",
        "\n",
        "  # PRINT RESULTS\n",
        "  print(\"Minimum mean loss attained in evaluation:\", min(mean_losses))\n",
        "  print(\"Minimum max loss attained in evaluation:\", min(max_losses))\n",
        "  print(\"Maximum mean accuracy attained in evaluation:\", max(mean_accuracy))\n",
        "  print(\"Maximum min accuracy attained in evaluation:\", max(min_accuracy))\n",
        "  time_fullexp = (time() - time_start)/60\n",
        "  print(\"Time Elapsed for Full Experiment:\", time_fullexp, \"minutes\")\n",
        "\n",
        "  # STORE RESULTS\n",
        "  results = {\n",
        "    \"exper_name\": config[\"exper_name\"],\n",
        "    \"min_mean_loss\":  min(mean_losses),\n",
        "    \"min_max_loss\": max(max_losses),\n",
        "    \"max_mean_acc\": max(mean_accuracy),\n",
        "    \"max_min_acc\": max(min_accuracy),\n",
        "    \"time_full_exp_minutes\": time_fullexp,\n",
        "    \"time_epoque_seconds\": time_epoch,\n",
        "    \"time_compilation_seconds\": time_compilation,\n",
        "    \"steps_per_second\": steps_per_second,\n",
        "    \"config\": config,\n",
        "    \"mean_losses_list\": mean_losses,\n",
        "    \"max_losses_list\": max_losses,\n",
        "    \"mean_acc_list\": mean_accuracy,\n",
        "    \"min_acc_list\": min_accuracy,\n",
        "  }\n",
        "\n",
        "  # store to json\n",
        "  if not os.path.exists(config['save_dir']+config['exper_name']):\n",
        "    os.mkdir(config['save_dir']+config['exper_name'])\n",
        "  with open(config['save_dir']+config['exper_name']+\"/results.json\", \"w\") as write_file:\n",
        "    json.dump(results, write_file)\n",
        "\n",
        "  # PLOT LEARNING\n",
        "\n",
        "  # Mean Losses\n",
        "  plt.plot([(i+1)*config[\"checkpoint_frequency\"] for i in range(len(mean_losses))], mean_losses)\n",
        "  plt.xlabel('Steps (NN updates)')\n",
        "  plt.ylabel('Mean Losses')\n",
        "  plt.savefig(config['save_dir']+config['exper_name']+'/mean_losses.jpg')\n",
        "  plt.close()\n",
        "\n",
        "  plt.plot([(i+1)*config[\"checkpoint_frequency\"] for i in range(len(max_losses))], max_losses)\n",
        "  plt.xlabel('Steps (NN updates)')\n",
        "  plt.ylabel('Max Losses')\n",
        "  plt.savefig(config['save_dir']+config['exper_name']+'/max_losses.jpg')\n",
        "  plt.close()\n",
        "\n",
        "  # Mean Accuracy\n",
        "  plt.plot([(i+1)*config[\"checkpoint_frequency\"] for i in range(len(mean_accuracy))], mean_accuracy)\n",
        "  plt.xlabel('Steps (NN updates)')\n",
        "  plt.ylabel('Mean Accuracy (%)')\n",
        "  plt.savefig(config['save_dir']+config['exper_name']+'/mean_accuracy.jpg')\n",
        "  plt.close()\n",
        "\n",
        "  # Min Accuracy\n",
        "  plt.plot([(i+1)*config[\"checkpoint_frequency\"] for i in range(len(min_accuracy))], min_accuracy)\n",
        "  plt.xlabel('Steps (NN updates)')\n",
        "  plt.ylabel('Minimum Accuracy (%)')\n",
        "  plt.savefig(config['save_dir']+config['exper_name']+'/min_accuracy.jpg')\n",
        "  plt.close()\n",
        "\n",
        "  # Learning rate schedule\n",
        "  plt.plot([(i+1)*config[\"checkpoint_frequency\"] for i in range(len(mean_losses))], [lr_schedule((i+1)*config[\"checkpoint_frequency\"]) for i in range(len(mean_losses))])\n",
        "  plt.xlabel('Steps (NN updates)')\n",
        "  plt.ylabel('Learning Rate')\n",
        "  plt.savefig(config['save_dir']+config['exper_name']+'/learning_rate.jpg')\n",
        "  plt.close()\n",
        "\n",
        "  return train_state"
      ],
      "metadata": {
        "id": "tw69_Ic-dcVr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run experiment\n",
        "*Finally*, we run the experiment abd get the trained parameter plus useful info."
      ],
      "metadata": {
        "id": "WdkzmdmHk_Il"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "awmY1xXgDOcU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2bc4011-e66d-4947-adf5-213e84e21f0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time Elapsed for Compilation: 6.052121639251709 seconds\n",
            "Time Elapsed for epoch: 0.5464625358581543 seconds\n",
            "Time Elapsed for eval: 0.0049397945404052734 seconds\n",
            "Estimated time for full experiment 0.9190038839975992 minutes\n",
            "Steps per second: 2998192.725924181 st/s\n",
            "EVALUATION:\n",
            " Iteration: 0 Mean Loss: 0.11436209094180974 , Max Loss: 0.7948116957212975 , Mean Acc: 0.7520290058915519 , Min Acc: 0.10847787704325729 \n",
            ", Mean Accs Foc [0.33811368 0.50984866 0.96659638 0.89222323 0.84613051 0.99261497\n",
            " 0.71867562] \n",
            ", Min Accs Foc: [0.33636888 0.10847788 0.92761977 0.8862874  0.80969721 0.89994026\n",
            " 0.60340746] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 100 , Mean Loss: 0.03273297418924186 , Max Loss: 0.18583739514082426 , Mean Acc: 0.8918663160931923 , Min Acc: 0.05554514026485724 , Learning rate: 0.0005 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 100 Mean Loss: 0.002821582791908187 , Max Loss: 0.01894669886718434 , Mean Acc: 0.9591209294616589 , Min Acc: 0.8623529917971904 \n",
            ", Mean Accs Foc [0.90612665 0.97176735 0.9706826  0.98905929 0.91212781 0.98609445\n",
            " 0.97798836] \n",
            ", Min Accs Foc: [0.86235299 0.93877944 0.95662045 0.97329887 0.89224733 0.95095673\n",
            " 0.87034218] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 200 , Mean Loss: 0.0013958897324953185 , Max Loss: 0.022270338247425383 , Mean Acc: 0.9730080878180501 , Min Acc: 0.6428404461622215 , Learning rate: 0.0005 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 200 Mean Loss: 0.0010025560536300214 , Max Loss: 0.10078906696770311 , Mean Acc: 0.9801644473208692 , Min Acc: 0.6825270610466097 \n",
            ", Mean Accs Foc [0.96833918 0.98802362 0.96809687 0.99648563 0.98299705 0.97495425\n",
            " 0.98225453] \n",
            ", Min Accs Foc: [0.68252706 0.86925077 0.91630925 0.97901152 0.94017532 0.83537982\n",
            " 0.9150658 ] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 300 , Mean Loss: 0.0006682518502777653 , Max Loss: 0.020150622856298043 , Mean Acc: 0.9834634170864263 , Min Acc: 0.6472750889561543 , Learning rate: 0.0005 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 300 Mean Loss: 0.0003284679557182911 , Max Loss: 0.018299248221747062 , Mean Acc: 0.9870946702264342 , Min Acc: 0.8647252860962291 \n",
            ", Mean Accs Foc [0.9880981  0.99715173 0.97454127 0.99674952 0.98704507 0.97878401\n",
            " 0.98729299] \n",
            ", Min Accs Foc: [0.86472529 0.97683995 0.96314806 0.97847153 0.94650137 0.90787794\n",
            " 0.92835455] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 400 , Mean Loss: 0.00020360723579515547 , Max Loss: 0.00220829239429686 , Mean Acc: 0.989398387062968 , Min Acc: 0.8581383198786288 , Learning rate: 0.0005 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 400 Mean Loss: 0.00012079277173028821 , Max Loss: 0.002320125683481796 , Mean Acc: 0.9915802892696352 , Min Acc: 0.9518323170218683 \n",
            ", Mean Accs Foc [0.99514469 0.99673903 0.98252509 0.99687999 0.99449802 0.98392713\n",
            " 0.99134808] \n",
            ", Min Accs Foc: [0.9718459  0.97037857 0.96851392 0.97783636 0.96639066 0.96386251\n",
            " 0.95183232] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 500 , Mean Loss: 8.996428587612534e-05 , Max Loss: 0.0005976277712558803 , Mean Acc: 0.9926436934489629 , Min Acc: 0.9251293872543895 , Learning rate: 0.0005 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 500 Mean Loss: 0.00011953659002785203 , Max Loss: 0.004369809726123993 , Mean Acc: 0.9919279852813402 , Min Acc: 0.9338954636494288 \n",
            ", Mean Accs Foc [0.99461103 0.99554076 0.98812647 0.99582713 0.98905443 0.99160772\n",
            " 0.98872836] \n",
            ", Min Accs Foc: [0.96579709 0.95981899 0.97387316 0.97344632 0.93573251 0.98096594\n",
            " 0.93389546] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 600 , Mean Loss: 3.521744343257184e-05 , Max Loss: 0.00036947332743119435 , Mean Acc: 0.995884252613501 , Min Acc: 0.9157330187327377 , Learning rate: 0.0005 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 600 Mean Loss: 1.1106783117399902e-05 , Max Loss: 0.00050933814975878 , Mean Acc: 0.997723987326303 , Min Acc: 0.9774314787866201 \n",
            ", Mean Accs Foc [0.99901989 0.9986236  0.99440557 0.99927519 0.99871612 0.99566186\n",
            " 0.99836569] \n",
            ", Min Accs Foc: [0.98741662 0.98962728 0.98307801 0.99117613 0.97743148 0.9853955\n",
            " 0.9831645 ] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 700 , Mean Loss: 5.400081457932749e-06 , Max Loss: 6.777834632099971e-05 , Mean Acc: 0.9984120432265499 , Min Acc: 0.9658641191995876 , Learning rate: 0.0005 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 700 Mean Loss: 2.5878239899373196e-06 , Max Loss: 0.00020351936316689569 , Mean Acc: 0.9988669240114201 , Min Acc: 0.9857339787198078 \n",
            ", Mean Accs Foc [0.99901783 0.99902398 0.99789532 0.99932803 0.99906578 0.99871001\n",
            " 0.99902753] \n",
            ", Min Accs Foc: [0.98830091 0.98850223 0.98573398 0.9935097  0.98748577 0.99062219\n",
            " 0.99221263] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 800 , Mean Loss: 1.7335543847563095e-06 , Max Loss: 2.9589735605259157e-05 , Mean Acc: 0.9990885460755755 , Min Acc: 0.9736557105723789 , Learning rate: 0.0005 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 800 Mean Loss: 1.2720590301818174e-06 , Max Loss: 0.0001571387246663092 , Mean Acc: 0.9992196101196462 , Min Acc: 0.9874645014193169 \n",
            ", Mean Accs Foc [0.99942616 0.99928821 0.9983732  0.99946699 0.99943329 0.99914628\n",
            " 0.99940314] \n",
            ", Min Accs Foc: [0.99584039 0.99460605 0.9874645  0.99517571 0.99430449 0.99164358\n",
            " 0.99404825] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 900 , Mean Loss: 1.03036408605231e-06 , Max Loss: 1.9002991451526982e-05 , Mean Acc: 0.9992950459066555 , Min Acc: 0.9760865531258918 , Learning rate: 0.0005 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 900 Mean Loss: 9.194636749096731e-07 , Max Loss: 0.00010610826980280482 , Mean Acc: 0.9993310668450299 , Min Acc: 0.9896991131545481 \n",
            ", Mean Accs Foc [0.9995214  0.99935759 0.99862778 0.99954128 0.99952461 0.99925446\n",
            " 0.99949035] \n",
            ", Min Accs Foc: [0.99644308 0.99449159 0.98969911 0.99631576 0.99450741 0.99318242\n",
            " 0.99476245] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 1000 , Mean Loss: 8.069056137158517e-07 , Max Loss: 1.4410523802532228e-05 , Mean Acc: 0.9993713000349456 , Min Acc: 0.9679921146395043 , Learning rate: 0.0005 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 1000 Mean Loss: 7.37444171015223e-07 , Max Loss: 8.48154816960548e-05 , Mean Acc: 0.9994023478876328 , Min Acc: 0.9907904678894064 \n",
            ", Mean Accs Foc [0.99956205 0.99943354 0.99875719 0.99958429 0.99960038 0.99933392\n",
            " 0.99954507] \n",
            ", Min Accs Foc: [0.99657286 0.99498676 0.99079047 0.99710114 0.99552719 0.99407016\n",
            " 0.99491761] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 1100 , Mean Loss: 6.694020648732752e-07 , Max Loss: 1.2014426539182906e-05 , Mean Acc: 0.999429868428073 , Min Acc: 0.9786374700639824 , Learning rate: 0.0005 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 1100 Mean Loss: 6.234089506346653e-07 , Max Loss: 7.90775283396785e-05 , Mean Acc: 0.9994554896481553 , Min Acc: 0.9911074453423283 \n",
            ", Mean Accs Foc [0.99960229 0.99950843 0.99883189 0.99962455 0.99964531 0.99939624\n",
            " 0.99957972] \n",
            ", Min Accs Foc: [0.99640162 0.99673597 0.99110745 0.99756507 0.99564249 0.99461129\n",
            " 0.99503343] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 1200 , Mean Loss: 5.90154764806642e-07 , Max Loss: 1.085612668914195e-05 , Mean Acc: 0.9994680846748085 , Min Acc: 0.9823593556272974 , Learning rate: 0.0005 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 1200 Mean Loss: 5.98179397498261e-07 , Max Loss: 7.079058270447498e-05 , Mean Acc: 0.9994574801351884 , Min Acc: 0.9915862860338329 \n",
            ", Mean Accs Foc [0.99963451 0.99935705 0.99888302 0.99964924 0.99966227 0.99943439\n",
            " 0.99958188] \n",
            ", Min Accs Foc: [0.99713161 0.99660867 0.99158629 0.99739361 0.9959445  0.99512784\n",
            " 0.9948494 ] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 1300 , Mean Loss: 5.458606670167622e-07 , Max Loss: 9.993716078904222e-06 , Mean Acc: 0.9994877004442703 , Min Acc: 0.981044104560395 , Learning rate: 0.0005 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 1300 Mean Loss: 5.269540853746564e-07 , Max Loss: 6.517251710862387e-05 , Mean Acc: 0.9995002926440382 , Min Acc: 0.9919270502845228 \n",
            ", Mean Accs Foc [0.99961249 0.99952356 0.99891565 0.99966873 0.99968684 0.99947079\n",
            " 0.99962398] \n",
            ", Min Accs Foc: [0.99671353 0.99656876 0.99192705 0.99751453 0.99584907 0.99553194\n",
            " 0.99514795] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 1400 , Mean Loss: 5.155481258103571e-07 , Max Loss: 9.498754917566806e-06 , Mean Acc: 0.9995039172875935 , Min Acc: 0.974431419107955 , Learning rate: 0.0005 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 1400 Mean Loss: 4.799211318474854e-07 , Max Loss: 5.695384800697525e-05 , Mean Acc: 0.9995311632529486 , Min Acc: 0.992453222674083 \n",
            ", Mean Accs Foc [0.99966763 0.99958065 0.99893361 0.99968362 0.99970548 0.99949956\n",
            " 0.99964759] \n",
            ", Min Accs Foc: [0.99654072 0.99682072 0.99245322 0.99743589 0.99618701 0.99574207\n",
            " 0.99534151] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 1500 , Mean Loss: 4.912027000691579e-07 , Max Loss: 9.10146451611754e-06 , Mean Acc: 0.9995159429269599 , Min Acc: 0.9794056446938821 , Learning rate: 0.0005 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 1500 Mean Loss: 4.5919820000043793e-07 , Max Loss: 4.975246028526923e-05 , Mean Acc: 0.9995440616331254 , Min Acc: 0.9929464576073246 \n",
            ", Mean Accs Foc [0.99967806 0.999591   0.99894404 0.99969372 0.99971429 0.99952703\n",
            " 0.9996603 ] \n",
            ", Min Accs Foc: [0.99649234 0.99617865 0.99294646 0.99744133 0.9962964  0.99611914\n",
            " 0.99529372] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 1600 , Mean Loss: 4.6364495269089206e-07 , Max Loss: 8.82209281576354e-06 , Mean Acc: 0.9995336418678905 , Min Acc: 0.9846745477163743 , Learning rate: 0.0005 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 1600 Mean Loss: 4.582519472410659e-07 , Max Loss: 4.505796865868354e-05 , Mean Acc: 0.9995362536836976 , Min Acc: 0.9932874767293749 \n",
            ", Mean Accs Foc [0.99963688 0.99954672 0.99895817 0.99968589 0.99972516 0.9995343\n",
            " 0.99966666] \n",
            ", Min Accs Foc: [0.99652761 0.99618147 0.99328748 0.99725402 0.99641743 0.99626951\n",
            " 0.99542136] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 1700 , Mean Loss: 4.4455189912767905e-07 , Max Loss: 8.58086493564781e-06 , Mean Acc: 0.999543977999652 , Min Acc: 0.9829644577706664 , Learning rate: 0.0005 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 1700 Mean Loss: 4.293391101266104e-07 , Max Loss: 4.134092604043687e-05 , Mean Acc: 0.9995619418952104 , Min Acc: 0.9935703090244992 \n",
            ", Mean Accs Foc [0.99967696 0.99961521 0.99896191 0.99971373 0.99972977 0.99955237\n",
            " 0.99968365] \n",
            ", Min Accs Foc: [0.99680952 0.9970362  0.99357031 0.99732598 0.9964938  0.99638629\n",
            " 0.99579409] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 1800 , Mean Loss: 4.40857100235326e-07 , Max Loss: 8.47999111134695e-06 , Mean Acc: 0.9995456484227969 , Min Acc: 0.9826331343744512 , Learning rate: 0.0005 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 1800 Mean Loss: 4.2442110406811926e-07 , Max Loss: 3.474678774755435e-05 , Mean Acc: 0.999562572502324 , Min Acc: 0.9941053594047173 \n",
            ", Mean Accs Foc [0.99969681 0.99957144 0.99896871 0.99971457 0.9997407  0.99955979\n",
            " 0.99968599] \n",
            ", Min Accs Foc: [0.99728878 0.99687877 0.99410536 0.99720889 0.99678423 0.99655858\n",
            " 0.99603982] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 1900 , Mean Loss: 4.354643213025231e-07 , Max Loss: 8.408554383471214e-06 , Mean Acc: 0.9995500210174288 , Min Acc: 0.9782631165270446 , Learning rate: 0.0005 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 1900 Mean Loss: 4.130316215974271e-07 , Max Loss: 3.1769125508022175e-05 , Mean Acc: 0.9995710768937318 , Min Acc: 0.994363589306303 \n",
            ", Mean Accs Foc [0.99966514 0.99962174 0.99896879 0.99972093 0.9997435  0.99957591\n",
            " 0.99970152] \n",
            ", Min Accs Foc: [0.99718988 0.99612959 0.99436359 0.99737918 0.99692985 0.99668502\n",
            " 0.99607442] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 2000 , Mean Loss: 4.304276562177193e-07 , Max Loss: 8.312267270159735e-06 , Mean Acc: 0.999550953645975 , Min Acc: 0.9845816910726082 , Learning rate: 0.0005 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 2000 Mean Loss: 4.5233647556457145e-07 , Max Loss: 2.9695454143839494e-05 , Mean Acc: 0.9995327716896723 , Min Acc: 0.994550646447161 \n",
            ", Mean Accs Foc [0.99965204 0.99939278 0.99896945 0.99969021 0.99975376 0.9995876\n",
            " 0.99968356] \n",
            ", Min Accs Foc: [0.99738993 0.99606042 0.99455065 0.99736425 0.99697968 0.99679651\n",
            " 0.99618235] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 2100 , Mean Loss: 4.2236856624140214e-07 , Max Loss: 8.219471954514283e-06 , Mean Acc: 0.9995577599113098 , Min Acc: 0.9861104528339844 , Learning rate: 0.0004998072976083687 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 2100 Mean Loss: 3.923278277992091e-07 , Max Loss: 3.008055695986788e-05 , Mean Acc: 0.9995863442890784 , Min Acc: 0.9945154255443227 \n",
            ", Mean Accs Foc [0.99971273 0.99962268 0.99898022 0.99974008 0.99975732 0.99957673\n",
            " 0.99971466] \n",
            ", Min Accs Foc: [0.99786031 0.99636337 0.99451543 0.99717759 0.99699999 0.99683515\n",
            " 0.9965135 ] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 2200 , Mean Loss: 4.077561713815818e-07 , Max Loss: 8.168240480410222e-06 , Mean Acc: 0.9995717577887203 , Min Acc: 0.9842459972660438 , Learning rate: 0.0004992294875665954 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 2200 Mean Loss: 3.8520664440659836e-07 , Max Loss: 2.9537500864114694e-05 , Mean Acc: 0.9995918921693102 , Min Acc: 0.9945651586164714 \n",
            ", Mean Accs Foc [0.99971295 0.99964096 0.99898063 0.99973968 0.99975795 0.99958673\n",
            " 0.99972435] \n",
            ", Min Accs Foc: [0.9977648  0.99653334 0.99456516 0.9972087  0.99693633 0.99687797\n",
            " 0.99678614] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 2300 , Mean Loss: 4.676695072931745e-07 , Max Loss: 8.302618562280367e-06 , Mean Acc: 0.9995317088981893 , Min Acc: 0.9790691087185786 , Learning rate: 0.0004982674608158839 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 2300 Mean Loss: 4.707048532462612e-07 , Max Loss: 2.9950976570133028e-05 , Mean Acc: 0.9995121306597121 , Min Acc: 0.9945272514610908 \n",
            ", Mean Accs Foc [0.99951053 0.99943404 0.99896633 0.99974529 0.99969903 0.99954724\n",
            " 0.99968246] \n",
            ", Min Accs Foc: [0.99733135 0.99673132 0.99452725 0.99691222 0.99674327 0.99709843\n",
            " 0.99686937] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 2400 , Mean Loss: 3.7080293438189684e-07 , Max Loss: 7.961879638355254e-06 , Mean Acc: 0.9996007246622753 , Min Acc: 0.9866812153374724 , Learning rate: 0.0004969227007317547 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 2400 Mean Loss: 3.714372086524165e-07 , Max Loss: 3.0128957015318928e-05 , Mean Acc: 0.99960462756625 , Min Acc: 0.9945110149375938 \n",
            ", Mean Accs Foc [0.99973058 0.99966224 0.99898524 0.99975395 0.99976905 0.99959468\n",
            " 0.99973665] \n",
            ", Min Accs Foc: [0.99806528 0.99687573 0.99451101 0.99715123 0.99696681 0.99698449\n",
            " 0.9972192 ] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 2500 , Mean Loss: 4.022568801497227e-07 , Max Loss: 8.062814482177388e-06 , Mean Acc: 0.9995815445405397 , Min Acc: 0.9881167271217022 , Learning rate: 0.0004951972808367875 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 2500 Mean Loss: 6.26329098958365e-07 , Max Loss: 2.8336929376127263e-05 , Mean Acc: 0.9994271156049054 , Min Acc: 0.9946767557470911 \n",
            ", Mean Accs Foc [0.99967842 0.99876031 0.99898547 0.99972478 0.99969003 0.99959691\n",
            " 0.99955388] \n",
            ", Min Accs Foc: [0.9979429  0.99577729 0.99467676 0.99694299 0.99670075 0.99707073\n",
            " 0.99688639] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 2600 , Mean Loss: 3.76436841932936e-07 , Max Loss: 7.919984604114521e-06 , Mean Acc: 0.9995958943212762 , Min Acc: 0.9822075348844785 , Learning rate: 0.0004930938616033992 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 2600 Mean Loss: 3.7300211479216873e-07 , Max Loss: 2.804998549994846e-05 , Mean Acc: 0.9996009268418472 , Min Acc: 0.9947037762981584 \n",
            ", Mean Accs Foc [0.9997377  0.99962555 0.99898778 0.99976158 0.99976391 0.99959221\n",
            " 0.99973775] \n",
            ", Min Accs Foc: [0.99820641 0.99753011 0.99470378 0.99717437 0.99687105 0.99702665\n",
            " 0.99715726] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 2700 , Mean Loss: 3.8605062888159723e-07 , Max Loss: 7.873167072263387e-06 , Mean Acc: 0.9995823603665858 , Min Acc: 0.9819611360193199 , Learning rate: 0.0004906156863515891 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 2700 Mean Loss: 3.808347339522303e-07 , Max Loss: 3.0105317612394353e-05 , Mean Acc: 0.9995898218947588 , Min Acc: 0.9945131687093192 \n",
            ", Mean Accs Foc [0.99970168 0.99956804 0.99898906 0.99976286 0.99977154 0.99960086\n",
            " 0.99973472] \n",
            ", Min Accs Foc: [0.99786023 0.99698772 0.99451317 0.99746913 0.99716355 0.99711065\n",
            " 0.99743516] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 2800 , Mean Loss: 3.999609076829928e-07 , Max Loss: 7.896576979945027e-06 , Mean Acc: 0.9995790123301254 , Min Acc: 0.9761665810840554 , Learning rate: 0.00048776657624797365 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 2800 Mean Loss: 4.632722743302836e-07 , Max Loss: 3.142691049921567e-05 , Mean Acc: 0.9995212933268725 , Min Acc: 0.9943940290315401 \n",
            ", Mean Accs Foc [0.99965253 0.99924056 0.99898164 0.99975928 0.99973251 0.99960372\n",
            " 0.99967882] \n",
            ", Min Accs Foc: [0.99768639 0.99634186 0.99439403 0.99766411 0.99730254 0.99720886\n",
            " 0.99757643] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 2900 , Mean Loss: 3.702622964776033e-07 , Max Loss: 7.79133896588284e-06 , Mean Acc: 0.9996006133685862 , Min Acc: 0.9797787616784814 , Learning rate: 0.000484550924413825 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 2900 Mean Loss: 3.4955961031999627e-07 , Max Loss: 2.880457046942745e-05 , Mean Acc: 0.9996241632801535 , Min Acc: 0.9946330110425465 \n",
            ", Mean Accs Foc [0.99975054 0.99969388 0.9989903  0.99977107 0.99978423 0.99961802\n",
            " 0.99976111] \n",
            ", Min Accs Foc: [0.99817696 0.99770581 0.99463301 0.99750157 0.99706728 0.99727129\n",
            " 0.99736248] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 3000 , Mean Loss: 3.789198792444728e-07 , Max Loss: 7.768615754292445e-06 , Mean Acc: 0.9995921990924651 , Min Acc: 0.9839562641817032 , Learning rate: 0.0004809736891511961 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 3000 Mean Loss: 3.8934526013313594e-07 , Max Loss: 2.7894109978169882e-05 , Mean Acc: 0.999579421567669 , Min Acc: 0.9947185125221989 \n",
            ", Mean Accs Foc [0.99971771 0.99947808 0.99899346 0.99977233 0.99975647 0.99961168\n",
            " 0.99972622] \n",
            ", Min Accs Foc: [0.99838616 0.9976123  0.99471851 0.99744962 0.99698779 0.99739185\n",
            " 0.99730262] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 3100 , Mean Loss: 3.571089364823192e-07 , Max Loss: 7.763561565730185e-06 , Mean Acc: 0.999609348599595 , Min Acc: 0.9813824052539144 , Learning rate: 0.00047704038629757913 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 3100 Mean Loss: 3.752081615193289e-07 , Max Loss: 2.7170766983281806e-05 , Mean Acc: 0.999590172004551 , Min Acc: 0.994787441416801 \n",
            ", Mean Accs Foc [0.99967745 0.99958183 0.99899599 0.99977644 0.99975167 0.99960349\n",
            " 0.99974434] \n",
            ", Min Accs Foc: [0.99840368 0.99788441 0.99478744 0.99753106 0.99700478 0.99740583\n",
            " 0.99731853] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 3200 , Mean Loss: 3.7602158616901636e-07 , Max Loss: 7.707768051233101e-06 , Mean Acc: 0.9995921039860506 , Min Acc: 0.9866811963284243 , Learning rate: 0.00047275708072088253 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 3200 Mean Loss: 3.846794994790108e-07 , Max Loss: 2.8496163170347923e-05 , Mean Acc: 0.999579053295052 , Min Acc: 0.994661820238101 \n",
            ", Mean Accs Foc [0.99969052 0.99947826 0.99899319 0.99973136 0.99979    0.99962208\n",
            " 0.99974796] \n",
            ", Min Accs Foc: [0.99845771 0.99740396 0.99466182 0.99786357 0.99714285 0.99748805\n",
            " 0.99755232] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 3300 , Mean Loss: 3.813641790927157e-07 , Max Loss: 7.72722425275366e-06 , Mean Acc: 0.9995925813647409 , Min Acc: 0.9874991974837639 , Learning rate: 0.00046813037696784564 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 3300 Mean Loss: 3.5396455784345904e-07 , Max Loss: 2.773601653053424e-05 , Mean Acc: 0.9996146205220259 , Min Acc: 0.9947335005430045 \n",
            ", Mean Accs Foc [0.99973975 0.99962666 0.99899712 0.99976263 0.99979348 0.99961543\n",
            " 0.99976728] \n",
            ", Min Accs Foc: [0.99803956 0.99789099 0.9947335  0.99761027 0.99722332 0.99752781\n",
            " 0.99742853] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 3400 , Mean Loss: 3.4197002114007374e-07 , Max Loss: 7.67338028672574e-06 , Mean Acc: 0.9996237171020812 , Min Acc: 0.9824216451717658 , Learning rate: 0.00046316740908030533 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 3400 Mean Loss: 4.3511471256290377e-07 , Max Loss: 2.582610905878745e-05 , Mean Acc: 0.9995375246615938 , Min Acc: 0.9949180605022504 \n",
            ", Mean Accs Foc [0.99930145 0.99971044 0.99898225 0.99970518 0.9997208  0.99957508\n",
            " 0.99976748] \n",
            ", Min Accs Foc: [0.99764885 0.99816053 0.99491806 0.99787289 0.99687727 0.99728689\n",
            " 0.99723361] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 3500 , Mean Loss: 3.7839888234729856e-07 , Max Loss: 7.667766878332827e-06 , Mean Acc: 0.9995892950147794 , Min Acc: 0.9835844768487934 , Learning rate: 0.0004578758295950212 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 3500 Mean Loss: 3.3234559431317655e-07 , Max Loss: 2.7436901173507666e-05 , Mean Acc: 0.99963897703811 , Min Acc: 0.9947619754512309 \n",
            ", Mean Accs Foc [0.99977194 0.99972094 0.99899765 0.99978746 0.99979627 0.99961948\n",
            " 0.9997791 ] \n",
            ", Min Accs Foc: [0.99842004 0.99769425 0.99476198 0.99785958 0.99725931 0.99754092\n",
            " 0.9975407 ] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 3600 , Mean Loss: 3.2990980674319894e-07 , Max Loss: 7.6020328647143546e-06 , Mean Acc: 0.9996365521987679 , Min Acc: 0.9858039561250558 , Learning rate: 0.0004522637977440181 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 3600 Mean Loss: 3.6875635887015403e-07 , Max Loss: 2.9930698815923666e-05 , Mean Acc: 0.9995947806276411 , Min Acc: 0.9945291043863072 \n",
            ", Mean Accs Foc [0.99968748 0.99954892 0.99899427 0.99979005 0.99977117 0.9996134\n",
            " 0.99975817] \n",
            ", Min Accs Foc: [0.99791878 0.99777889 0.9945291  0.99784828 0.9975375  0.99762089\n",
            " 0.99767688] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 3700 , Mean Loss: 3.5785244092442614e-07 , Max Loss: 7.585439285936091e-06 , Mean Acc: 0.9996049753870909 , Min Acc: 0.9835220328326348 , Learning rate: 0.0004463399668736422 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 3700 Mean Loss: 3.531873646367804e-07 , Max Loss: 2.888974007462702e-05 , Mean Acc: 0.9996097801978179 , Min Acc: 0.9946250823192697 \n",
            ", Mean Accs Foc [0.99973054 0.99958531 0.99899981 0.99979331 0.99978464 0.99961056\n",
            " 0.9997643 ] \n",
            ", Min Accs Foc: [0.99810155 0.99781669 0.99462508 0.99794244 0.9975488  0.99754768\n",
            " 0.99770076] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 3800 , Mean Loss: 3.6130607115111463e-07 , Max Loss: 7.573857283721616e-06 , Mean Acc: 0.9996079343697151 , Min Acc: 0.9852701169576603 , Learning rate: 0.0004401134711017278 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 3800 Mean Loss: 3.272565156876174e-07 , Max Loss: 2.7741294889990198e-05 , Mean Acc: 0.9996429244428837 , Min Acc: 0.9947329994408591 \n",
            ", Mean Accs Foc [0.99977329 0.99972105 0.99899926 0.99979485 0.99979952 0.99962521\n",
            " 0.99978729] \n",
            ", Min Accs Foc: [0.99829128 0.99792068 0.994733   0.99799853 0.99730865 0.99759357\n",
            " 0.99754513] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 3900 , Mean Loss: 3.3310998204625677e-07 , Max Loss: 7.555737435258348e-06 , Mean Acc: 0.9996321974945565 , Min Acc: 0.9782150440703528 , Learning rate: 0.0004335939112334496 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 3900 Mean Loss: 3.234600025878845e-07 , Max Loss: 2.7220838502724787e-05 , Mean Acc: 0.9996475840148125 , Min Acc: 0.9947826406580795 \n",
            ", Mean Accs Foc [0.99978272 0.99973426 0.99900021 0.9997978  0.99980197 0.99962415\n",
            " 0.99979198] \n",
            ", Min Accs Foc: [0.99822663 0.99782942 0.99478264 0.99808171 0.99731481 0.99767239\n",
            " 0.99757891] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 4000 , Mean Loss: 3.486665428701223e-07 , Max Loss: 7.561437551690794e-06 , Mean Acc: 0.9996176339035379 , Min Acc: 0.9857213903442015 , Learning rate: 0.00042679133995757754 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 4000 Mean Loss: 3.278168746470727e-07 , Max Loss: 2.7711904711219267e-05 , Mean Acc: 0.9996408758757138 , Min Acc: 0.9947357902101817 \n",
            ", Mean Accs Foc [0.99977381 0.99970128 0.99900115 0.99980254 0.99979585 0.99962439\n",
            " 0.99978711] \n",
            ", Min Accs Foc: [0.9982379  0.99816399 0.99473579 0.99804532 0.99734971 0.99767181\n",
            " 0.99753985] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 4100 , Mean Loss: 3.3587571928991973e-07 , Max Loss: 7.518610851535467e-06 , Mean Acc: 0.9996269766291497 , Min Acc: 0.9820597804645097 , Learning rate: 0.0004197162463459588 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 4100 Mean Loss: 3.4512687735294346e-07 , Max Loss: 2.646861904090331e-05 , Mean Acc: 0.9996179677816285 , Min Acc: 0.99485523382058 \n",
            ", Mean Accs Foc [0.99966418 0.99968628 0.99899814 0.99978668 0.99977889 0.9996281\n",
            " 0.9997835 ] \n",
            ", Min Accs Foc: [0.99781091 0.9979221  0.99485523 0.99811603 0.99717379 0.99777433\n",
            " 0.99751724] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 4200 , Mean Loss: 3.307417145829674e-07 , Max Loss: 7.489251616735811e-06 , Mean Acc: 0.9996328237966924 , Min Acc: 0.9817055352350439 , Learning rate: 0.00041237953968012946 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 4200 Mean Loss: 3.2401960658500496e-07 , Max Loss: 2.8183659901874055e-05 , Mean Acc: 0.9996470442470938 , Min Acc: 0.9946911715132363 \n",
            ", Mean Accs Foc [0.99978494 0.99970723 0.9989981  0.99980391 0.99980281 0.99963606\n",
            " 0.99979625] \n",
            ", Min Accs Foc: [0.99823997 0.99820387 0.99469117 0.99806061 0.99741983 0.99775188\n",
            " 0.99758012] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 4300 , Mean Loss: 3.487894113970099e-07 , Max Loss: 7.531529638490795e-06 , Mean Acc: 0.9996166565448027 , Min Acc: 0.9855116144101437 , Learning rate: 0.00040479253262999307 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 4300 Mean Loss: 3.1911018954786303e-07 , Max Loss: 2.6959847999177585e-05 , Mean Acc: 0.9996508909275863 , Min Acc: 0.9948077126428541 \n",
            ", Mean Accs Foc [0.99976718 0.99974594 0.99900091 0.99980215 0.99980513 0.99963294\n",
            " 0.99980198] \n",
            ", Min Accs Foc: [0.99806961 0.99796825 0.99480771 0.99817541 0.99736607 0.99781974\n",
            " 0.9976409 ] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 4400 , Mean Loss: 3.2105985292344234e-07 , Max Loss: 7.489930986463211e-06 , Mean Acc: 0.9996455297543944 , Min Acc: 0.9879131618227339 , Learning rate: 0.0003969669238105037 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 4400 Mean Loss: 3.8970719138522565e-07 , Max Loss: 2.5702323007655127e-05 , Mean Acc: 0.9995740479821529 , Min Acc: 0.9949302541476268 \n",
            ", Mean Accs Foc [0.99972006 0.99937633 0.99900161 0.99980731 0.99976437 0.99961818\n",
            " 0.99973048] \n",
            ", Min Accs Foc: [0.99786298 0.99774334 0.99493025 0.99793655 0.99726017 0.99778161\n",
            " 0.99745246] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 4500 , Mean Loss: 3.2312729291431297e-07 , Max Loss: 7.473930743905188e-06 , Mean Acc: 0.9996413041980446 , Min Acc: 0.986146641839877 , Learning rate: 0.0003889147797432496 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 4500 Mean Loss: 3.1762528765144793e-07 , Max Loss: 2.7426604860862316e-05 , Mean Acc: 0.9996517266562559 , Min Acc: 0.9947629583865638 \n",
            ", Mean Accs Foc [0.99978594 0.99972128 0.99900164 0.99980773 0.99981111 0.99963498\n",
            " 0.9997994 ] \n",
            ", Min Accs Foc: [0.99814127 0.9980305  0.99476296 0.99817955 0.99751077 0.99779328\n",
            " 0.99771497] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 4600 , Mean Loss: 3.3514495390802916e-07 , Max Loss: 7.483034883055424e-06 , Mean Acc: 0.9996338978581162 , Min Acc: 0.9809638615066121 , Learning rate: 0.00038064851625075144 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 4600 Mean Loss: 3.193234816610134e-07 , Max Loss: 2.626295945872432e-05 , Mean Acc: 0.9996480533805799 , Min Acc: 0.9948752600594055 \n",
            ", Mean Accs Foc [0.99975336 0.99974079 0.99900487 0.99980173 0.99980588 0.99962501\n",
            " 0.99980475] \n",
            ", Min Accs Foc: [0.99790106 0.99803217 0.99487526 0.99812108 0.99741507 0.99783245\n",
            " 0.99770234] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 4700 , Mean Loss: 3.156342825210794e-07 , Max Loss: 7.463756252321919e-06 , Mean Acc: 0.9996499108847668 , Min Acc: 0.9804973829269645 , Learning rate: 0.00037218087931216394 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 4700 Mean Loss: 3.701531941198667e-07 , Max Loss: 2.856939570759319e-05 , Mean Acc: 0.9995924025640296 , Min Acc: 0.9946549653221337 \n",
            ", Mean Accs Foc [0.99974142 0.99941846 0.99899708 0.99981266 0.99978474 0.99963405\n",
            " 0.99975841] \n",
            ", Min Accs Foc: [0.99812276 0.99773776 0.99465497 0.99823781 0.99775639 0.99775753\n",
            " 0.99790245] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 4800 , Mean Loss: 3.255286757240711e-07 , Max Loss: 7.408981444522327e-06 , Mean Acc: 0.9996384943323244 , Min Acc: 0.9855906845439228 , Learning rate: 0.00036352492540989975 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 4800 Mean Loss: 3.221662805029122e-07 , Max Loss: 2.636927715980858e-05 , Mean Acc: 0.9996428950064172 , Min Acc: 0.9948648975511867 \n",
            ", Mean Accs Foc [0.99974502 0.99970713 0.99900272 0.99979536 0.99981047 0.99963593\n",
            " 0.99980362] \n",
            ", Min Accs Foc: [0.99783164 0.99795946 0.9948649  0.99822257 0.99747387 0.99782468\n",
            " 0.99776093] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 4900 , Mean Loss: 3.146761734394828e-07 , Max Loss: 7.422332890481807e-06 , Mean Acc: 0.9996498217091636 , Min Acc: 0.9841226879983296 , Learning rate: 0.00035469400139748013 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 4900 Mean Loss: 3.227628824982827e-07 , Max Loss: 2.6410355677905127e-05 , Mean Acc: 0.9996443371858352 , Min Acc: 0.9948608993317989 \n",
            ", Mean Accs Foc [0.99979841 0.99966158 0.99900614 0.99981454 0.99980294 0.99962982\n",
            " 0.99979694] \n",
            ", Min Accs Foc: [0.99800007 0.9981227  0.9948609  0.99804704 0.99750395 0.99779137\n",
            " 0.99763777] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 5000 , Mean Loss: 3.2176703701833885e-07 , Max Loss: 7.41486405592334e-06 , Mean Acc: 0.9996427018757658 , Min Acc: 0.984237568146983 , Learning rate: 0.0003457017239196542 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 5000 Mean Loss: 3.088286965213196e-07 , Max Loss: 2.72244660427572e-05 , Mean Acc: 0.999662415008822 , Min Acc: 0.9947822930282779 \n",
            ", Mean Accs Foc [0.99979072 0.99975909 0.99900431 0.999821   0.9998138  0.99963264\n",
            " 0.99981534] \n",
            ", Min Accs Foc: [0.99818143 0.99837644 0.99478229 0.99816748 0.99765047 0.9977755\n",
            " 0.99776501] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 5100 , Mean Loss: 3.120954266385505e-07 , Max Loss: 7.396366019185306e-06 , Mean Acc: 0.9996543900011153 , Min Acc: 0.9866537577321801 , Learning rate: 0.00033656195841651936 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 5100 Mean Loss: 3.2041707259630953e-07 , Max Loss: 2.5934566282756922e-05 , Mean Acc: 0.9996461418340592 , Min Acc: 0.99490740083231 \n",
            ", Mean Accs Foc [0.99975808 0.99970261 0.99900508 0.99982239 0.99979816 0.99963433\n",
            " 0.99980235] \n",
            ", Min Accs Foc: [0.99777957 0.99809833 0.9949074  0.99810889 0.99746718 0.99782203\n",
            " 0.99765717] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 5200 , Mean Loss: 3.0470559187460453e-07 , Max Loss: 7.367540010110958e-06 , Mean Acc: 0.9996621973995647 , Min Acc: 0.985206144404279 , Learning rate: 0.0003272887977440181 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 5200 Mean Loss: 3.132677411031261e-07 , Max Loss: 2.7264324014176907e-05 , Mean Acc: 0.9996548765010798 , Min Acc: 0.994778474934066 \n",
            ", Mean Accs Foc [0.99975638 0.99974249 0.99900323 0.99982138 0.99980965 0.99963477\n",
            " 0.99981623] \n",
            ", Min Accs Foc: [0.99829192 0.99825986 0.99477847 0.99818266 0.99775467 0.99774572\n",
            " 0.99782605] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 5300 , Mean Loss: 3.083358910574871e-07 , Max Loss: 7.368958236846758e-06 , Mean Acc: 0.9996569837598139 , Min Acc: 0.9844847297400927 , Learning rate: 0.0003178965404437753 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 5300 Mean Loss: 3.359482021723374e-07 , Max Loss: 2.7744449211873256e-05 , Mean Acc: 0.99962568607123 , Min Acc: 0.9947327000074162 \n",
            ", Mean Accs Foc [0.9997328  0.99959919 0.99899944 0.999826   0.99979505 0.9996299\n",
            " 0.99979742] \n",
            ", Min Accs Foc: [0.99814903 0.99787928 0.9947327  0.99830543 0.99788075 0.99768814\n",
            " 0.99791143] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 5400 , Mean Loss: 3.085504402812955e-07 , Max Loss: 7.354599927167549e-06 , Mean Acc: 0.9996559865437814 , Min Acc: 0.9871826085960214 , Learning rate: 0.0003083996686957836 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 5400 Mean Loss: 3.028952584404698e-07 , Max Loss: 2.6266552024918414e-05 , Mean Acc: 0.9996709121868474 , Min Acc: 0.9948749095593425 \n",
            ", Mean Accs Foc [0.99981176 0.99977077 0.99900436 0.99982943 0.99981855 0.99964238\n",
            " 0.99981914] \n",
            ", Min Accs Foc: [0.99806254 0.99844151 0.99487491 0.99814862 0.99767423 0.99773988\n",
            " 0.99781627] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 5500 , Mean Loss: 3.0112203684815e-07 , Max Loss: 7.345775013072543e-06 , Mean Acc: 0.9996665697541898 , Min Acc: 0.9826952686361803 , Learning rate: 0.0002988128259879313 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 5500 Mean Loss: 3.0683890125568806e-07 , Max Loss: 2.6501488846718197e-05 , Mean Acc: 0.9996637487854081 , Min Acc: 0.9948520403219607 \n",
            ", Mean Accs Foc [0.99981453 0.99972409 0.99900453 0.99982543 0.99981904 0.99964326\n",
            " 0.99981536] \n",
            ", Min Accs Foc: [0.99796197 0.99829314 0.99485204 0.99828742 0.99769914 0.99778987\n",
            " 0.99786938] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 5600 , Mean Loss: 3.031998826649489e-07 , Max Loss: 7.3363492862830486e-06 , Mean Acc: 0.9996636980466141 , Min Acc: 0.9828120483300671 , Learning rate: 0.0002891507945368057 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 5600 Mean Loss: 3.0212403132204136e-07 , Max Loss: 2.609837800740731e-05 , Mean Acc: 0.9996698088816287 , Min Acc: 0.9948913428371629 \n",
            ", Mean Accs Foc [0.99980314 0.99976952 0.99900783 0.99983007 0.999817   0.99963642\n",
            " 0.99982468] \n",
            ", Min Accs Foc: [0.99787116 0.9984258  0.99489134 0.99821476 0.99768591 0.99776519\n",
            " 0.99781338] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 5700 , Mean Loss: 3.0067717298009206e-07 , Max Loss: 7.323309344939673e-06 , Mean Acc: 0.9996657544985353 , Min Acc: 0.9824251720013557 , Learning rate: 0.0002794284724945865 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 5700 Mean Loss: 3.037191082188582e-07 , Max Loss: 2.64661701613671e-05 , Mean Acc: 0.9996671878689842 , Min Acc: 0.9948554718232507 \n",
            ", Mean Accs Foc [0.99980754 0.99974669 0.99900678 0.99983457 0.99981914 0.99963316\n",
            " 0.99982244] \n",
            ", Min Accs Foc: [0.99814557 0.99828567 0.99485547 0.99820648 0.99780214 0.99774545\n",
            " 0.99787376] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 5800 , Mean Loss: 2.961191118280379e-07 , Max Loss: 7.330965582901387e-06 , Mean Acc: 0.9996737426179784 , Min Acc: 0.9880302919793731 , Learning rate: 0.00026966085097717487 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 5800 Mean Loss: 3.011288068712046e-07 , Max Loss: 2.5825510283279675e-05 , Mean Acc: 0.9996713935183952 , Min Acc: 0.994918119414697 \n",
            ", Mean Accs Foc [0.99979357 0.99978264 0.99900721 0.99982896 0.9998205  0.99963947\n",
            " 0.99982741] \n",
            ", Min Accs Foc: [0.99814146 0.99843267 0.99491812 0.99815442 0.99777527 0.99774063\n",
            " 0.99784524] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 5900 , Mean Loss: 2.9602360773739664e-07 , Max Loss: 7.319154171544881e-06 , Mean Acc: 0.9996728626384166 , Min Acc: 0.9847027542033118 , Learning rate: 0.0002598629909489792 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 5900 Mean Loss: 2.9910861047514453e-07 , Max Loss: 2.5911514730438248e-05 , Mean Acc: 0.999674754446956 , Min Acc: 0.994909664575842 \n",
            ", Mean Accs Foc [0.9998208  0.99976999 0.99900656 0.99983407 0.99982471 0.99964278\n",
            " 0.99982438] \n",
            ", Min Accs Foc: [0.99797827 0.99834897 0.99490966 0.99821415 0.99774404 0.9977728\n",
            " 0.99786426] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 6000 , Mean Loss: 2.93991665180238e-07 , Max Loss: 7.302819150754724e-06 , Mean Acc: 0.9996754626340894 , Min Acc: 0.9836320706662267 , Learning rate: 0.00025005 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 6000 Mean Loss: 3.010495009859634e-07 , Max Loss: 2.5617830475521873e-05 , Mean Acc: 0.9996723877460667 , Min Acc: 0.9949385940218629 \n",
            ", Mean Accs Foc [0.99980147 0.99977183 0.99900716 0.99983151 0.99982239 0.99964354\n",
            " 0.99982882] \n",
            ", Min Accs Foc: [0.99809115 0.99845765 0.99493859 0.99810164 0.99774279 0.99777439\n",
            " 0.99782403] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 6100 , Mean Loss: 2.9564299064505986e-07 , Max Loss: 7.325578057204508e-06 , Mean Acc: 0.9996738592167513 , Min Acc: 0.97808738751866 , Learning rate: 0.0002402370090510208 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 6100 Mean Loss: 2.9807393308326635e-07 , Max Loss: 2.562862015193678e-05 , Mean Acc: 0.9996751616515007 , Min Acc: 0.9949375282566777 \n",
            ", Mean Accs Foc [0.99981247 0.99977366 0.9990087  0.9998396  0.99982281 0.99964045\n",
            " 0.99982843] \n",
            ", Min Accs Foc: [0.99805294 0.99834867 0.99493753 0.99815345 0.99779819 0.99775552\n",
            " 0.99788073] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 6200 , Mean Loss: 2.915133221296599e-07 , Max Loss: 7.294741929576181e-06 , Mean Acc: 0.9996794375509589 , Min Acc: 0.9845718229447395 , Learning rate: 0.00023043914902282515 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 6200 Mean Loss: 2.9583119625964024e-07 , Max Loss: 2.5683794228796023e-05 , Mean Acc: 0.9996794132897613 , Min Acc: 0.9949320818644343 \n",
            ", Mean Accs Foc [0.9998234  0.99978801 0.99900754 0.99984045 0.9998235  0.99964242\n",
            " 0.99983057] \n",
            ", Min Accs Foc: [0.99790267 0.99846221 0.99493208 0.99822705 0.99777156 0.99773923\n",
            " 0.99787226] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 6300 , Mean Loss: 2.914844699598714e-07 , Max Loss: 7.298528810344672e-06 , Mean Acc: 0.9996788235047125 , Min Acc: 0.9824235641296357 , Learning rate: 0.0002206715275054135 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 6300 Mean Loss: 2.966431555586269e-07 , Max Loss: 2.5711871446699787e-05 , Mean Acc: 0.9996773122706826 , Min Acc: 0.994929312527211 \n",
            ", Mean Accs Foc [0.99982757 0.99976702 0.99900748 0.99984111 0.9998264  0.99964062\n",
            " 0.99983098] \n",
            ", Min Accs Foc: [0.9979891  0.9983068  0.99492931 0.99826418 0.9978664  0.99773053\n",
            " 0.9979479 ] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 6400 , Mean Loss: 2.893841301826993e-07 , Max Loss: 7.2900170050893e-06 , Mean Acc: 0.9996817181588431 , Min Acc: 0.9805258889836388 , Learning rate: 0.0002109492054631943 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 6400 Mean Loss: 2.9463189177616833e-07 , Max Loss: 2.539150749352503e-05 , Mean Acc: 0.9996807619866729 , Min Acc: 0.9949610013401942 \n",
            ", Mean Accs Foc [0.99982554 0.9997832  0.99900844 0.99984289 0.9998289  0.99964467\n",
            " 0.99983169] \n",
            ", Min Accs Foc: [0.99803692 0.99837146 0.994961   0.99819733 0.99781669 0.99776942\n",
            " 0.9979231 ] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 6500 , Mean Loss: 2.890468331522875e-07 , Max Loss: 7.302954668729671e-06 , Mean Acc: 0.9996831228488734 , Min Acc: 0.98000700770422 , Learning rate: 0.00020128717401206875 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 6500 Mean Loss: 2.9410681441583427e-07 , Max Loss: 2.5321504219577627e-05 , Mean Acc: 0.9996803063721962 , Min Acc: 0.9949679522836545 \n",
            ", Mean Accs Foc [0.9998242  0.99978373 0.99901033 0.99984426 0.99982798 0.999638\n",
            " 0.99983366] \n",
            ", Min Accs Foc: [0.99807232 0.99835257 0.99496795 0.99817417 0.99790169 0.99773149\n",
            " 0.99793913] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 6600 , Mean Loss: 2.87407358199873e-07 , Max Loss: 7.2665317547600245e-06 , Mean Acc: 0.9996842568971954 , Min Acc: 0.9835073342098346 , Learning rate: 0.00019170033130421645 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 6600 Mean Loss: 2.929952025857158e-07 , Max Loss: 2.4929596167946323e-05 , Mean Acc: 0.9996828748961226 , Min Acc: 0.9950070453468967 \n",
            ", Mean Accs Foc [0.99982853 0.99979494 0.99901117 0.99984328 0.99982935 0.99963863\n",
            " 0.99983422] \n",
            ", Min Accs Foc: [0.99786985 0.99843511 0.99500705 0.99822032 0.99782463 0.99775558\n",
            " 0.99791164] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 6700 , Mean Loss: 2.8604681613516003e-07 , Max Loss: 7.255826621226835e-06 , Mean Acc: 0.9996862177917851 , Min Acc: 0.9848064408683368 , Learning rate: 0.0001822034595562247 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 6700 Mean Loss: 2.92911770522779e-07 , Max Loss: 2.514545697111968e-05 , Mean Acc: 0.9996832344909741 , Min Acc: 0.9949854753992906 \n",
            ", Mean Accs Foc [0.99982985 0.99979028 0.99900903 0.99984637 0.99982587 0.99964549\n",
            " 0.99983575] \n",
            ", Min Accs Foc: [0.99797427 0.99850914 0.99498548 0.99815607 0.99783378 0.99774836\n",
            " 0.99789832] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 6800 , Mean Loss: 2.8655299232613694e-07 , Max Loss: 7.279948274203426e-06 , Mean Acc: 0.9996861317592931 , Min Acc: 0.9841504008973505 , Learning rate: 0.00017281120225598194 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 6800 Mean Loss: 2.922531126057906e-07 , Max Loss: 2.49667231308764e-05 , Mean Acc: 0.9996844503200624 , Min Acc: 0.995003328795 \n",
            ", Mean Accs Foc [0.99983281 0.99979232 0.99900942 0.99984739 0.99982814 0.99964609\n",
            " 0.99983498] \n",
            ", Min Accs Foc: [0.99794599 0.99848214 0.99500333 0.99820362 0.99785184 0.99776224\n",
            " 0.99790289] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 6900 , Mean Loss: 2.845567082752244e-07 , Max Loss: 7.2392046898414294e-06 , Mean Acc: 0.9996882338540272 , Min Acc: 0.9855730008742691 , Learning rate: 0.00016353804158348063 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 6900 Mean Loss: 2.9097173177148105e-07 , Max Loss: 2.5141713436238186e-05 , Mean Acc: 0.9996864349905401 , Min Acc: 0.9949858486823553 \n",
            ", Mean Accs Foc [0.99983465 0.99979701 0.99900797 0.99984763 0.99983032 0.99964939\n",
            " 0.99983808] \n",
            ", Min Accs Foc: [0.99803342 0.99841064 0.99498585 0.99820709 0.99790309 0.9977456\n",
            " 0.9979533 ] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 7000 , Mean Loss: 2.842669044614741e-07 , Max Loss: 7.223328340116423e-06 , Mean Acc: 0.9996891149283613 , Min Acc: 0.986314873069543 , Learning rate: 0.00015439827608034582 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 7000 Mean Loss: 2.902937198717467e-07 , Max Loss: 2.5126291605850438e-05 , Mean Acc: 0.9996874400472578 , Min Acc: 0.9949873867488255 \n",
            ", Mean Accs Foc [0.9998366  0.99979976 0.99900849 0.99984781 0.99983128 0.99964898\n",
            " 0.99983915] \n",
            ", Min Accs Foc: [0.99795573 0.99845176 0.99498739 0.9982329  0.99789128 0.99774672\n",
            " 0.9979471 ] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 7100 , Mean Loss: 2.831910188349135e-07 , Max Loss: 7.25932543751375e-06 , Mean Acc: 0.9996907159705523 , Min Acc: 0.9861807753368703 , Learning rate: 0.0001454059986025198 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 7100 Mean Loss: 2.899205839471589e-07 , Max Loss: 2.5156535006929442e-05 , Mean Acc: 0.9996878328774259 , Min Acc: 0.9949843709261021 \n",
            ", Mean Accs Foc [0.99983759 0.99980061 0.99900902 0.99984979 0.99983008 0.99964585\n",
            " 0.9998419 ] \n",
            ", Min Accs Foc: [0.99806158 0.99847645 0.99498437 0.99822062 0.99792791 0.99773393\n",
            " 0.99794431] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 7200 , Mean Loss: 2.833215921362394e-07 , Max Loss: 7.249147144274286e-06 , Mean Acc: 0.9996906422050096 , Min Acc: 0.9869196536011589 , Learning rate: 0.0001365750745901003 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 7200 Mean Loss: 2.894485553287413e-07 , Max Loss: 2.486196496939169e-05 , Mean Acc: 0.9996872847256183 , Min Acc: 0.9950138226095142 \n",
            ", Mean Accs Foc [0.99983228 0.99980219 0.99901129 0.99985017 0.99983041 0.99964326\n",
            " 0.9998414 ] \n",
            ", Min Accs Foc: [0.99799624 0.99844848 0.99501382 0.99820953 0.99791947 0.99771205\n",
            " 0.99796095] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 7300 , Mean Loss: 2.824933126593009e-07 , Max Loss: 7.224934105865781e-06 , Mean Acc: 0.9996913681523938 , Min Acc: 0.9835868452383119 , Learning rate: 0.00012791912068783607 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 7300 Mean Loss: 2.8905801150474387e-07 , Max Loss: 2.470722734822297e-05 , Mean Acc: 0.9996892523078311 , Min Acc: 0.9950293634866123 \n",
            ", Mean Accs Foc [0.99983933 0.99980085 0.99901019 0.99985123 0.99983296 0.99964882\n",
            " 0.9998414 ] \n",
            ", Min Accs Foc: [0.99800587 0.99841433 0.99502936 0.99820526 0.99791277 0.99775815\n",
            " 0.99797201] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 7400 , Mean Loss: 2.8205232201900553e-07 , Max Loss: 7.221697210733982e-06 , Mean Acc: 0.9996923405076099 , Min Acc: 0.98716794105336 , Learning rate: 0.0001194514837492486 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 7400 Mean Loss: 2.8898609622835264e-07 , Max Loss: 2.4791700072771526e-05 , Mean Acc: 0.9996885896668128 , Min Acc: 0.9950208735632873 \n",
            ", Mean Accs Foc [0.99983814 0.99979534 0.99900983 0.99985117 0.99983422 0.99965011\n",
            " 0.99984132] \n",
            ", Min Accs Foc: [0.99812943 0.99837798 0.99502087 0.99821832 0.99795106 0.99775074\n",
            " 0.99799604] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 7500 , Mean Loss: 2.807820761584872e-07 , Max Loss: 7.21150777136748e-06 , Mean Acc: 0.9996933431508525 , Min Acc: 0.9832427062346067 , Learning rate: 0.0001111852202567505 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 7500 Mean Loss: 2.8803766266320474e-07 , Max Loss: 2.4684399497145298e-05 , Mean Acc: 0.9996899644111183 , Min Acc: 0.995031660287667 \n",
            ", Mean Accs Foc [0.99984139 0.99980032 0.99901044 0.99985293 0.99983413 0.99964781\n",
            " 0.99984273] \n",
            ", Min Accs Foc: [0.99807822 0.99846284 0.99503166 0.9982334  0.99796077 0.9977285\n",
            " 0.99800419] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 7600 , Mean Loss: 2.8079550765703364e-07 , Max Loss: 7.217067111826762e-06 , Mean Acc: 0.9996938660381542 , Min Acc: 0.9852985109821042 , Learning rate: 0.00010313307618949637 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 7600 Mean Loss: 2.8709339287426064e-07 , Max Loss: 2.4732147419984338e-05 , Mean Acc: 0.9996909576245374 , Min Acc: 0.995026857389941 \n",
            ", Mean Accs Foc [0.99984176 0.99980633 0.9990124  0.99985444 0.99983438 0.9996429\n",
            " 0.99984449] \n",
            ", Min Accs Foc: [0.99802788 0.99851999 0.99502686 0.99822612 0.99797224 0.99773856\n",
            " 0.99799008] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 7700 , Mean Loss: 2.801318927340228e-07 , Max Loss: 7.208597934980982e-06 , Mean Acc: 0.9996946636587647 , Min Acc: 0.9795540060180643 , Learning rate: 9.530746737000706e-05 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 7700 Mean Loss: 2.868008704382023e-07 , Max Loss: 2.4538268337004948e-05 , Mean Acc: 0.9996911514953296 , Min Acc: 0.9950463883542404 \n",
            ", Mean Accs Foc [0.99984116 0.99980608 0.99901347 0.99985477 0.99983415 0.99964308\n",
            " 0.99984535] \n",
            ", Min Accs Foc: [0.99807078 0.99853326 0.99504639 0.99820101 0.997967   0.9977362\n",
            " 0.99799134] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 7800 , Mean Loss: 2.7921705119666615e-07 , Max Loss: 7.197411275580583e-06 , Mean Acc: 0.9996954859905981 , Min Acc: 0.9826913858857571 , Learning rate: 8.772046031987063e-05 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 7800 Mean Loss: 2.8696054834947753e-07 , Max Loss: 2.4374903089643202e-05 , Mean Acc: 0.9996924380252104 , Min Acc: 0.9950629053999702 \n",
            ", Mean Accs Foc [0.99984296 0.99980798 0.99901073 0.99985508 0.99983629 0.99965002\n",
            " 0.99984401] \n",
            ", Min Accs Foc: [0.99806966 0.99845374 0.99506291 0.99817528 0.99795516 0.99777496\n",
            " 0.99799593] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 7900 , Mean Loss: 2.7921608274587187e-07 , Max Loss: 7.194552066099818e-06 , Mean Acc: 0.9996958108001607 , Min Acc: 0.9880825508317295 , Learning rate: 8.038375365404128e-05 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 7900 Mean Loss: 2.866718569956093e-07 , Max Loss: 2.4726842947863116e-05 , Mean Acc: 0.999691818921052 , Min Acc: 0.995027390730425 \n",
            ", Mean Accs Foc [0.99984382 0.99980581 0.99901078 0.99985453 0.99983535 0.9996465\n",
            " 0.99984594] \n",
            ", Min Accs Foc: [0.99811219 0.99855356 0.99502739 0.99828087 0.99800325 0.99773331\n",
            " 0.99800732] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 8000 , Mean Loss: 2.7924073870546217e-07 , Max Loss: 7.197869821876525e-06 , Mean Acc: 0.9996960147510564 , Min Acc: 0.985174823144938 , Learning rate: 7.330866004242246e-05 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 8000 Mean Loss: 2.857515807213122e-07 , Max Loss: 2.450340699071434e-05 , Mean Acc: 0.9996933213405624 , Min Acc: 0.9950499083856241 \n",
            ", Mean Accs Foc [0.99984516 0.99980914 0.99901241 0.9998566  0.99983749 0.99964613\n",
            " 0.99984632] \n",
            ", Min Accs Foc: [0.99811512 0.9985541  0.99504991 0.99824162 0.99799179 0.99773781\n",
            " 0.99800942] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 8100 , Mean Loss: 2.792541977257082e-07 , Max Loss: 7.204539268121878e-06 , Mean Acc: 0.9996962806164443 , Min Acc: 0.9847478603979543 , Learning rate: 6.65060887665504e-05 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 8100 Mean Loss: 2.856638650040568e-07 , Max Loss: 2.4428462074749768e-05 , Mean Acc: 0.9996933163471894 , Min Acc: 0.9950574842362669 \n",
            ", Mean Accs Foc [0.99984559 0.99980709 0.99901185 0.99985647 0.99983508 0.99964943\n",
            " 0.99984771] \n",
            ", Min Accs Foc: [0.99809501 0.99854431 0.99505748 0.99824144 0.99799934 0.99774794\n",
            " 0.9980228 ] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 8200 , Mean Loss: 2.7860046543584627e-07 , Max Loss: 7.193582995591672e-06 , Mean Acc: 0.999697048421267 , Min Acc: 0.9860041942026057 , Learning rate: 5.9986528898272277e-05 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 8200 Mean Loss: 2.8519904245813355e-07 , Max Loss: 2.455770917653889e-05 , Mean Acc: 0.9996940716952463 , Min Acc: 0.9950444264533216 \n",
            ", Mean Accs Foc [0.99984503 0.99981039 0.99901199 0.9998578  0.99983725 0.9996488\n",
            " 0.99984724] \n",
            ", Min Accs Foc: [0.99809491 0.99853827 0.99504443 0.99824839 0.99800715 0.99775206\n",
            " 0.99801305] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 8300 , Mean Loss: 2.777397871065202e-07 , Max Loss: 7.183084994662543e-06 , Mean Acc: 0.9996976861325021 , Min Acc: 0.986718352394556 , Learning rate: 5.376003312635778e-05 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 8300 Mean Loss: 2.849794934774001e-07 , Max Loss: 2.443494455100462e-05 , Mean Acc: 0.9996944270406167 , Min Acc: 0.9950568284926573 \n",
            ", Mean Accs Foc [0.99984559 0.99981057 0.9990125  0.99985821 0.99983897 0.99964803\n",
            " 0.99984712] \n",
            ", Min Accs Foc: [0.99810553 0.99856288 0.99505683 0.99825296 0.99799508 0.99777476\n",
            " 0.99802397] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 8400 , Mean Loss: 2.7786818178309917e-07 , Max Loss: 7.190924078559267e-06 , Mean Acc: 0.9996979480334287 , Min Acc: 0.9839015733405065 , Learning rate: 4.783620225598192e-05 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 8400 Mean Loss: 2.850078739357999e-07 , Max Loss: 2.4365945846676848e-05 , Mean Acc: 0.9996950037945767 , Min Acc: 0.9950638126203843 \n",
            ", Mean Accs Foc [0.99984724 0.99981048 0.99901102 0.99985868 0.99983794 0.99965219\n",
            " 0.99984747] \n",
            ", Min Accs Foc: [0.998086   0.99857437 0.99506381 0.99824924 0.99800291 0.99776346\n",
            " 0.99802641] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 8500 , Mean Loss: 2.7747556448649535e-07 , Max Loss: 7.1842430042538646e-06 , Mean Acc: 0.999698340930797 , Min Acc: 0.9840050777815881 , Learning rate: 4.222417040497879e-05 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 8500 Mean Loss: 2.845797093233324e-07 , Max Loss: 2.4382860280406287e-05 , Mean Acc: 0.9996946486274441 , Min Acc: 0.9950620996080919 \n",
            ", Mean Accs Foc [0.99984517 0.99981217 0.99901271 0.99985933 0.99983786 0.99964754\n",
            " 0.99984776] \n",
            ", Min Accs Foc: [0.99813206 0.99855343 0.9950621  0.99824903 0.99803205 0.99775508\n",
            " 0.99803654] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 8600 , Mean Loss: 2.772326062684348e-07 , Max Loss: 7.174043936598239e-06 , Mean Acc: 0.9996984896168217 , Min Acc: 0.9888543931773981 , Learning rate: 3.6932590919694664e-05 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 8600 Mean Loss: 2.8448244058552765e-07 , Max Loss: 2.432548950809749e-05 , Mean Acc: 0.9996957281453627 , Min Acc: 0.9950679122566506 \n",
            ", Mean Accs Foc [0.99984672 0.99981264 0.99901084 0.99985913 0.99983879 0.99965369\n",
            " 0.99984828] \n",
            ", Min Accs Foc: [0.99816752 0.99859089 0.99506791 0.99827226 0.99801695 0.99775314\n",
            " 0.99803575] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 8700 , Mean Loss: 2.7766758710717784e-07 , Max Loss: 7.214109913323871e-06 , Mean Acc: 0.9996987643678881 , Min Acc: 0.9856198844458408 , Learning rate: 3.196962303215435e-05 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 8700 Mean Loss: 2.8413664525212423e-07 , Max Loss: 2.424740570777697e-05 , Mean Acc: 0.999695485394804 , Min Acc: 0.9950758345166133 \n",
            ", Mean Accs Foc [0.99984849 0.99981307 0.9990131  0.99985944 0.9998377  0.99964756\n",
            " 0.99984905] \n",
            ", Min Accs Foc: [0.99810934 0.99860677 0.99507583 0.9982646  0.99802999 0.99776513\n",
            " 0.99804021] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 8800 , Mean Loss: 2.7679577382319787e-07 , Max Loss: 7.187578025569428e-06 , Mean Acc: 0.999699240631333 , Min Acc: 0.9827458187287499 , Learning rate: 2.7342919279117472e-05 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 8800 Mean Loss: 2.8406728688180855e-07 , Max Loss: 2.4400940167576315e-05 , Mean Acc: 0.999696056113949 , Min Acc: 0.9950602692211441 \n",
            ", Mean Accs Foc [0.99984703 0.99981353 0.99901136 0.99986001 0.99983964 0.99965183\n",
            " 0.999849  ] \n",
            ", Min Accs Foc: [0.9981574  0.99857848 0.99506027 0.99825453 0.99802688 0.99776238\n",
            " 0.99804795] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 8900 , Mean Loss: 2.769995564597148e-07 , Max Loss: 7.1930762272924915e-06 , Mean Acc: 0.9996992046456993 , Min Acc: 0.9806775452351464 , Learning rate: 2.3059613702420968e-05 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 8900 Mean Loss: 2.8380163457548725e-07 , Max Loss: 2.4392498348718628e-05 , Mean Acc: 0.9996959180530861 , Min Acc: 0.9950611237767364 \n",
            ", Mean Accs Foc [0.99984666 0.99981356 0.99901244 0.99986001 0.99984033 0.99964888\n",
            " 0.99984955] \n",
            ", Min Accs Foc: [0.99815918 0.99856748 0.99506112 0.99826722 0.99802836 0.99774772\n",
            " 0.99805008] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 9000 , Mean Loss: 2.7683400507625583e-07 , Max Loss: 7.1930354324064e-06 , Mean Acc: 0.9996994680078273 , Min Acc: 0.9819044585797629 , Learning rate: 1.9126310848803877e-05 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 9000 Mean Loss: 2.835687204026202e-07 , Max Loss: 2.42519136152643e-05 , Mean Acc: 0.9996959887942879 , Min Acc: 0.9950753768047429 \n",
            ", Mean Accs Foc [0.99984795 0.99981357 0.99901385 0.99986084 0.99983992 0.9996462\n",
            " 0.99984959] \n",
            ", Min Accs Foc: [0.99816002 0.99856946 0.99507538 0.99824935 0.99804299 0.99773555\n",
            " 0.99805363] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 9100 , Mean Loss: 2.762903839480366e-07 , Max Loss: 7.1746362448611475e-06 , Mean Acc: 0.9996996468548561 , Min Acc: 0.9839115100620459 , Learning rate: 1.5549075586175112e-05 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 9100 Mean Loss: 2.8370210388330373e-07 , Max Loss: 2.4295542046399245e-05 , Mean Acc: 0.9996966258652726 , Min Acc: 0.9950709491738876 \n",
            ", Mean Accs Foc [0.99984888 0.9998137  0.99901165 0.99986064 0.99983894 0.99965269\n",
            " 0.9998499 ] \n",
            ", Min Accs Foc: [0.99815016 0.99859973 0.99507095 0.99827159 0.99802629 0.99776999\n",
            " 0.99804406] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 9200 , Mean Loss: 2.7688632422698746e-07 , Max Loss: 7.205049341995032e-06 , Mean Acc: 0.9996996256556352 , Min Acc: 0.9851553190849951 , Learning rate: 1.2333423752026375e-05 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 9200 Mean Loss: 2.8348492181525683e-07 , Max Loss: 2.4224642819131963e-05 , Mean Acc: 0.9996965273143811 , Min Acc: 0.9950781464041347 \n",
            ", Mean Accs Foc [0.99984903 0.99981471 0.99901317 0.99986095 0.99983944 0.99964852\n",
            " 0.99984988] \n",
            ", Min Accs Foc: [0.99816365 0.99858543 0.99507815 0.99824856 0.99804209 0.99775505\n",
            " 0.99804899] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 9300 , Mean Loss: 2.76619782097396e-07 , Max Loss: 7.169343766643007e-06 , Mean Acc: 0.999699622525296 , Min Acc: 0.9844641791354996 , Learning rate: 9.484313648410891e-06 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 9300 Mean Loss: 2.8342434960413914e-07 , Max Loss: 2.4255581182157546e-05 , Mean Acc: 0.999696696203795 , Min Acc: 0.9950750044485139 \n",
            ", Mean Accs Foc [0.99984864 0.99981449 0.99901283 0.99986106 0.99983998 0.99964984\n",
            " 0.99985004] \n",
            ", Min Accs Foc: [0.99815962 0.99859729 0.995075   0.99826345 0.99803743 0.99776254\n",
            " 0.99805238] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 9400 , Mean Loss: 2.764417275583593e-07 , Max Loss: 7.182264561069016e-06 , Mean Acc: 0.9996998741139222 , Min Acc: 0.9873998073337835 , Learning rate: 7.006138396600745e-06 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 9400 Mean Loss: 2.833300861787833e-07 , Max Loss: 2.426471322511067e-05 , Mean Acc: 0.9996966066950871 , Min Acc: 0.995074077423963 \n",
            ", Mean Accs Foc [0.99984835 0.99981476 0.99901336 0.9998611  0.99984016 0.99964848\n",
            " 0.99985003] \n",
            ", Min Accs Foc: [0.99816145 0.99858753 0.99507408 0.99827157 0.99804072 0.99775373\n",
            " 0.99805436] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 9500 , Mean Loss: 2.763014981657799e-07 , Max Loss: 7.17332696299726e-06 , Mean Acc: 0.9997000286050661 , Min Acc: 0.9848447989861444 , Learning rate: 4.902719163212554e-06 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 9500 Mean Loss: 2.8344241997752074e-07 , Max Loss: 2.4213353860434563e-05 , Mean Acc: 0.9996968151418635 , Min Acc: 0.9950792933576127 \n",
            ", Mean Accs Foc [0.99984877 0.99981443 0.99901257 0.99986116 0.9998398  0.99965086\n",
            " 0.99985012] \n",
            ", Min Accs Foc: [0.99816772 0.9986062  0.99507929 0.99826401 0.99803365 0.99776515\n",
            " 0.99804912] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 9600 , Mean Loss: 2.7616486814414016e-07 , Max Loss: 7.1675729397051405e-06 , Mean Acc: 0.9997001297608265 , Min Acc: 0.9828589775654422 , Learning rate: 3.1772992682453426e-06 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 9600 Mean Loss: 2.833099523659392e-07 , Max Loss: 2.4248256207948106e-05 , Mean Acc: 0.9996967952717709 , Min Acc: 0.9950757481575423 \n",
            ", Mean Accs Foc [0.9998487  0.99981491 0.99901281 0.99986124 0.99983985 0.99965003\n",
            " 0.99985003] \n",
            ", Min Accs Foc: [0.99817214 0.99858836 0.99507575 0.99827047 0.99804178 0.99775592\n",
            " 0.99805315] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 9700 , Mean Loss: 2.770986466105572e-07 , Max Loss: 7.1999861004394454e-06 , Mean Acc: 0.9996996734529928 , Min Acc: 0.9820440683407914 , Learning rate: 1.832539184116173e-06 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 9700 Mean Loss: 2.832923583479257e-07 , Max Loss: 2.4248231147755222e-05 , Mean Acc: 0.9996968639374091 , Min Acc: 0.9950757507021115 \n",
            ", Mean Accs Foc [0.99984915 0.99981479 0.99901284 0.99986122 0.99984004 0.99964988\n",
            " 0.99985013] \n",
            ", Min Accs Foc: [0.99816113 0.99859572 0.99507575 0.99827741 0.9980437  0.99775909\n",
            " 0.99805467] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 9800 , Mean Loss: 2.7604875265621555e-07 , Max Loss: 7.1680324982547525e-06 , Mean Acc: 0.9997002754904398 , Min Acc: 0.9848579551802898 , Learning rate: 8.705124334046654e-07 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 9800 Mean Loss: 2.8324444203319396e-07 , Max Loss: 2.425684425608041e-05 , Mean Acc: 0.9996968186933537 , Min Acc: 0.9950748762192123 \n",
            ", Mean Accs Foc [0.99984914 0.99981477 0.99901301 0.99986129 0.99983971 0.99964943\n",
            " 0.99985038] \n",
            ", Min Accs Foc: [0.99816096 0.99858754 0.99507488 0.99827638 0.99804656 0.99775506\n",
            " 0.99805689] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 9900 , Mean Loss: 2.7601435613285714e-07 , Max Loss: 7.170210031748051e-06 , Mean Acc: 0.9997001947170745 , Min Acc: 0.988465432744233 , Learning rate: 2.9270239163131087e-07 \n",
            "\n",
            "EVALUATION:\n",
            " Iteration: 9900 Mean Loss: 2.832717201185935e-07 , Max Loss: 2.425374531508023e-05 , Mean Acc: 0.9996968487692364 , Min Acc: 0.9950751908346536 \n",
            ", Mean Accs Foc [0.99984902 0.99981476 0.99901294 0.99986124 0.99984001 0.99964972\n",
            " 0.99985025] \n",
            ", Min Accs Foc: [0.99815904 0.99859628 0.99507519 0.99827536 0.99804255 0.9977593\n",
            " 0.99805559] \n",
            "\n",
            "TRAINING:\n",
            " Iteration: 10000 , Mean Loss: 2.7608043412555284e-07 , Max Loss: 7.165074063105916e-06 , Mean Acc: 0.9997000790804299 , Min Acc: 0.9887418765161404 , Learning rate: 1e-07 \n",
            "\n",
            "Minimum mean loss attained in evaluation: 2.832717201185935e-07\n",
            "Minimum max loss attained in evaluation: 2.425374531508023e-05\n",
            "Maximum mean accuracy attained in evaluation: 0.9996968487692364\n",
            "Maximum min accuracy attained in evaluation: 0.9950751908346536\n",
            "Time Elapsed for Full Experiment: 0.9399755915006002 minutes\n"
          ]
        }
      ],
      "source": [
        "trained_train_state = run_experiment(econ_model, config)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analysis"
      ],
      "metadata": {
        "id": "1avWoBL0_id-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config_analysis = {\n",
        "    \"init_range\": 0,\n",
        "    \"periods_per_epis\": 2000000,\n",
        "    \"simul_vol_scale\": 1,\n",
        "}\n",
        "\n",
        "config_stochss = {\n",
        "    \"n_draws\": 2000,\n",
        "    \"time_to_converge\": 500,\n",
        "    \"seed\": 0\n",
        "}\n",
        "\n",
        "rng_analysis=random.PRNGKey(4)\n",
        "\n",
        "\n",
        "# create functions\n",
        "simul_fn_verbose = jax.jit(create_episode_simul_verbose_fn(econ_model, config_analysis))\n",
        "descstats_fn = create_descstats_fn(econ_model, config_analysis)\n",
        "stochss_fn = jax.jit(create_stochss_fn(econ_model, config_stochss))\n",
        "\n",
        "# simulate model\n",
        "simul_obs, simul_policies = simul_fn_verbose(trained_train_state, rng_analysis)\n",
        "simul_policies_logdev = jnp.log(simul_policies)\n",
        "descstats_df, autocorr_df = descstats_fn(simul_policies_logdev)\n",
        "print(\"\\n descstat: \\n\", descstats_df)\n",
        "\n",
        "# calculate stochastic steady state\n",
        "stochss = stochss_fn(simul_obs, trained_train_state)\n",
        "print(\"\\n stoch_ss: \\n\", stochss)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qIiYsNJJAH1-",
        "outputId": "95a7729d-994a-48c8-dd30-8ed4077d5463"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " descstat:\n",
            "                C        L        K        I        Y\n",
            "Mean      0.00006  0.00002  0.00053 -0.00037  0.00015\n",
            "Sd        0.01489  0.00299  0.01874  0.06545  0.02040\n",
            "Skewness  0.00873 -0.02430 -0.00604 -0.15695 -0.00758\n",
            "Kurtosis  0.04262  0.20266  0.04703 -0.01917 -0.01837\n",
            "Q1       -0.03481 -0.00716 -0.04390 -0.15981 -0.04744\n",
            "Q25      -0.00995 -0.00195 -0.01196 -0.04430 -0.01370\n",
            "Q50       0.00000  0.00005  0.00030  0.00143  0.00019\n",
            "Q75       0.01006  0.00200  0.01316  0.04508  0.01399\n",
            "Q99       0.03489  0.00715  0.04425  0.14291  0.04734\n",
            "\n",
            " stoch_ss:\n",
            "[-0.00013008  0.00015333  0.00023468  0.00173204  0.00023521  0.00071905\n",
            "  0.0001409 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def dataframe_to_latex(df):\n",
        "    latex_str = \"\\\\begin{table}[h!]\\n\\\\centering\\n\\\\begin{tabular}{l\" + \"c\" * len(df.columns) + \"}\\n\"\n",
        "    latex_str += \" & \".join([\"\"] + list(df.columns)) + \" \\\\\\\\\\n\"\n",
        "    latex_str += \"\\\\hline\\n\"\n",
        "    for idx in df.index:\n",
        "        row = \" & \".join([idx] + [f\"{val:.5f}\" for val in df.loc[idx]])\n",
        "        latex_str += row + \" \\\\\\\\\\n\"\n",
        "    latex_str += \"\\\\hline\\n\"\n",
        "    latex_str += \"\\\\end{tabular}\\n\\\\caption{Descriptive Statistics}\\n\\\\label{table:desc_stats}\\n\\\\end{table}\"\n",
        "    return latex_str\n",
        "\n",
        "latex_table = dataframe_to_latex(descstats_df)\n",
        "print(latex_table)\n",
        "latex_filename = config['save_dir'] + config['exper_name'] + f'/descstat_table.tex'\n",
        "\n",
        "# Save the LaTeX code to the specified file\n",
        "with open(latex_filename, 'w') as file:\n",
        "    file.write(latex_table)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mXQdK_8RZqSl",
        "outputId": "e7d31ffd-d183-41b3-c78c-c051fa8bd55d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\\begin{table}[h!]\n",
            "\\centering\n",
            "\\begin{tabular}{lccccc}\n",
            " & C & L & K & I & Y \\\\\n",
            "\\hline\n",
            "Mean & 0.00006 & 0.00002 & 0.00053 & -0.00037 & 0.00015 \\\\\n",
            "Sd & 0.01489 & 0.00299 & 0.01874 & 0.06545 & 0.02040 \\\\\n",
            "Skewness & 0.00873 & -0.02430 & -0.00604 & -0.15695 & -0.00758 \\\\\n",
            "Kurtosis & 0.04262 & 0.20266 & 0.04703 & -0.01917 & -0.01837 \\\\\n",
            "Q1 & -0.03481 & -0.00716 & -0.04390 & -0.15981 & -0.04744 \\\\\n",
            "Q25 & -0.00995 & -0.00195 & -0.01196 & -0.04430 & -0.01370 \\\\\n",
            "Q50 & 0.00000 & 0.00005 & 0.00030 & 0.00143 & 0.00019 \\\\\n",
            "Q75 & 0.01006 & 0.00200 & 0.01316 & 0.04508 & 0.01399 \\\\\n",
            "Q99 & 0.03489 & 0.00715 & 0.04425 & 0.14291 & 0.04734 \\\\\n",
            "\\hline\n",
            "\\end{tabular}\n",
            "\\caption{Descriptive Statistics}\n",
            "\\label{table:desc_stats}\n",
            "\\end{table}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "table_titles = [\"Consumption\", \"Labor\", \"Capital\", \"Investment\",  \"Price\", \"Price of Capital\", \" GDP\"]\n",
        "table_data_strings = [str(round(float(value),5)) for value in stochss]\n",
        "\n",
        "# Initialize the LaTeX table string\n",
        "latex_table = \"\\\\begin{tabular}{\" + \"c\" * 7 + \"}\\n\\\\hline\\n\"\n",
        "\n",
        "# Add column titles\n",
        "latex_table += \" & \".join(table_titles) + \" \\\\\\\\\\n\\\\hline\\n\"\n",
        "\n",
        "# Add rows of values\n",
        "\n",
        "latex_table += \" & \".join(table_data_strings) +  \" \\\\\\\\\\n\"\n",
        "\n",
        "# End the table\n",
        "latex_table += \"\\\\hline\\n \\\\end{tabular}\"\n",
        "\n",
        "# Print the LaTeX table string\n",
        "print(latex_table)\n",
        "latex_filename = config['save_dir'] + config['restore_exper_name'] + '/stoch_ss_table.tex'\n",
        "\n",
        "# Save the LaTeX code to the specified file\n",
        "with open(latex_filename, 'w') as file:\n",
        "    file.write(latex_table)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ssg-bwHEaWk5",
        "outputId": "d64fbb61-7a7d-4bd7-d512-339ef8785f99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\\begin{tabular}{ccccccc}\n",
            "\\hline\n",
            "Consumption & Labor & Capital & Investment & Price & Price of Capital &  GDP \\\\\n",
            "\\hline\n",
            "-0.00013 & 0.00015 & 0.00023 & 0.00173 & 0.00024 & 0.00072 & 0.00014 \\\\\n",
            "\\hline\n",
            " \\end{tabular}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DISCONNECT SESSION (uncomment next 2 lines if you do large run)\n",
        "# from google.colab import runtime\n",
        "# runtime.unassign()"
      ],
      "metadata": {
        "id": "suVNiqThVOl9"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuClass": "premium",
      "gpuType": "A100",
      "toc_visible": true,
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOIYmiHbOM8VrOUlb3rt8ht",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}