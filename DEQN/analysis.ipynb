{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "690d35ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment: Google Colab\n",
      "Installing JAX with CUDA support...\n",
      "Cloning jaxecon repository...\n",
      "Mounting Google Drive...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-2430737911.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mbase_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/drive/MyDrive/Jaxecontemp\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m     98\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    132\u001b[0m   )\n\u001b[1;32m    133\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    135\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     if (\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Analysis script for DEQN trained models.\n",
    "\n",
    "Usage:\n",
    "    LOCAL:\n",
    "        # Method 1: Run as module (from repository root):\n",
    "        python -m DEQN.analysis\n",
    "\n",
    "        # Method 2: Run directly as script (from repository root):\n",
    "        python DEQN/analysis.py\n",
    "\n",
    "        Both methods require you to be in the repository root directory.\n",
    "\n",
    "    COLAB:\n",
    "        Simply run all cells in order. The script will automatically detect the Colab\n",
    "        environment, install dependencies, clone the repository, and mount Google Drive.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# ============================================================================\n",
    "# ENVIRONMENT DETECTION AND SETUP\n",
    "# ============================================================================\n",
    "\n",
    "try:\n",
    "    import google.colab  # type: ignore  # noqa: F401\n",
    "\n",
    "    IN_COLAB = True\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "\n",
    "print(f\"Environment: {'Google Colab' if IN_COLAB else 'Local'}\")\n",
    "\n",
    "if IN_COLAB:\n",
    "    print(\"Installing JAX with CUDA support...\")\n",
    "    import subprocess\n",
    "\n",
    "    subprocess.run([\"pip\", \"install\", \"--upgrade\", \"jax[cuda12]\"], check=True)\n",
    "\n",
    "    print(\"Cloning jaxecon repository...\")\n",
    "    if not os.path.exists(\"/content/jaxecon\"):\n",
    "        subprocess.run([\"git\", \"clone\", \"https://github.com/MatiasCovarrubias/jaxecon\"], check=True)\n",
    "\n",
    "    sys.path.insert(0, \"/content/jaxecon\")\n",
    "\n",
    "    print(\"Mounting Google Drive...\")\n",
    "    from google.colab import drive  # type: ignore\n",
    "\n",
    "    drive.mount(\"/content/drive\")\n",
    "\n",
    "    base_dir = \"/content/drive/MyDrive/Jaxecontemp\"\n",
    "\n",
    "else:\n",
    "    repo_root = os.path.abspath(os.path.join(os.path.dirname(__file__), \"..\"))\n",
    "    if repo_root not in sys.path:\n",
    "        sys.path.insert(0, repo_root)\n",
    "    base_dir = os.path.join(repo_root, \"DEQN\", \"econ_models\")\n",
    "\n",
    "# ============================================================================\n",
    "# IMPORTS\n",
    "# ============================================================================\n",
    "\n",
    "import importlib  # noqa: E402\n",
    "import json  # noqa: E402\n",
    "\n",
    "import jax  # noqa: E402\n",
    "import jax.numpy as jnp  # noqa: E402\n",
    "import scipy.io as sio  # noqa: E402\n",
    "from jax import config as jax_config  # noqa: E402\n",
    "from jax import random  # noqa: E402\n",
    "\n",
    "from DEQN.analysis.GIR import create_GIR_fn  # noqa: E402\n",
    "from DEQN.analysis.plots import (  # noqa: E402\n",
    "    plot_ergodic_histograms,\n",
    "    plot_gir_responses,\n",
    ")\n",
    "from DEQN.analysis.simul_analysis import (  # noqa: E402\n",
    "    create_episode_simulation_fn_verbose,\n",
    "    simulation_analysis,\n",
    ")\n",
    "from DEQN.analysis.stochastic_ss import create_stochss_fn  # noqa: E402\n",
    "from DEQN.analysis.tables import (  # noqa: E402\n",
    "    create_comparative_stats_table,\n",
    "    create_descriptive_stats_table,\n",
    "    create_stochastic_ss_table,\n",
    "    create_welfare_table,\n",
    ")\n",
    "from DEQN.analysis.welfare import get_welfare_fn  # noqa: E402\n",
    "from DEQN.utils import load_experiment_data, load_trained_model_orbax  # noqa: E402\n",
    "\n",
    "jax_config.update(\"jax_debug_nans\", True)\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURATION\n",
    "# ============================================================================\n",
    "\n",
    "# Configuration dictionary\n",
    "config = {\n",
    "    # Key configuration - Edit these first\n",
    "    \"model_dir\": \"RbcProdNet_nonlinear\",\n",
    "    \"analysis_name\": \"npnlinearv2_lowvol\",\n",
    "    # Experiments to analyze\n",
    "    \"experiments_to_analyze\": {\n",
    "        # \"higher volatility\": \"3vol\",\n",
    "        # \"x0.075 volatility\": \"nonlinearv2_volx0dot075\",\n",
    "        # \"x0.05 volatility\": \"nonlinearv2_vol0dot05\",\n",
    "        # \"x0.025 volatility\": \"nonlinearv2_volx0dot025\",\n",
    "        \"x1.5 volatility\": \"nonlinearv2_volx1.5\",\n",
    "        \"baseline\": \"nonlinearv2\",\n",
    "        \"x0.1 volatility\": \"nonlinearv2_volx0dot1\",\n",
    "        # \"x0.75 volatility\": \"x0dot75vol_newNN\",\n",
    "        # \"x0.5 volatility\": \"x0dot5_newNN\",\n",
    "        # \"x0.1 volatility\": \"newcalib_volx0dot1\",\n",
    "    },\n",
    "    # Simulation configuration\n",
    "    \"init_range\": 6,\n",
    "    \"periods_per_epis\": 64000,\n",
    "    \"burn_in_periods\": 3200,\n",
    "    \"simul_vol_scale\": 1,\n",
    "    \"simul_seed\": 0,\n",
    "    \"n_simul_seeds\": 16,\n",
    "    # Welfare configuration\n",
    "    \"welfare_n_trajects\": 16000,\n",
    "    \"welfare_traject_length\": 100,\n",
    "    \"welfare_seed\": 0,\n",
    "    # Stochastic steady state configuration\n",
    "    \"n_draws\": 2000,\n",
    "    \"time_to_converge\": 500,\n",
    "    \"seed\": 0,\n",
    "    # GIR configuration\n",
    "    \"gir_n_draws\": 1000,\n",
    "    \"gir_trajectory_length\": 100,\n",
    "    \"shock_size\": 0.2,\n",
    "    \"states_to_shock\": [37],\n",
    "    \"gir_seed\": 42,\n",
    "    # JAX configuration\n",
    "    \"double_precision\": True,\n",
    "}\n",
    "\n",
    "# ============================================================================\n",
    "# DYNAMIC IMPORTS (based on model_dir from config)\n",
    "# ============================================================================\n",
    "\n",
    "# Import Model class from the specified model directory\n",
    "model_module = importlib.import_module(f\"DEQN.econ_models.{config['model_dir']}.model\")\n",
    "Model = model_module.Model\n",
    "\n",
    "# Import model-specific plots module and registry\n",
    "plots_module = importlib.import_module(f\"DEQN.econ_models.{config['model_dir']}.plots\")\n",
    "MODEL_SPECIFIC_PLOTS = getattr(plots_module, \"MODEL_SPECIFIC_PLOTS\", [])\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# MAIN FUNCTION\n",
    "# ============================================================================\n",
    "\n",
    "\n",
    "def main():\n",
    "    print(f\"Analysis: {config['analysis_name']}\", flush=True)\n",
    "\n",
    "    # Environment and precision setup\n",
    "    print(\"Setting up precision...\", flush=True)\n",
    "    precision = jnp.float64 if config[\"double_precision\"] else jnp.float32\n",
    "    if config[\"double_precision\"]:\n",
    "        jax_config.update(\"jax_enable_x64\", True)\n",
    "    print(\"Precision setup complete.\", flush=True)\n",
    "\n",
    "    model_dir = os.path.join(base_dir, config[\"model_dir\"])\n",
    "    save_dir = os.path.join(model_dir, \"experiments/\")\n",
    "\n",
    "    # Create analysis directory structure\n",
    "    analysis_dir = os.path.join(model_dir, \"analysis\", config[\"analysis_name\"])\n",
    "    simulation_dir = os.path.join(analysis_dir, \"simulation\")\n",
    "    irs_dir = os.path.join(analysis_dir, \"IRs\")\n",
    "\n",
    "    # Create all directories\n",
    "    os.makedirs(analysis_dir, exist_ok=True)\n",
    "    os.makedirs(simulation_dir, exist_ok=True)\n",
    "    os.makedirs(irs_dir, exist_ok=True)\n",
    "\n",
    "    # Save analysis configuration as JSON\n",
    "    config_path = os.path.join(analysis_dir, \"config.json\")\n",
    "    with open(config_path, \"w\") as f:\n",
    "        json.dump(config, f, indent=2)\n",
    "    print(f\"Analysis configuration saved to: {config_path}\", flush=True)\n",
    "\n",
    "    # Load model data\n",
    "    print(\"Loading model data...\", flush=True)\n",
    "    model_path = os.path.join(model_dir, \"model_data.mat\")\n",
    "    if not os.path.exists(model_path):\n",
    "        raise FileNotFoundError(f\"Model file not found: {model_path}\")\n",
    "\n",
    "    model_data = sio.loadmat(model_path, simplify_cells=True)\n",
    "    print(\"Model data loaded successfully.\", flush=True)\n",
    "    n_sectors = model_data[\"SolData\"][\"parameters\"][\"parn_sectors\"]\n",
    "    a_ss = jnp.zeros(shape=(n_sectors,), dtype=precision)\n",
    "    state_ss = jnp.concatenate([model_data[\"SolData\"][\"k_ss\"], a_ss])\n",
    "\n",
    "    # Create economic model\n",
    "    print(\"Creating economic model...\", flush=True)\n",
    "    econ_model = Model(\n",
    "        parameters=model_data[\"SolData\"][\"parameters\"],\n",
    "        state_ss=state_ss,\n",
    "        policies_ss=model_data[\"SolData\"][\"policies_ss\"],\n",
    "        state_sd=model_data[\"SolData\"][\"states_sd\"],\n",
    "        policies_sd=model_data[\"SolData\"][\"policies_sd\"],\n",
    "        double_precision=config[\"double_precision\"],\n",
    "    )\n",
    "    print(\"Economic model created successfully.\", flush=True)\n",
    "\n",
    "    # Load experiment data\n",
    "    print(\"Loading experiment data...\", flush=True)\n",
    "    experiments_to_analyze = config[\"experiments_to_analyze\"]\n",
    "    experiments_data = load_experiment_data(experiments_to_analyze, save_dir)\n",
    "    print(\"Experiment data loaded successfully.\", flush=True)\n",
    "\n",
    "    # Define shared nn_config using model_data (features will be set per experiment)\n",
    "    nn_config_base = {\n",
    "        \"C\": model_data[\"SolData\"][\"C\"],\n",
    "        \"states_sd\": model_data[\"SolData\"][\"states_sd\"],\n",
    "        \"policies_sd\": model_data[\"SolData\"][\"policies_sd\"],\n",
    "        \"params_dtype\": precision,\n",
    "    }\n",
    "\n",
    "    # Create analysis functions\n",
    "    print(\"Creating analysis functions...\", flush=True)\n",
    "    simulation_fn = jax.jit(create_episode_simulation_fn_verbose(econ_model, config))\n",
    "    welfare_fn = jax.jit(get_welfare_fn(econ_model, config))\n",
    "    stoch_ss_fn = jax.jit(create_stochss_fn(econ_model, config))\n",
    "    gir_fn = jax.jit(create_GIR_fn(econ_model, config))\n",
    "    print(\"Analysis functions created successfully.\", flush=True)\n",
    "\n",
    "    # Storage for analysis results\n",
    "    analysis_variables_data = {}\n",
    "    raw_simulation_data = {}\n",
    "    welfare_costs = {}\n",
    "    stochastic_ss_data = {}\n",
    "    gir_data = {}\n",
    "\n",
    "    # Data collection loop\n",
    "    print(\"Collecting analysis data...\", flush=True)\n",
    "    for experiment_label, exp_data in experiments_data.items():\n",
    "        print(f\"  Processing: {experiment_label}\", flush=True)\n",
    "\n",
    "        experiment_config = exp_data[\"config\"]\n",
    "        experiment_name = exp_data[\"results\"][\"exper_name\"]\n",
    "\n",
    "        # Build nn_config with experiment-specific features\n",
    "        nn_config = nn_config_base.copy()\n",
    "        nn_config[\"features\"] = experiment_config[\"layers\"] + [econ_model.dim_policies]\n",
    "\n",
    "        # Load trained model (using same initialization approach as training)\n",
    "        train_state = load_trained_model_orbax(experiment_name, save_dir, nn_config, econ_model.state_ss)\n",
    "\n",
    "        # Generate simulation data\n",
    "        simul_obs, simul_policies, simul_analysis_variables = simulation_analysis(\n",
    "            train_state, econ_model, config, simulation_fn\n",
    "        )\n",
    "\n",
    "        # Store raw simulation data for model-specific plots\n",
    "        raw_simulation_data[experiment_label] = {\n",
    "            \"simul_obs\": simul_obs,\n",
    "            \"simul_policies\": simul_policies,\n",
    "            \"simul_analysis_variables\": simul_analysis_variables,\n",
    "        }\n",
    "\n",
    "        # Store analysis variables for general analysis\n",
    "        analysis_variables_data[experiment_label] = simul_analysis_variables\n",
    "\n",
    "        # Calculate utilities separately using the new utility method\n",
    "        simul_utilities = jax.vmap(econ_model.utility_from_policies)(simul_policies)\n",
    "\n",
    "        # Calculate and store welfare cost\n",
    "        welfare_ss = econ_model.utility_ss / (1 - econ_model.beta)\n",
    "        welfare = welfare_fn(simul_utilities, welfare_ss, random.PRNGKey(config[\"welfare_seed\"]))\n",
    "        welfare_loss = (1 - welfare / welfare_ss) * 100\n",
    "        welfare_costs[experiment_label] = welfare_loss\n",
    "\n",
    "        # Calculate and store stochastic steady state\n",
    "        stoch_ss_policy, stoch_ss_obs, stoch_ss_obs_std = stoch_ss_fn(simul_obs, train_state)\n",
    "        if stoch_ss_obs_std.max() > 0.001:\n",
    "            raise ValueError(\"Stochastic steady state standard deviation too large\")\n",
    "\n",
    "        # Get average prices from simulation policies\n",
    "        simul_policies_mean = jnp.mean(simul_policies, axis=0)\n",
    "        P_mean = simul_policies_mean[8 * econ_model.n_sectors : 9 * econ_model.n_sectors]\n",
    "        Pk_mean = simul_policies_mean[2 * econ_model.n_sectors : 3 * econ_model.n_sectors]\n",
    "        Pm_mean = simul_policies_mean[3 * econ_model.n_sectors : 4 * econ_model.n_sectors]\n",
    "\n",
    "        # Calculate stochastic steady state analysis variables (returns dictionary)\n",
    "        stoch_ss_analysis_variables = econ_model.get_analysis_variables(\n",
    "            stoch_ss_obs, stoch_ss_policy, P_mean, Pk_mean, Pm_mean\n",
    "        )\n",
    "\n",
    "        # Store stochastic steady state data as dictionary\n",
    "        stochastic_ss_data[experiment_label] = stoch_ss_analysis_variables\n",
    "\n",
    "        # Calculate and store GIR\n",
    "        gir_results = gir_fn(simul_obs, train_state, simul_policies)\n",
    "        gir_data[experiment_label] = gir_results\n",
    "\n",
    "    print(\"Data collection completed successfully.\", flush=True)\n",
    "\n",
    "    # ============================================================================\n",
    "    # GENERAL ANALYSIS: Tables and Plots\n",
    "    # ============================================================================\n",
    "    print(\"Generating general analysis tables and figures...\", flush=True)\n",
    "\n",
    "    # Descriptive statistics tables (in simulation folder)\n",
    "    create_descriptive_stats_table(\n",
    "        analysis_variables_data=analysis_variables_data,\n",
    "        save_path=os.path.join(simulation_dir, \"descriptive_stats_table.tex\"),\n",
    "        analysis_name=config[\"analysis_name\"],\n",
    "    )\n",
    "\n",
    "    if len(analysis_variables_data) > 1:\n",
    "        create_comparative_stats_table(\n",
    "            analysis_variables_data=analysis_variables_data,\n",
    "            save_path=os.path.join(simulation_dir, \"descriptive_stats_comparative.tex\"),\n",
    "            analysis_name=config[\"analysis_name\"],\n",
    "        )\n",
    "\n",
    "    # Welfare table (in analysis directory)\n",
    "    create_welfare_table(\n",
    "        welfare_data=welfare_costs,\n",
    "        save_path=os.path.join(analysis_dir, \"welfare_table.tex\"),\n",
    "        analysis_name=config[\"analysis_name\"],\n",
    "    )\n",
    "\n",
    "    # Stochastic steady state table (in analysis directory)\n",
    "    create_stochastic_ss_table(\n",
    "        stochastic_ss_data=stochastic_ss_data,\n",
    "        save_path=os.path.join(analysis_dir, \"stochastic_ss_table.tex\"),\n",
    "        analysis_name=config[\"analysis_name\"],\n",
    "    )\n",
    "\n",
    "    # Analysis variable histograms (in simulation folder)\n",
    "    plot_ergodic_histograms(\n",
    "        analysis_variables_data=analysis_variables_data, save_dir=simulation_dir, analysis_name=config[\"analysis_name\"]\n",
    "    )\n",
    "\n",
    "    # GIR plots (in IRs folder)\n",
    "    first_experiment = list(gir_data.keys())[0]\n",
    "    states_shocked = list(gir_data[first_experiment].keys())\n",
    "\n",
    "    plot_gir_responses(\n",
    "        gir_data=gir_data,\n",
    "        states_to_plot=states_shocked,\n",
    "        save_dir=irs_dir,\n",
    "        analysis_name=config[\"analysis_name\"],\n",
    "    )\n",
    "\n",
    "    # ============================================================================\n",
    "    # MODEL-SPECIFIC ANALYSIS: Plots\n",
    "    # ============================================================================\n",
    "    print(\"Generating model-specific plots...\", flush=True)\n",
    "\n",
    "    if MODEL_SPECIFIC_PLOTS:\n",
    "        for plot_spec in MODEL_SPECIFIC_PLOTS:\n",
    "            plot_name = plot_spec[\"name\"]\n",
    "            plot_function = plot_spec[\"function\"]\n",
    "            print(f\"  - Running model-specific plot: {plot_name}\", flush=True)\n",
    "\n",
    "            # Run the plot for each experiment (save in simulation folder)\n",
    "            for experiment_label, sim_data in raw_simulation_data.items():\n",
    "                try:\n",
    "                    plot_function(\n",
    "                        simul_obs=sim_data[\"simul_obs\"],\n",
    "                        simul_policies=sim_data[\"simul_policies\"],\n",
    "                        simul_analysis_variables=sim_data[\"simul_analysis_variables\"],\n",
    "                        save_path=os.path.join(simulation_dir, f\"{plot_name}_{experiment_label}.png\"),\n",
    "                        analysis_name=config[\"analysis_name\"],\n",
    "                        econ_model=econ_model,\n",
    "                        experiment_label=experiment_label,\n",
    "                    )\n",
    "                    print(f\"    ✓ {plot_name} for {experiment_label}\", flush=True)\n",
    "                except Exception as e:\n",
    "                    print(f\"    ✗ Failed to create {plot_name} for {experiment_label}: {e}\", flush=True)\n",
    "    else:\n",
    "        print(\"  No model-specific plots registered.\", flush=True)\n",
    "\n",
    "    print(\"Analysis completed successfully.\", flush=True)\n",
    "\n",
    "    return {\n",
    "        \"analysis_variables_data\": analysis_variables_data,\n",
    "        \"raw_simulation_data\": raw_simulation_data,\n",
    "        \"welfare_costs\": welfare_costs,\n",
    "        \"stochastic_ss_data\": stochastic_ss_data,\n",
    "        \"gir_data\": gir_data,\n",
    "    }\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
